{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ruptures # ruptures is designed to perform offline change point algorithms within the Python language. Also in this library, new methods are presented. How to cite If you use ruptures in a scientific publication, we would appreciate citations to the following paper: Truong, C., Oudre, L., & Vayatis, N. (2020). Selective review of offline change point detection methods. Signal Processing , 167. [abstract] [doi] [pdf] Contact Concerning this package, its use and bugs, use the issue page of the ruptures repository . For other inquiries, you can contact me here .","title":"Welcome to ruptures"},{"location":"#welcome-to-ruptures","text":"ruptures is designed to perform offline change point algorithms within the Python language. Also in this library, new methods are presented. How to cite If you use ruptures in a scientific publication, we would appreciate citations to the following paper: Truong, C., Oudre, L., & Vayatis, N. (2020). Selective review of offline change point detection methods. Signal Processing , 167. [abstract] [doi] [pdf] Contact Concerning this package, its use and bugs, use the issue page of the ruptures repository . For other inquiries, you can contact me here .","title":"Welcome to ruptures"},{"location":"contributing/","text":"Contributing # Before contributing # In all following steps, it is highly recommended to use a virtual environment. Build and installation are performed using pip so be sure to have the latest version available. python -m pip install --upgrade pip Install the development version # It is important that you contribute to the latest version of the code. To that end, start by cloning the Github repository. git clone https://github.com/deepcharles/ruptures cd ruptures Then install the downloaded package with pip . python -m pip install --editable .[dev] Note that python -m can be omitted most of the times, but within virtualenvs, it can prevent certain errors. Also, in certain terminals (such as zsh ), the square brackets must be escaped, e.g. replace .[dev] by .\\[dev\\] . In addition to numpy , scipy and ruptures , this command will install all packages needed to develop ruptures . The exact list of librairies can be found in the setup.cfg file (section [options.extras_require] ). Pre-commit hooks # We use pre-commit to run Git hooks before submitting the code to review. These hook scripts perform simple tasks before each commit (code formatting mostly). To activate the hooks, simply run the following command in your terminal. pre-commit install If you try to commit a non-compliant (i.e. badly formatted) file, pre-commit will modify this file and make the commit fail. However you need to stage the new changes yourself as pre-commit will not do that for you (this is by design; see here or here ). Fortunately, pre-commit outputs useful messages. The list of hooks (and their options) can be found in .pre-commit-config.yaml . For more information, see their website . If you want to manually run all pre-commit hooks on a repository, run pre-commit run --all-files . To run individual hooks use pre-commit run <hook_id> . Contribute to the code # Write tests # The following command executes the test suite. python -m pytest Write docstrings # Contribute to the documentation # Use MkDocs . Use mkdocs serve to preview your changes. Once you are satisfied, no need to build the documentation, the CI will take care of that and publish it online at the next release of the package (if the pull request has been merged). Add examples to the gallery # An easy way to showcase your work with ruptures is to write a narrative example. To that, simply put a Jupyter notebook in the docs/examples folder. To make it appear in the documentation, add a reference in mkdocs.yml ( nav > Gallery of examples ): if the notebook's name is my_notebook.ipynb , it will be available as examples/my_notebook.ipynb . It will be rendered automatically when MkDocs builds the documentation. Note To automatically add a Binder link and a download link to your notebook, simply add the following line of code. <!-- {{ add_binder_block(page) }} --> Ideally, place this code below the title of the notebook (same cell) and it will be rendered as in here . We welcome any interesting work about a new cost function, algorithm, data, calibration method, etc. Any other package can be used in combination with ruptures . However, each example should be clearly explained with text and figures. The amount of raw code should also remain limited for readability. Miscellaneous # Naming convention # We try to follow (roughly) a consistent naming convention of modules, classes, functions, etc. When in doubt, you can refer to the PEP 8 style guide for Python code .","title":"Contributing"},{"location":"contributing/#contributing","text":"","title":"Contributing"},{"location":"contributing/#before-contributing","text":"In all following steps, it is highly recommended to use a virtual environment. Build and installation are performed using pip so be sure to have the latest version available. python -m pip install --upgrade pip","title":"Before contributing"},{"location":"contributing/#install-the-development-version","text":"It is important that you contribute to the latest version of the code. To that end, start by cloning the Github repository. git clone https://github.com/deepcharles/ruptures cd ruptures Then install the downloaded package with pip . python -m pip install --editable .[dev] Note that python -m can be omitted most of the times, but within virtualenvs, it can prevent certain errors. Also, in certain terminals (such as zsh ), the square brackets must be escaped, e.g. replace .[dev] by .\\[dev\\] . In addition to numpy , scipy and ruptures , this command will install all packages needed to develop ruptures . The exact list of librairies can be found in the setup.cfg file (section [options.extras_require] ).","title":"Install the development version"},{"location":"contributing/#pre-commit-hooks","text":"We use pre-commit to run Git hooks before submitting the code to review. These hook scripts perform simple tasks before each commit (code formatting mostly). To activate the hooks, simply run the following command in your terminal. pre-commit install If you try to commit a non-compliant (i.e. badly formatted) file, pre-commit will modify this file and make the commit fail. However you need to stage the new changes yourself as pre-commit will not do that for you (this is by design; see here or here ). Fortunately, pre-commit outputs useful messages. The list of hooks (and their options) can be found in .pre-commit-config.yaml . For more information, see their website . If you want to manually run all pre-commit hooks on a repository, run pre-commit run --all-files . To run individual hooks use pre-commit run <hook_id> .","title":"Pre-commit hooks"},{"location":"contributing/#contribute-to-the-code","text":"","title":"Contribute to the code"},{"location":"contributing/#write-tests","text":"The following command executes the test suite. python -m pytest","title":"Write tests"},{"location":"contributing/#write-docstrings","text":"","title":"Write docstrings"},{"location":"contributing/#contribute-to-the-documentation","text":"Use MkDocs . Use mkdocs serve to preview your changes. Once you are satisfied, no need to build the documentation, the CI will take care of that and publish it online at the next release of the package (if the pull request has been merged).","title":"Contribute to the documentation"},{"location":"contributing/#add-examples-to-the-gallery","text":"An easy way to showcase your work with ruptures is to write a narrative example. To that, simply put a Jupyter notebook in the docs/examples folder. To make it appear in the documentation, add a reference in mkdocs.yml ( nav > Gallery of examples ): if the notebook's name is my_notebook.ipynb , it will be available as examples/my_notebook.ipynb . It will be rendered automatically when MkDocs builds the documentation. Note To automatically add a Binder link and a download link to your notebook, simply add the following line of code. <!-- {{ add_binder_block(page) }} --> Ideally, place this code below the title of the notebook (same cell) and it will be rendered as in here . We welcome any interesting work about a new cost function, algorithm, data, calibration method, etc. Any other package can be used in combination with ruptures . However, each example should be clearly explained with text and figures. The amount of raw code should also remain limited for readability.","title":"Add examples to the gallery"},{"location":"contributing/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"contributing/#naming-convention","text":"We try to follow (roughly) a consistent naming convention of modules, classes, functions, etc. When in doubt, you can refer to the PEP 8 style guide for Python code .","title":"Naming convention"},{"location":"custom-cost-function/","text":"Creating a custom cost function # In order to define custom cost functions, simply create a class that inherits from ruptures.base.BaseCost and implement the methods .fit(signal) and .error(start, end) : The method .fit(signal) takes a signal as input and sets parameters. It returns 'self' . The method .error(start, end) takes two indexes 'start' and 'end' and returns the cost on the segment start:end. Example See this custom cost example .","title":"Custom cost function"},{"location":"custom-cost-function/#creating-a-custom-cost-function","text":"In order to define custom cost functions, simply create a class that inherits from ruptures.base.BaseCost and implement the methods .fit(signal) and .error(start, end) : The method .fit(signal) takes a signal as input and sets parameters. It returns 'self' . The method .error(start, end) takes two indexes 'start' and 'end' and returns the cost on the segment start:end. Example See this custom cost example .","title":"Creating a custom cost function"},{"location":"fit-and-predict/","text":"Fitting and prediction: estimator basics # ruptures has an object-oriented modelling approach (largely inspired by scikit-learn ): change point detection algorithms are broken down into two conceptual objects that inherits from base classes: BaseEstimator and BaseCost . Initializing a new estimator # Each change point detection algorithm inherits from the base class ruptures.base.BaseEstimator . When a class that inherits from the base estimator is created, the .__init__() method initializes an estimator with the following arguments: model : \"l1\", \"l2\", \"normal\", \"rbf\", \"linear\", etc. Cost function to use to compute the approximation error. cost : a custom cost function to the detection algorithm. Should be a BaseCost instance. jump : reduce the set of possible change point indexes; predicted change points can only be a multiple of jump . min_size : minimum number of samples between two change points. Making a prediction # The main methods are .fit() , .predict() , .fit_predict() : .fit() : generally takes a signal as input and fit the algorithm to the data. .predict() : performs the change point detection. This method returns a list of indexes corresponding to the end of each regimes. By design, the last element of this list is the number of samples. .fit_predict() : helper method which calls .fit() and .predict() successively.","title":"Fitting and predicting"},{"location":"fit-and-predict/#fitting-and-prediction-estimator-basics","text":"ruptures has an object-oriented modelling approach (largely inspired by scikit-learn ): change point detection algorithms are broken down into two conceptual objects that inherits from base classes: BaseEstimator and BaseCost .","title":"Fitting and prediction: estimator basics"},{"location":"fit-and-predict/#initializing-a-new-estimator","text":"Each change point detection algorithm inherits from the base class ruptures.base.BaseEstimator . When a class that inherits from the base estimator is created, the .__init__() method initializes an estimator with the following arguments: model : \"l1\", \"l2\", \"normal\", \"rbf\", \"linear\", etc. Cost function to use to compute the approximation error. cost : a custom cost function to the detection algorithm. Should be a BaseCost instance. jump : reduce the set of possible change point indexes; predicted change points can only be a multiple of jump . min_size : minimum number of samples between two change points.","title":"Initializing a new estimator"},{"location":"fit-and-predict/#making-a-prediction","text":"The main methods are .fit() , .predict() , .fit_predict() : .fit() : generally takes a signal as input and fit the algorithm to the data. .predict() : performs the change point detection. This method returns a list of indexes corresponding to the end of each regimes. By design, the last element of this list is the number of samples. .fit_predict() : helper method which calls .fit() and .predict() successively.","title":"Making a prediction"},{"location":"install/","text":"Installation # This library requires Python >=3.6 and the following packages: numpy , scipy and matplotlib (the last one is optional and only for display purposes). You can either install the latest stable release or the development version. Stable release # To install the latest stable release, use pip or conda . With pip python -m pip install ruptures With conda ruptures can be installed from the conda-forge channel (run conda config --add channels conda-forge to add it): conda install ruptures Development release # Alternatively, you can install the development version of ruptures which can contain features that have not yet been integrated to the stable release. To that end, refer to the contributing guide . Upgrade # Show the current version of the package. python -m pip show ruptures In order to upgrade to the version, use the following command. python -m pip install -U ruptures","title":"Installation"},{"location":"install/#installation","text":"This library requires Python >=3.6 and the following packages: numpy , scipy and matplotlib (the last one is optional and only for display purposes). You can either install the latest stable release or the development version.","title":"Installation"},{"location":"install/#stable-release","text":"To install the latest stable release, use pip or conda . With pip python -m pip install ruptures With conda ruptures can be installed from the conda-forge channel (run conda config --add channels conda-forge to add it): conda install ruptures","title":"Stable release"},{"location":"install/#development-release","text":"Alternatively, you can install the development version of ruptures which can contain features that have not yet been integrated to the stable release. To that end, refer to the contributing guide .","title":"Development release"},{"location":"install/#upgrade","text":"Show the current version of the package. python -m pip show ruptures In order to upgrade to the version, use the following command. python -m pip install -U ruptures","title":"Upgrade"},{"location":"license/","text":"License # This project is under BSD license. BSD 2-Clause License Copyright (c) 2017, ENS Paris-Saclay, CNRS All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"license/#license","text":"This project is under BSD license. BSD 2-Clause License Copyright (c) 2017, ENS Paris-Saclay, CNRS All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"release-notes/","text":"Changelog # All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased # Added # Changed # 1.1.2 - 2020-12-01 # Added # 12cbc9e feat: add piecewise linear cpd (#91) a12b215 test: add code coverage badge (#97) 2e9b17f docs: add binder for notebooks (#94) da7544f docs(costcosine): add entry for CostCosine in docs (#93) 8c9aa35 build(setup.py/cfg): add build_ext to setup.py (#88) 10ef8e8 build(python39): add py39 to supported versions (#87) Changed # 069bd41 fix(kernelcpd): bug fix in pelt (#95) b4abc34 fix: memory leak in KernelCPD (#89) 1.1.1 - 2020-11-26 # No change to the code compared to the previous version. The package was only partly published to Pypi because of the failure of one provider in the CI. Since Pypi's policy prevents re-uploading twice the same version, we have to increment the version number. 1.1.0 - 2020-11-23 # Added # modify publishing process to Pypi PR#83 add cosine kernel (cost function and in KernelCPD)PR#74 add faster kernel change point detection ( KernelCPD , C implementation) PR#74 add manual trigger to publish to Pypi PR#72 Changed # 1.0.6 - 2020-10-23 # Added # Correct minor error in Dynp (about min_size) PR#74 Fix legacy formatting errors PR#69 New documentation (from Sphinx to Mkdocs) PR#64 Separate requirements.txt and requirements-dev.txt PR#64 A changelog file ( link ) New Github actions for automatic generation of documentation Pre-commit code formatting using black Changed # Correction of display function test #64 Add badges in the README (Github repo) PR#62: pypi version, python version, code style, contributor list Typo in documentation ( PR#60 ) by @gjaeger Documentation theme Documentation site 1.0.5 - 2020-07-22 # Changed # Link to documentation in PyPi description","title":"Release notes"},{"location":"release-notes/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"release-notes/#unreleased","text":"","title":"Unreleased"},{"location":"release-notes/#added","text":"","title":"Added"},{"location":"release-notes/#changed","text":"","title":"Changed"},{"location":"release-notes/#112-2020-12-01","text":"","title":"1.1.2 - 2020-12-01"},{"location":"release-notes/#added_1","text":"12cbc9e feat: add piecewise linear cpd (#91) a12b215 test: add code coverage badge (#97) 2e9b17f docs: add binder for notebooks (#94) da7544f docs(costcosine): add entry for CostCosine in docs (#93) 8c9aa35 build(setup.py/cfg): add build_ext to setup.py (#88) 10ef8e8 build(python39): add py39 to supported versions (#87)","title":"Added"},{"location":"release-notes/#changed_1","text":"069bd41 fix(kernelcpd): bug fix in pelt (#95) b4abc34 fix: memory leak in KernelCPD (#89)","title":"Changed"},{"location":"release-notes/#111-2020-11-26","text":"No change to the code compared to the previous version. The package was only partly published to Pypi because of the failure of one provider in the CI. Since Pypi's policy prevents re-uploading twice the same version, we have to increment the version number.","title":"1.1.1 - 2020-11-26"},{"location":"release-notes/#110-2020-11-23","text":"","title":"1.1.0 - 2020-11-23"},{"location":"release-notes/#added_2","text":"modify publishing process to Pypi PR#83 add cosine kernel (cost function and in KernelCPD)PR#74 add faster kernel change point detection ( KernelCPD , C implementation) PR#74 add manual trigger to publish to Pypi PR#72","title":"Added"},{"location":"release-notes/#changed_2","text":"","title":"Changed"},{"location":"release-notes/#106-2020-10-23","text":"","title":"1.0.6 - 2020-10-23"},{"location":"release-notes/#added_3","text":"Correct minor error in Dynp (about min_size) PR#74 Fix legacy formatting errors PR#69 New documentation (from Sphinx to Mkdocs) PR#64 Separate requirements.txt and requirements-dev.txt PR#64 A changelog file ( link ) New Github actions for automatic generation of documentation Pre-commit code formatting using black","title":"Added"},{"location":"release-notes/#changed_3","text":"Correction of display function test #64 Add badges in the README (Github repo) PR#62: pypi version, python version, code style, contributor list Typo in documentation ( PR#60 ) by @gjaeger Documentation theme Documentation site","title":"Changed"},{"location":"release-notes/#105-2020-07-22","text":"","title":"1.0.5 - 2020-07-22"},{"location":"release-notes/#changed_4","text":"Link to documentation in PyPi description","title":"Changed"},{"location":"what-is-cpd/","text":"What is change point detection? # Under construction. In the meantime, you can refer to the associated review of methods [Truong2020] . References # [Truong2020] Truong, C., Oudre, L., & Vayatis, N. (2020). Selective review of offline change point detection methods. Signal Processing , 167. [abstract] [doi] [pdf]","title":"Change point detection?"},{"location":"what-is-cpd/#what-is-change-point-detection","text":"Under construction. In the meantime, you can refer to the associated review of methods [Truong2020] .","title":"What is change point detection?"},{"location":"what-is-cpd/#references","text":"[Truong2020] Truong, C., Oudre, L., & Vayatis, N. (2020). Selective review of offline change point detection methods. Signal Processing , 167. [abstract] [doi] [pdf]","title":"References"},{"location":"code-reference/","text":"Introduction # This section describes the API of all functions and classes in the ruptures package. For a more intuitive description of each method, please refer to the User guide . Roughly, each module corresponds to a certain type of procedure: ruptures.base : base classes; ruptures.detection : search methods; ruptures.costs : costs functions; ruptures.datasets : data set generating utilities; ruptures.metrics : evaluation metrics; ruptures.show : display functions.","title":"Introduction"},{"location":"code-reference/#introduction","text":"This section describes the API of all functions and classes in the ruptures package. For a more intuitive description of each method, please refer to the User guide . Roughly, each module corresponds to a certain type of procedure: ruptures.base : base classes; ruptures.detection : search methods; ruptures.costs : costs functions; ruptures.datasets : data set generating utilities; ruptures.metrics : evaluation metrics; ruptures.show : display functions.","title":"Introduction"},{"location":"code-reference/base-reference/","text":"Base classes (ruptures.base) # All estimators and cost functions are subclasses of BaseEstimator and BaseCost respectively. BaseCost # Base class for all segment cost classes. Notes All classes should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ). error ( self , start , end ) # Returns the cost on segment [start:end]. Source code in ruptures/base.py @abc . abstractmethod def error ( self , start , end ): \"\"\"Returns the cost on segment [start:end].\"\"\" pass fit ( self , * args , ** kwargs ) # Set the parameters of the cost function, for instance the Gram matrix, etc. Source code in ruptures/base.py @abc . abstractmethod def fit ( self , * args , ** kwargs ): \"\"\"Set the parameters of the cost function, for instance the Gram matrix, etc.\"\"\" pass sum_of_costs ( self , bkps ) # Returns the sum of segments cost for the given segmentation. Parameters: Name Type Description Default bkps list list of change points. By convention, bkps[-1]==n_samples. required Returns: Type Description float sum of costs Source code in ruptures/base.py def sum_of_costs ( self , bkps ): \"\"\"Returns the sum of segments cost for the given segmentation. Args: bkps (list): list of change points. By convention, bkps[-1]==n_samples. Returns: float: sum of costs \"\"\" soc = sum ( self . error ( start , end ) for start , end in pairwise ([ 0 ] + bkps )) return soc BaseEstimator # Base class for all change point detection estimators. Notes All estimators should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ). fit ( self , * args , ** kwargs ) # To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def fit ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass fit_predict ( self , * args , ** kwargs ) # To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def fit_predict ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass predict ( self , * args , ** kwargs ) # To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def predict ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass","title":"Base classes"},{"location":"code-reference/base-reference/#base-classes-rupturesbase","text":"All estimators and cost functions are subclasses of BaseEstimator and BaseCost respectively.","title":"Base classes (ruptures.base)"},{"location":"code-reference/base-reference/#ruptures.base.BaseCost","text":"Base class for all segment cost classes. Notes All classes should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ).","title":"BaseCost"},{"location":"code-reference/base-reference/#ruptures.base.BaseCost.error","text":"Returns the cost on segment [start:end]. Source code in ruptures/base.py @abc . abstractmethod def error ( self , start , end ): \"\"\"Returns the cost on segment [start:end].\"\"\" pass","title":"error()"},{"location":"code-reference/base-reference/#ruptures.base.BaseCost.fit","text":"Set the parameters of the cost function, for instance the Gram matrix, etc. Source code in ruptures/base.py @abc . abstractmethod def fit ( self , * args , ** kwargs ): \"\"\"Set the parameters of the cost function, for instance the Gram matrix, etc.\"\"\" pass","title":"fit()"},{"location":"code-reference/base-reference/#ruptures.base.BaseCost.sum_of_costs","text":"Returns the sum of segments cost for the given segmentation. Parameters: Name Type Description Default bkps list list of change points. By convention, bkps[-1]==n_samples. required Returns: Type Description float sum of costs Source code in ruptures/base.py def sum_of_costs ( self , bkps ): \"\"\"Returns the sum of segments cost for the given segmentation. Args: bkps (list): list of change points. By convention, bkps[-1]==n_samples. Returns: float: sum of costs \"\"\" soc = sum ( self . error ( start , end ) for start , end in pairwise ([ 0 ] + bkps )) return soc","title":"sum_of_costs()"},{"location":"code-reference/base-reference/#ruptures.base.BaseEstimator","text":"Base class for all change point detection estimators. Notes All estimators should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ).","title":"BaseEstimator"},{"location":"code-reference/base-reference/#ruptures.base.BaseEstimator.fit","text":"To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def fit ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass","title":"fit()"},{"location":"code-reference/base-reference/#ruptures.base.BaseEstimator.fit_predict","text":"To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def fit_predict ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass","title":"fit_predict()"},{"location":"code-reference/base-reference/#ruptures.base.BaseEstimator.predict","text":"To call the segmentation algorithm. Source code in ruptures/base.py @abc . abstractmethod def predict ( self , * args , ** kwargs ): \"\"\"To call the segmentation algorithm.\"\"\" pass","title":"predict()"},{"location":"code-reference/costs/costautoregressive-reference/","text":"Autoregressive model change (CostAutoregressive) # ruptures.costs.costautoregressive # CostAR # Least-squares estimate for changes in autoregressive coefficients. __init__ ( self , order = 4 ) special # Initialize the object. Parameters: Name Type Description Default order int autoregressive order 4 Source code in ruptures/costs/costautoregressive.py def __init__ ( self , order = 4 ): \"\"\"Initialize the object. Args: order (int): autoregressive order \"\"\" self . signal = None self . covar = None self . min_size = max ( 5 , order + 1 ) self . order = order error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than 'min_size' samples). Source code in ruptures/costs/costautoregressive.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than ``'min_size'`` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints y , X = self . signal [ start : end ], self . covar [ start : end ] _ , residual , _ , _ = lstsq ( X , y , rcond = None ) return residual . sum () fit ( self , signal ) # Set parameters of the instance. The signal must be 1D. Parameters: Name Type Description Default signal array 1d signal. Shape (n_samples, 1) or (n_samples,). required Returns: Type Description self the current object Source code in ruptures/costs/costautoregressive.py def fit ( self , signal ): \"\"\"Set parameters of the instance. The signal must be 1D. Args: signal (array): 1d signal. Shape (n_samples, 1) or (n_samples,). Returns: self: the current object \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal # lagged covariates n_samples , _ = self . signal . shape strides = ( self . signal . itemsize , self . signal . itemsize ) shape = ( n_samples - self . order , self . order ) lagged = as_strided ( self . signal , shape = shape , strides = strides ) # pad the first columns lagged_after_padding = np . pad ( lagged , (( self . order , 0 ), ( 0 , 0 )), mode = \"edge\" ) # add intercept self . covar = np . c_ [ lagged_after_padding , np . ones ( n_samples )] # pad signal on the edges self . signal [: self . order ] = self . signal [ self . order ] return self","title":"CostAR"},{"location":"code-reference/costs/costautoregressive-reference/#autoregressive-model-change-costautoregressive","text":"","title":"Autoregressive model change (CostAutoregressive)"},{"location":"code-reference/costs/costautoregressive-reference/#ruptures.costs.costautoregressive","text":"","title":"costautoregressive"},{"location":"code-reference/costs/costautoregressive-reference/#ruptures.costs.costautoregressive.CostAR","text":"Least-squares estimate for changes in autoregressive coefficients.","title":"CostAR"},{"location":"code-reference/costs/costautoregressive-reference/#ruptures.costs.costautoregressive.CostAR.__init__","text":"Initialize the object. Parameters: Name Type Description Default order int autoregressive order 4 Source code in ruptures/costs/costautoregressive.py def __init__ ( self , order = 4 ): \"\"\"Initialize the object. Args: order (int): autoregressive order \"\"\" self . signal = None self . covar = None self . min_size = max ( 5 , order + 1 ) self . order = order","title":"__init__()"},{"location":"code-reference/costs/costautoregressive-reference/#ruptures.costs.costautoregressive.CostAR.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than 'min_size' samples). Source code in ruptures/costs/costautoregressive.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than ``'min_size'`` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints y , X = self . signal [ start : end ], self . covar [ start : end ] _ , residual , _ , _ = lstsq ( X , y , rcond = None ) return residual . sum ()","title":"error()"},{"location":"code-reference/costs/costautoregressive-reference/#ruptures.costs.costautoregressive.CostAR.fit","text":"Set parameters of the instance. The signal must be 1D. Parameters: Name Type Description Default signal array 1d signal. Shape (n_samples, 1) or (n_samples,). required Returns: Type Description self the current object Source code in ruptures/costs/costautoregressive.py def fit ( self , signal ): \"\"\"Set parameters of the instance. The signal must be 1D. Args: signal (array): 1d signal. Shape (n_samples, 1) or (n_samples,). Returns: self: the current object \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal # lagged covariates n_samples , _ = self . signal . shape strides = ( self . signal . itemsize , self . signal . itemsize ) shape = ( n_samples - self . order , self . order ) lagged = as_strided ( self . signal , shape = shape , strides = strides ) # pad the first columns lagged_after_padding = np . pad ( lagged , (( self . order , 0 ), ( 0 , 0 )), mode = \"edge\" ) # add intercept self . covar = np . c_ [ lagged_after_padding , np . ones ( n_samples )] # pad signal on the edges self . signal [: self . order ] = self . signal [ self . order ] return self","title":"fit()"},{"location":"code-reference/costs/costclinear-reference/","text":"Continuous linear change (CostCLinear) # ruptures.costs.costclinear.CostCLinear # Piecewise linear approximation with a continuity constraint. __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costclinear.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 3 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost (float) Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costclinear.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost (float) Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints if start == 0 : start = 1 sub = self . signal [ start : end ] slope = ( self . signal [ end - 1 ] - self . signal [ start - 1 ]) / ( end - start ) intercept = self . signal [ start - 1 ] approx = slope . reshape ( - 1 , 1 ) * np . arange ( 1 , end - start + 1 ) + intercept . reshape ( - 1 , 1 ) return np . sum (( sub - approx . transpose ()) ** 2 ) fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array signal of shape (n_samples, n_dims) or (n_samples,) required Returns: Type Description CostCLinear self Source code in ruptures/costs/costclinear.py def fit ( self , signal ) -> \"CostCLinear\" : \"\"\"Set parameters of the instance. Args: signal (array): signal of shape (n_samples, n_dims) or (n_samples,) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"CostCLinear"},{"location":"code-reference/costs/costclinear-reference/#continuous-linear-change-costclinear","text":"","title":"Continuous linear change (CostCLinear)"},{"location":"code-reference/costs/costclinear-reference/#ruptures.costs.costclinear.CostCLinear","text":"Piecewise linear approximation with a continuity constraint.","title":"CostCLinear"},{"location":"code-reference/costs/costclinear-reference/#ruptures.costs.costclinear.CostCLinear.__init__","text":"Initialize the object. Source code in ruptures/costs/costclinear.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 3","title":"__init__()"},{"location":"code-reference/costs/costclinear-reference/#ruptures.costs.costclinear.CostCLinear.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost (float) Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costclinear.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost (float) Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints if start == 0 : start = 1 sub = self . signal [ start : end ] slope = ( self . signal [ end - 1 ] - self . signal [ start - 1 ]) / ( end - start ) intercept = self . signal [ start - 1 ] approx = slope . reshape ( - 1 , 1 ) * np . arange ( 1 , end - start + 1 ) + intercept . reshape ( - 1 , 1 ) return np . sum (( sub - approx . transpose ()) ** 2 )","title":"error()"},{"location":"code-reference/costs/costclinear-reference/#ruptures.costs.costclinear.CostCLinear.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array signal of shape (n_samples, n_dims) or (n_samples,) required Returns: Type Description CostCLinear self Source code in ruptures/costs/costclinear.py def fit ( self , signal ) -> \"CostCLinear\" : \"\"\"Set parameters of the instance. Args: signal (array): signal of shape (n_samples, n_dims) or (n_samples,) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costcosine-reference/","text":"Kernelized mean change (CostCosine) # ruptures.costs.costcosine.CostCosine # Kernel change point detection with the cosine similarity. gram property readonly # Generate the gram matrix (lazy loading). Only access this function after a .fit() (otherwise self.signal is not defined). __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costcosine.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 1 self . _gram = None error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costcosine.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array array of shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostCosine self Source code in ruptures/costs/costcosine.py def fit ( self , signal ) -> \"CostCosine\" : \"\"\"Set parameters of the instance. Args: signal (array): array of shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"CostCosine"},{"location":"code-reference/costs/costcosine-reference/#kernelized-mean-change-costcosine","text":"","title":"Kernelized mean change (CostCosine)"},{"location":"code-reference/costs/costcosine-reference/#ruptures.costs.costcosine.CostCosine","text":"Kernel change point detection with the cosine similarity.","title":"CostCosine"},{"location":"code-reference/costs/costcosine-reference/#ruptures.costs.costcosine.CostCosine.gram","text":"Generate the gram matrix (lazy loading). Only access this function after a .fit() (otherwise self.signal is not defined).","title":"gram"},{"location":"code-reference/costs/costcosine-reference/#ruptures.costs.costcosine.CostCosine.__init__","text":"Initialize the object. Source code in ruptures/costs/costcosine.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 1 self . _gram = None","title":"__init__()"},{"location":"code-reference/costs/costcosine-reference/#ruptures.costs.costcosine.CostCosine.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costcosine.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val","title":"error()"},{"location":"code-reference/costs/costcosine-reference/#ruptures.costs.costcosine.CostCosine.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array array of shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostCosine self Source code in ruptures/costs/costcosine.py def fit ( self , signal ) -> \"CostCosine\" : \"\"\"Set parameters of the instance. Args: signal (array): array of shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costl1-reference/","text":"CostL1 (least absolute deviation) # ruptures.costs.costl1.CostL1 # Least absolute deviation. __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costl1.py def __init__ ( self ) -> None : \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costl1.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub = self . signal [ start : end ] med = np . median ( sub , axis = 0 ) return abs ( sub - med ) . sum () fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostL1 self Source code in ruptures/costs/costl1.py def fit ( self , signal ) -> \"CostL1\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"CostL1"},{"location":"code-reference/costs/costl1-reference/#costl1-least-absolute-deviation","text":"","title":"CostL1 (least absolute deviation)"},{"location":"code-reference/costs/costl1-reference/#ruptures.costs.costl1.CostL1","text":"Least absolute deviation.","title":"CostL1"},{"location":"code-reference/costs/costl1-reference/#ruptures.costs.costl1.CostL1.__init__","text":"Initialize the object. Source code in ruptures/costs/costl1.py def __init__ ( self ) -> None : \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costl1-reference/#ruptures.costs.costl1.CostL1.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costl1.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub = self . signal [ start : end ] med = np . median ( sub , axis = 0 ) return abs ( sub - med ) . sum ()","title":"error()"},{"location":"code-reference/costs/costl1-reference/#ruptures.costs.costl1.CostL1.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostL1 self Source code in ruptures/costs/costl1.py def fit ( self , signal ) -> \"CostL1\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costl2-reference/","text":"CostL2 (least squared deviation) # ruptures.costs.costl2.CostL2 # Least squared deviation. __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costl2.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costl2.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints return self . signal [ start : end ] . var ( axis = 0 ) . sum () * ( end - start ) fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array array of shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostL2 self Source code in ruptures/costs/costl2.py def fit ( self , signal ) -> \"CostL2\" : \"\"\"Set parameters of the instance. Args: signal (array): array of shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"CostL2"},{"location":"code-reference/costs/costl2-reference/#costl2-least-squared-deviation","text":"","title":"CostL2 (least squared deviation)"},{"location":"code-reference/costs/costl2-reference/#ruptures.costs.costl2.CostL2","text":"Least squared deviation.","title":"CostL2"},{"location":"code-reference/costs/costl2-reference/#ruptures.costs.costl2.CostL2.__init__","text":"Initialize the object. Source code in ruptures/costs/costl2.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costl2-reference/#ruptures.costs.costl2.CostL2.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costl2.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints return self . signal [ start : end ] . var ( axis = 0 ) . sum () * ( end - start )","title":"error()"},{"location":"code-reference/costs/costl2-reference/#ruptures.costs.costl2.CostL2.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array array of shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostL2 self Source code in ruptures/costs/costl2.py def fit ( self , signal ) -> \"CostL2\" : \"\"\"Set parameters of the instance. Args: signal (array): array of shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costlinear-reference/","text":"Linear model change (CostLinear) # ruptures.costs.costlinear.CostLinear # Least-square estimate for linear changes. __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costlinear.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . covar = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costlinear.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints y , X = self . signal [ start : end ], self . covar [ start : end ] _ , residual , _ , _ = lstsq ( X , y , rcond = None ) return residual . sum () fit ( self , signal ) # Set parameters of the instance. The first column contains the observed variable. The other columns contains the covariates. Parameters: Name Type Description Default signal array signal of shape (n_samples, n_regressors+1) required Returns: Type Description CostLinear self Source code in ruptures/costs/costlinear.py def fit ( self , signal ) -> \"CostLinear\" : \"\"\"Set parameters of the instance. The first column contains the observed variable. The other columns contains the covariates. Args: signal (array): signal of shape (n_samples, n_regressors+1) Returns: self \"\"\" assert signal . ndim > 1 , \"Not enough dimensions\" self . signal = signal [:, 0 ] . reshape ( - 1 , 1 ) self . covar = signal [:, 1 :] return self","title":"CostLinear"},{"location":"code-reference/costs/costlinear-reference/#linear-model-change-costlinear","text":"","title":"Linear model change (CostLinear)"},{"location":"code-reference/costs/costlinear-reference/#ruptures.costs.costlinear.CostLinear","text":"Least-square estimate for linear changes.","title":"CostLinear"},{"location":"code-reference/costs/costlinear-reference/#ruptures.costs.costlinear.CostLinear.__init__","text":"Initialize the object. Source code in ruptures/costs/costlinear.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . covar = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costlinear-reference/#ruptures.costs.costlinear.CostLinear.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costlinear.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints y , X = self . signal [ start : end ], self . covar [ start : end ] _ , residual , _ , _ = lstsq ( X , y , rcond = None ) return residual . sum ()","title":"error()"},{"location":"code-reference/costs/costlinear-reference/#ruptures.costs.costlinear.CostLinear.fit","text":"Set parameters of the instance. The first column contains the observed variable. The other columns contains the covariates. Parameters: Name Type Description Default signal array signal of shape (n_samples, n_regressors+1) required Returns: Type Description CostLinear self Source code in ruptures/costs/costlinear.py def fit ( self , signal ) -> \"CostLinear\" : \"\"\"Set parameters of the instance. The first column contains the observed variable. The other columns contains the covariates. Args: signal (array): signal of shape (n_samples, n_regressors+1) Returns: self \"\"\" assert signal . ndim > 1 , \"Not enough dimensions\" self . signal = signal [:, 0 ] . reshape ( - 1 , 1 ) self . covar = signal [:, 1 :] return self","title":"fit()"},{"location":"code-reference/costs/costml-reference/","text":"Mahalanobis-type change (CostMl) # ruptures.costs.costml.CostMl # Mahalanobis-type cost function. __init__ ( self , metric = None ) special # Create a new instance. Parameters: Name Type Description Default metric ndarray PSD matrix that defines a Mahalanobis-type pseudo distance. If None, defaults to the Mahalanobis matrix. Shape (n_features, n_features). None Source code in ruptures/costs/costml.py def __init__ ( self , metric = None ): \"\"\"Create a new instance. Args: metric (ndarray, optional): PSD matrix that defines a Mahalanobis-type pseudo distance. If None, defaults to the Mahalanobis matrix. Shape (n_features, n_features). \"\"\" self . metric = metric self . gram = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than 'min_size' samples). Source code in ruptures/costs/costml.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than ``'min_size'`` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostMl self Source code in ruptures/costs/costml.py def fit ( self , signal ) -> \"CostMl\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" s_ = signal . reshape ( - 1 , 1 ) if signal . ndim == 1 else signal # Mahalanobis metric if self.metric is None if self . metric is None : covar = np . cov ( s_ . T ) self . metric = inv ( covar . reshape ( 1 , 1 ) if covar . size == 1 else covar ) self . gram = s_ . dot ( self . metric ) . dot ( s_ . T ) return self","title":"CostMl"},{"location":"code-reference/costs/costml-reference/#mahalanobis-type-change-costml","text":"","title":"Mahalanobis-type change (CostMl)"},{"location":"code-reference/costs/costml-reference/#ruptures.costs.costml.CostMl","text":"Mahalanobis-type cost function.","title":"CostMl"},{"location":"code-reference/costs/costml-reference/#ruptures.costs.costml.CostMl.__init__","text":"Create a new instance. Parameters: Name Type Description Default metric ndarray PSD matrix that defines a Mahalanobis-type pseudo distance. If None, defaults to the Mahalanobis matrix. Shape (n_features, n_features). None Source code in ruptures/costs/costml.py def __init__ ( self , metric = None ): \"\"\"Create a new instance. Args: metric (ndarray, optional): PSD matrix that defines a Mahalanobis-type pseudo distance. If None, defaults to the Mahalanobis matrix. Shape (n_features, n_features). \"\"\" self . metric = metric self . gram = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costml-reference/#ruptures.costs.costml.CostMl.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than 'min_size' samples). Source code in ruptures/costs/costml.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than ``'min_size'`` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val","title":"error()"},{"location":"code-reference/costs/costml-reference/#ruptures.costs.costml.CostMl.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostMl self Source code in ruptures/costs/costml.py def fit ( self , signal ) -> \"CostMl\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" s_ = signal . reshape ( - 1 , 1 ) if signal . ndim == 1 else signal # Mahalanobis metric if self.metric is None if self . metric is None : covar = np . cov ( s_ . T ) self . metric = inv ( covar . reshape ( 1 , 1 ) if covar . size == 1 else covar ) self . gram = s_ . dot ( self . metric ) . dot ( s_ . T ) return self","title":"fit()"},{"location":"code-reference/costs/costnormal-reference/","text":"Gaussian process change (CostNormal) # ruptures.costs.costnormal.CostNormal # Gaussian process change. __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costnormal.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costnormal.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub = self . signal [ start : end ] if self . signal . shape [ 1 ] > 1 : cov = np . cov ( sub . T ) else : cov = np . array ([[ sub . var ()]]) _ , val = slogdet ( cov ) return val * ( end - start ) fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostNormal self Source code in ruptures/costs/costnormal.py def fit ( self , signal ) -> \"CostNormal\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"CostNormal"},{"location":"code-reference/costs/costnormal-reference/#gaussian-process-change-costnormal","text":"","title":"Gaussian process change (CostNormal)"},{"location":"code-reference/costs/costnormal-reference/#ruptures.costs.costnormal.CostNormal","text":"Gaussian process change.","title":"CostNormal"},{"location":"code-reference/costs/costnormal-reference/#ruptures.costs.costnormal.CostNormal.__init__","text":"Initialize the object. Source code in ruptures/costs/costnormal.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . signal = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costnormal-reference/#ruptures.costs.costnormal.CostNormal.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costnormal.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub = self . signal [ start : end ] if self . signal . shape [ 1 ] > 1 : cov = np . cov ( sub . T ) else : cov = np . array ([[ sub . var ()]]) _ , val = slogdet ( cov ) return val * ( end - start )","title":"error()"},{"location":"code-reference/costs/costnormal-reference/#ruptures.costs.costnormal.CostNormal.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostNormal self Source code in ruptures/costs/costnormal.py def fit ( self , signal ) -> \"CostNormal\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costrank-reference/","text":"Rank-based change (CostRank) # ruptures.costs.costrank.CostRank # Rank-based cost function __init__ ( self ) special # Initialize the object. Source code in ruptures/costs/costrank.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . inv_cov = None self . ranks = None self . min_size = 2 error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costrank.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints mean = np . reshape ( np . mean ( self . ranks [ start : end ], axis = 0 ), ( - 1 , 1 )) return - ( end - start ) * mean . T @ self . inv_cov @ mean fit ( self , signal ) # Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostRank self Source code in ruptures/costs/costrank.py def fit ( self , signal ) -> \"CostRank\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : signal = signal . reshape ( - 1 , 1 ) obs , vars = signal . shape # Convert signal data into ranks in the range [1, n] ranks = rankdata ( signal , axis = 0 ) # Center the ranks into the range [-(n+1)/2, (n+1)/2] centered_ranks = ranks - (( obs + 1 ) / 2 ) # Sigma is the covariance of these ranks. # If it's a scalar, reshape it into a 1x1 matrix cov = np . cov ( centered_ranks , rowvar = False , bias = True ) . reshape ( vars , vars ) # Use the pseudoinverse to handle linear dependencies # see Lung-Yut-Fong, A., L\u00e9vy-Leduc, C., & Capp\u00e9, O. (2015) try : self . inv_cov = pinv ( cov ) except LinAlgError as e : raise LinAlgError ( \"The covariance matrix of the rank signal is not invertible and the \" \"pseudo-inverse computation did not converge.\" ) from e self . ranks = centered_ranks self . signal = signal return self","title":"CostRank"},{"location":"code-reference/costs/costrank-reference/#rank-based-change-costrank","text":"","title":"Rank-based change (CostRank)"},{"location":"code-reference/costs/costrank-reference/#ruptures.costs.costrank.CostRank","text":"Rank-based cost function","title":"CostRank"},{"location":"code-reference/costs/costrank-reference/#ruptures.costs.costrank.CostRank.__init__","text":"Initialize the object. Source code in ruptures/costs/costrank.py def __init__ ( self ): \"\"\"Initialize the object.\"\"\" self . inv_cov = None self . ranks = None self . min_size = 2","title":"__init__()"},{"location":"code-reference/costs/costrank-reference/#ruptures.costs.costrank.CostRank.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costrank.py def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints mean = np . reshape ( np . mean ( self . ranks [ start : end ], axis = 0 ), ( - 1 , 1 )) return - ( end - start ) * mean . T @ self . inv_cov @ mean","title":"error()"},{"location":"code-reference/costs/costrank-reference/#ruptures.costs.costrank.CostRank.fit","text":"Set parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostRank self Source code in ruptures/costs/costrank.py def fit ( self , signal ) -> \"CostRank\" : \"\"\"Set parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : signal = signal . reshape ( - 1 , 1 ) obs , vars = signal . shape # Convert signal data into ranks in the range [1, n] ranks = rankdata ( signal , axis = 0 ) # Center the ranks into the range [-(n+1)/2, (n+1)/2] centered_ranks = ranks - (( obs + 1 ) / 2 ) # Sigma is the covariance of these ranks. # If it's a scalar, reshape it into a 1x1 matrix cov = np . cov ( centered_ranks , rowvar = False , bias = True ) . reshape ( vars , vars ) # Use the pseudoinverse to handle linear dependencies # see Lung-Yut-Fong, A., L\u00e9vy-Leduc, C., & Capp\u00e9, O. (2015) try : self . inv_cov = pinv ( cov ) except LinAlgError as e : raise LinAlgError ( \"The covariance matrix of the rank signal is not invertible and the \" \"pseudo-inverse computation did not converge.\" ) from e self . ranks = centered_ranks self . signal = signal return self","title":"fit()"},{"location":"code-reference/costs/costrbf-reference/","text":"Kernelized mean change (CostRbf) # ruptures.costs.costrbf.CostRbf # Kernel cost function (rbf kernel). gram property readonly # Generate the gram matrix (lazy loading). Only access this function after a .fit() (otherwise self.signal is not defined). __init__ ( self , gamma = None ) special # Initialize the object. Source code in ruptures/costs/costrbf.py def __init__ ( self , gamma = None ): \"\"\"Initialize the object.\"\"\" self . min_size = 2 self . gamma = gamma self . _gram = None error ( self , start , end ) # Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costrbf.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val fit ( self , signal ) # Sets parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostRbf self Source code in ruptures/costs/costrbf.py def fit ( self , signal ) -> \"CostRbf\" : \"\"\"Sets parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal # If gamma is none, set it using the median heuristic. # This heuristic involves computing the gram matrix which is lazy loaded # so we simply access the `.gram` property if self . gamma is None : self . gram return self","title":"CostRbf"},{"location":"code-reference/costs/costrbf-reference/#kernelized-mean-change-costrbf","text":"","title":"Kernelized mean change (CostRbf)"},{"location":"code-reference/costs/costrbf-reference/#ruptures.costs.costrbf.CostRbf","text":"Kernel cost function (rbf kernel).","title":"CostRbf"},{"location":"code-reference/costs/costrbf-reference/#ruptures.costs.costrbf.CostRbf.gram","text":"Generate the gram matrix (lazy loading). Only access this function after a .fit() (otherwise self.signal is not defined).","title":"gram"},{"location":"code-reference/costs/costrbf-reference/#ruptures.costs.costrbf.CostRbf.__init__","text":"Initialize the object. Source code in ruptures/costs/costrbf.py def __init__ ( self , gamma = None ): \"\"\"Initialize the object.\"\"\" self . min_size = 2 self . gamma = gamma self . _gram = None","title":"__init__()"},{"location":"code-reference/costs/costrbf-reference/#ruptures.costs.costrbf.CostRbf.error","text":"Return the approximation cost on the segment [start:end]. Parameters: Name Type Description Default start int start of the segment required end int end of the segment required Returns: Type Description float segment cost Exceptions: Type Description NotEnoughPoints when the segment is too short (less than min_size samples). Source code in ruptures/costs/costrbf.py def error ( self , start , end ) -> float : \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: segment cost Raises: NotEnoughPoints: when the segment is too short (less than `min_size` samples). \"\"\" if end - start < self . min_size : raise NotEnoughPoints sub_gram = self . gram [ start : end , start : end ] val = np . diagonal ( sub_gram ) . sum () val -= sub_gram . sum () / ( end - start ) return val","title":"error()"},{"location":"code-reference/costs/costrbf-reference/#ruptures.costs.costrbf.CostRbf.fit","text":"Sets parameters of the instance. Parameters: Name Type Description Default signal array signal. Shape (n_samples,) or (n_samples, n_features) required Returns: Type Description CostRbf self Source code in ruptures/costs/costrbf.py def fit ( self , signal ) -> \"CostRbf\" : \"\"\"Sets parameters of the instance. Args: signal (array): signal. Shape (n_samples,) or (n_samples, n_features) Returns: self \"\"\" if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal # If gamma is none, set it using the median heuristic. # This heuristic involves computing the gram matrix which is lazy loaded # so we simply access the `.gram` property if self . gamma is None : self . gram return self","title":"fit()"},{"location":"code-reference/datasets/pw_constant-reference/","text":"Piecewise constant (pw_constant) # ruptures . datasets . pw_constant . pw_constant ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None , delta = ( 1 , 10 ), seed = None ) # Return a piecewise constant signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_features int number of dimensions 1 n_bkps int number of changepoints 3 noise_std float noise std. If None, no noise is added None delta tuple (delta_min, delta_max) max and min jump values (1, 10) seed int random seed None Returns: Type Description tuple signal of shape (n_samples, n_features), list of breakpoints Source code in ruptures/datasets/pw_constant.py def pw_constant ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None , delta = ( 1 , 10 ), seed = None ): \"\"\"Return a piecewise constant signal and the associated changepoints. Args: n_samples (int): signal length n_features (int, optional): number of dimensions n_bkps (int, optional): number of changepoints noise_std (float, optional): noise std. If None, no noise is added delta (tuple, optional): (delta_min, delta_max) max and min jump values seed (int): random seed Returns: tuple: signal of shape (n_samples, n_features), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal signal = np . empty (( n_samples , n_features ), dtype = float ) tt_ = np . arange ( n_samples ) delta_min , delta_max = delta # mean value center = np . zeros ( n_features ) rd = RandomState ( seed ) for ind in np . split ( tt_ , bkps ): if ind . size > 0 : # jump value jump = rd . uniform ( delta_min , delta_max , size = n_features ) spin = rd . choice ([ - 1 , 1 ], n_features ) center += jump * spin signal [ ind ] = center if noise_std is not None : noise = rd . normal ( size = signal . shape ) * noise_std signal = signal + noise return signal , bkps","title":"Piecewise constant"},{"location":"code-reference/datasets/pw_constant-reference/#piecewise-constant-pw_constant","text":"","title":"Piecewise constant (pw_constant)"},{"location":"code-reference/datasets/pw_constant-reference/#ruptures.datasets.pw_constant.pw_constant","text":"Return a piecewise constant signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_features int number of dimensions 1 n_bkps int number of changepoints 3 noise_std float noise std. If None, no noise is added None delta tuple (delta_min, delta_max) max and min jump values (1, 10) seed int random seed None Returns: Type Description tuple signal of shape (n_samples, n_features), list of breakpoints Source code in ruptures/datasets/pw_constant.py def pw_constant ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None , delta = ( 1 , 10 ), seed = None ): \"\"\"Return a piecewise constant signal and the associated changepoints. Args: n_samples (int): signal length n_features (int, optional): number of dimensions n_bkps (int, optional): number of changepoints noise_std (float, optional): noise std. If None, no noise is added delta (tuple, optional): (delta_min, delta_max) max and min jump values seed (int): random seed Returns: tuple: signal of shape (n_samples, n_features), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal signal = np . empty (( n_samples , n_features ), dtype = float ) tt_ = np . arange ( n_samples ) delta_min , delta_max = delta # mean value center = np . zeros ( n_features ) rd = RandomState ( seed ) for ind in np . split ( tt_ , bkps ): if ind . size > 0 : # jump value jump = rd . uniform ( delta_min , delta_max , size = n_features ) spin = rd . choice ([ - 1 , 1 ], n_features ) center += jump * spin signal [ ind ] = center if noise_std is not None : noise = rd . normal ( size = signal . shape ) * noise_std signal = signal + noise return signal , bkps","title":"pw_constant()"},{"location":"code-reference/datasets/pw_linear-reference/","text":"Piecewise linear (pw_linear) # ruptures . datasets . pw_linear . pw_linear ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None ) # Return piecewise linear signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_features int number of covariates 1 n_bkps int number of change points 3 noise_std float noise std. If None, no noise is added None Returns: Type Description tuple signal of shape (n_samples, n_features+1), list of breakpoints Source code in ruptures/datasets/pw_linear.py def pw_linear ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None ): \"\"\"Return piecewise linear signal and the associated changepoints. Args: n_samples (int, optional): signal length n_features (int, optional): number of covariates n_bkps (int, optional): number of change points noise_std (float, optional): noise std. If None, no noise is added Returns: tuple: signal of shape (n_samples, n_features+1), list of breakpoints \"\"\" covar = normal ( size = ( n_samples , n_features )) linear_coeff , bkps = pw_constant ( n_samples = n_samples , n_bkps = n_bkps , n_features = n_features , noise_std = None ) var = np . sum ( linear_coeff * covar , axis = 1 ) if noise_std is not None : var += normal ( scale = noise_std , size = var . shape ) signal = np . c_ [ var , covar ] return signal , bkps","title":"Piecewise linear"},{"location":"code-reference/datasets/pw_linear-reference/#piecewise-linear-pw_linear","text":"","title":"Piecewise linear (pw_linear)"},{"location":"code-reference/datasets/pw_linear-reference/#ruptures.datasets.pw_linear.pw_linear","text":"Return piecewise linear signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_features int number of covariates 1 n_bkps int number of change points 3 noise_std float noise std. If None, no noise is added None Returns: Type Description tuple signal of shape (n_samples, n_features+1), list of breakpoints Source code in ruptures/datasets/pw_linear.py def pw_linear ( n_samples = 200 , n_features = 1 , n_bkps = 3 , noise_std = None ): \"\"\"Return piecewise linear signal and the associated changepoints. Args: n_samples (int, optional): signal length n_features (int, optional): number of covariates n_bkps (int, optional): number of change points noise_std (float, optional): noise std. If None, no noise is added Returns: tuple: signal of shape (n_samples, n_features+1), list of breakpoints \"\"\" covar = normal ( size = ( n_samples , n_features )) linear_coeff , bkps = pw_constant ( n_samples = n_samples , n_bkps = n_bkps , n_features = n_features , noise_std = None ) var = np . sum ( linear_coeff * covar , axis = 1 ) if noise_std is not None : var += normal ( scale = noise_std , size = var . shape ) signal = np . c_ [ var , covar ] return signal , bkps","title":"pw_linear()"},{"location":"code-reference/datasets/pw_normal-reference/","text":"Piecewise Gaussian (pw_normal) # ruptures . datasets . pw_normal . pw_normal ( n_samples = 200 , n_bkps = 3 ) # Return a 2D piecewise Gaussian signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_bkps int number of change points 3 Returns: Type Description tuple signal of shape (n_samples, 2), list of breakpoints Source code in ruptures/datasets/pw_normal.py def pw_normal ( n_samples = 200 , n_bkps = 3 ): \"\"\"Return a 2D piecewise Gaussian signal and the associated changepoints. Args: n_samples (int, optional): signal length n_bkps (int, optional): number of change points Returns: tuple: signal of shape (n_samples, 2), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal signal = np . zeros (( n_samples , 2 ), dtype = float ) cov1 = np . array ([[ 1 , 0.9 ], [ 0.9 , 1 ]]) cov2 = np . array ([[ 1 , - 0.9 ], [ - 0.9 , 1 ]]) for sub , cov in zip ( np . split ( signal , bkps ), cycle (( cov1 , cov2 ))): n_sub , _ = sub . shape sub += rd . multivariate_normal ([ 0 , 0 ], cov , size = n_sub ) return signal , bkps","title":"Piecewise normal"},{"location":"code-reference/datasets/pw_normal-reference/#piecewise-gaussian-pw_normal","text":"","title":"Piecewise Gaussian (pw_normal)"},{"location":"code-reference/datasets/pw_normal-reference/#ruptures.datasets.pw_normal.pw_normal","text":"Return a 2D piecewise Gaussian signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_bkps int number of change points 3 Returns: Type Description tuple signal of shape (n_samples, 2), list of breakpoints Source code in ruptures/datasets/pw_normal.py def pw_normal ( n_samples = 200 , n_bkps = 3 ): \"\"\"Return a 2D piecewise Gaussian signal and the associated changepoints. Args: n_samples (int, optional): signal length n_bkps (int, optional): number of change points Returns: tuple: signal of shape (n_samples, 2), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal signal = np . zeros (( n_samples , 2 ), dtype = float ) cov1 = np . array ([[ 1 , 0.9 ], [ 0.9 , 1 ]]) cov2 = np . array ([[ 1 , - 0.9 ], [ - 0.9 , 1 ]]) for sub , cov in zip ( np . split ( signal , bkps ), cycle (( cov1 , cov2 ))): n_sub , _ = sub . shape sub += rd . multivariate_normal ([ 0 , 0 ], cov , size = n_sub ) return signal , bkps","title":"pw_normal()"},{"location":"code-reference/datasets/pw_wavy-reference/","text":"Piecewise wavy (pw_wavy) # ruptures . datasets . pw_wavy . pw_wavy ( n_samples = 200 , n_bkps = 3 , noise_std = None ) # Return a 1D piecewise wavy signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_bkps int number of changepoints 3 noise_std float noise std. If None, no noise is added None Returns: Type Description tuple signal of shape (n_samples, 1), list of breakpoints Source code in ruptures/datasets/pw_wavy.py def pw_wavy ( n_samples = 200 , n_bkps = 3 , noise_std = None ): \"\"\"Return a 1D piecewise wavy signal and the associated changepoints. Args: n_samples (int, optional): signal length n_bkps (int, optional): number of changepoints noise_std (float, optional): noise std. If None, no noise is added Returns: tuple: signal of shape (n_samples, 1), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal f1 = np . array ([ 0.075 , 0.1 ]) f2 = np . array ([ 0.1 , 0.125 ]) freqs = np . zeros (( n_samples , 2 )) for sub , val in zip ( np . split ( freqs , bkps [: - 1 ]), cycle ([ f1 , f2 ])): sub += val tt = np . arange ( n_samples ) # DeprecationWarning: Calling np.sum(generator) is deprecated # Use np.sum(np.from_iter(generator)) or the python sum builtin instead. signal = np . sum ([ np . sin ( 2 * np . pi * tt * f ) for f in freqs . T ], axis = 0 ) if noise_std is not None : noise = normal ( scale = noise_std , size = signal . shape ) signal += noise return signal , bkps","title":"Piecewise wavy"},{"location":"code-reference/datasets/pw_wavy-reference/#piecewise-wavy-pw_wavy","text":"","title":"Piecewise wavy (pw_wavy)"},{"location":"code-reference/datasets/pw_wavy-reference/#ruptures.datasets.pw_wavy.pw_wavy","text":"Return a 1D piecewise wavy signal and the associated changepoints. Parameters: Name Type Description Default n_samples int signal length 200 n_bkps int number of changepoints 3 noise_std float noise std. If None, no noise is added None Returns: Type Description tuple signal of shape (n_samples, 1), list of breakpoints Source code in ruptures/datasets/pw_wavy.py def pw_wavy ( n_samples = 200 , n_bkps = 3 , noise_std = None ): \"\"\"Return a 1D piecewise wavy signal and the associated changepoints. Args: n_samples (int, optional): signal length n_bkps (int, optional): number of changepoints noise_std (float, optional): noise std. If None, no noise is added Returns: tuple: signal of shape (n_samples, 1), list of breakpoints \"\"\" # breakpoints bkps = draw_bkps ( n_samples , n_bkps ) # we create the signal f1 = np . array ([ 0.075 , 0.1 ]) f2 = np . array ([ 0.1 , 0.125 ]) freqs = np . zeros (( n_samples , 2 )) for sub , val in zip ( np . split ( freqs , bkps [: - 1 ]), cycle ([ f1 , f2 ])): sub += val tt = np . arange ( n_samples ) # DeprecationWarning: Calling np.sum(generator) is deprecated # Use np.sum(np.from_iter(generator)) or the python sum builtin instead. signal = np . sum ([ np . sin ( 2 * np . pi * tt * f ) for f in freqs . T ], axis = 0 ) if noise_std is not None : noise = normal ( scale = noise_std , size = signal . shape ) signal += noise return signal , bkps","title":"pw_wavy()"},{"location":"code-reference/detection/binseg-reference/","text":"Binary segmentation # ruptures.detection.binseg.Binseg # Binary segmentation. __init__ ( self , model = 'l2' , custom_cost = None , min_size = 2 , jump = 5 , params = None ) special # Initialize a Binseg instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. Defaults to 2 samples. 2 jump int subsample (one every jump points). Defaults to 5 samples. 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/binseg.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a Binseg instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. Defaults to 2 samples. jump (int, optional): subsample (one every *jump* points). Defaults to 5 samples. params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None self . signal = None # cache for intermediate results self . single_bkp = lru_cache ( maxsize = None )( self . _single_bkp ) fit ( self , signal ) # Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Binseg self Source code in ruptures/detection/binseg.py def fit ( self , signal ) -> \"Binseg\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal self . n_samples , _ = self . signal . shape self . cost . fit ( signal ) self . single_bkp . cache_clear () return self fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/binseg.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) predict ( self , n_bkps = None , pen = None , epsilon = None ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/binseg.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.binseg.Binseg.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"Binseg"},{"location":"code-reference/detection/binseg-reference/#binary-segmentation","text":"","title":"Binary segmentation"},{"location":"code-reference/detection/binseg-reference/#ruptures.detection.binseg.Binseg","text":"Binary segmentation.","title":"Binseg"},{"location":"code-reference/detection/binseg-reference/#ruptures.detection.binseg.Binseg.__init__","text":"Initialize a Binseg instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. Defaults to 2 samples. 2 jump int subsample (one every jump points). Defaults to 5 samples. 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/binseg.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a Binseg instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. Defaults to 2 samples. jump (int, optional): subsample (one every *jump* points). Defaults to 5 samples. params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None self . signal = None # cache for intermediate results self . single_bkp = lru_cache ( maxsize = None )( self . _single_bkp )","title":"__init__()"},{"location":"code-reference/detection/binseg-reference/#ruptures.detection.binseg.Binseg.fit","text":"Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Binseg self Source code in ruptures/detection/binseg.py def fit ( self , signal ) -> \"Binseg\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal self . n_samples , _ = self . signal . shape self . cost . fit ( signal ) self . single_bkp . cache_clear () return self","title":"fit()"},{"location":"code-reference/detection/binseg-reference/#ruptures.detection.binseg.Binseg.fit_predict","text":"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/binseg.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon )","title":"fit_predict()"},{"location":"code-reference/detection/binseg-reference/#ruptures.detection.binseg.Binseg.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/binseg.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.binseg.Binseg.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"predict()"},{"location":"code-reference/detection/bottomup-reference/","text":"Bottom-up segmentation # ruptures.detection.bottomup.BottomUp # Bottom-up segmentation. __init__ ( self , model = 'l2' , custom_cost = None , min_size = 2 , jump = 5 , params = None ) special # Initialize a BottomUp instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. Defaults to 2 samples. 2 jump int subsample (one every jump points). Defaults to 5 samples. 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/bottomup.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a BottomUp instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. Defaults to 2 samples. jump (int, optional): subsample (one every *jump* points). Defaults to 5 samples. params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None self . signal = None self . leaves = None self . merge = lru_cache ( maxsize = None )( self . _merge ) fit ( self , signal ) # Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description BottomUp self Source code in ruptures/detection/bottomup.py def fit ( self , signal ) -> \"BottomUp\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params self . cost . fit ( signal ) self . merge . cache_clear () if signal . ndim == 1 : ( n_samples ,) = signal . shape else : n_samples , _ = signal . shape self . n_samples = n_samples self . leaves = self . _grow_tree () return self fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/bottomup.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) predict ( self , n_bkps = None , pen = None , epsilon = None ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/bottomup.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.bottomup.BottomUp.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"BottomUp"},{"location":"code-reference/detection/bottomup-reference/#bottom-up-segmentation","text":"","title":"Bottom-up segmentation"},{"location":"code-reference/detection/bottomup-reference/#ruptures.detection.bottomup.BottomUp","text":"Bottom-up segmentation.","title":"BottomUp"},{"location":"code-reference/detection/bottomup-reference/#ruptures.detection.bottomup.BottomUp.__init__","text":"Initialize a BottomUp instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. Defaults to 2 samples. 2 jump int subsample (one every jump points). Defaults to 5 samples. 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/bottomup.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a BottomUp instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. Defaults to 2 samples. jump (int, optional): subsample (one every *jump* points). Defaults to 5 samples. params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None self . signal = None self . leaves = None self . merge = lru_cache ( maxsize = None )( self . _merge )","title":"__init__()"},{"location":"code-reference/detection/bottomup-reference/#ruptures.detection.bottomup.BottomUp.fit","text":"Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description BottomUp self Source code in ruptures/detection/bottomup.py def fit ( self , signal ) -> \"BottomUp\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params self . cost . fit ( signal ) self . merge . cache_clear () if signal . ndim == 1 : ( n_samples ,) = signal . shape else : n_samples , _ = signal . shape self . n_samples = n_samples self . leaves = self . _grow_tree () return self","title":"fit()"},{"location":"code-reference/detection/bottomup-reference/#ruptures.detection.bottomup.BottomUp.fit_predict","text":"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/bottomup.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon )","title":"fit_predict()"},{"location":"code-reference/detection/bottomup-reference/#ruptures.detection.bottomup.BottomUp.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/bottomup.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.bottomup.BottomUp.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"predict()"},{"location":"code-reference/detection/dynp-reference/","text":"Dynamic programming # ruptures.detection.dynp.Dynp # Find optimal change points using dynamic programming. Given a segment model, it computes the best partition for which the sum of errors is minimum. __init__ ( self , model = 'l2' , custom_cost = None , min_size = 2 , jump = 5 , params = None ) special # Creates a Dynp instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/dynp.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Creates a Dynp instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" self . seg = lru_cache ( maxsize = None )( self . _seg ) # dynamic programming if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : self . model_name = model if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None fit ( self , signal ) # Create the cache associated with the signal. Dynamic programming is a recurrence; intermediate results are cached to speed up computations. This method sets up the cache. Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Dynp self Source code in ruptures/detection/dynp.py def fit ( self , signal ) -> \"Dynp\" : \"\"\"Create the cache associated with the signal. Dynamic programming is a recurrence; intermediate results are cached to speed up computations. This method sets up the cache. Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # clear cache self . seg . cache_clear () # update some params self . cost . fit ( signal ) self . n_samples = signal . shape [ 0 ] return self fit_predict ( self , signal , n_bkps ) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. required Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/dynp.py def fit_predict ( self , signal , n_bkps ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps ) predict ( self , n_bkps ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default n_bkps int number of breakpoints. required Exceptions: Type Description BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/dynp.py def predict ( self , n_bkps ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.dynp.Dynp.fit]. Args: n_bkps (int): number of breakpoints. Raises: BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . seg ( 0 , self . n_samples , n_bkps ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"Dynp"},{"location":"code-reference/detection/dynp-reference/#dynamic-programming","text":"","title":"Dynamic programming"},{"location":"code-reference/detection/dynp-reference/#ruptures.detection.dynp.Dynp","text":"Find optimal change points using dynamic programming. Given a segment model, it computes the best partition for which the sum of errors is minimum.","title":"Dynp"},{"location":"code-reference/detection/dynp-reference/#ruptures.detection.dynp.Dynp.__init__","text":"Creates a Dynp instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/dynp.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Creates a Dynp instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" self . seg = lru_cache ( maxsize = None )( self . _seg ) # dynamic programming if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : self . model_name = model if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None","title":"__init__()"},{"location":"code-reference/detection/dynp-reference/#ruptures.detection.dynp.Dynp.fit","text":"Create the cache associated with the signal. Dynamic programming is a recurrence; intermediate results are cached to speed up computations. This method sets up the cache. Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Dynp self Source code in ruptures/detection/dynp.py def fit ( self , signal ) -> \"Dynp\" : \"\"\"Create the cache associated with the signal. Dynamic programming is a recurrence; intermediate results are cached to speed up computations. This method sets up the cache. Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # clear cache self . seg . cache_clear () # update some params self . cost . fit ( signal ) self . n_samples = signal . shape [ 0 ] return self","title":"fit()"},{"location":"code-reference/detection/dynp-reference/#ruptures.detection.dynp.Dynp.fit_predict","text":"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int number of breakpoints. required Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/dynp.py def fit_predict ( self , signal , n_bkps ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int): number of breakpoints. Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps )","title":"fit_predict()"},{"location":"code-reference/detection/dynp-reference/#ruptures.detection.dynp.Dynp.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default n_bkps int number of breakpoints. required Exceptions: Type Description BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/dynp.py def predict ( self , n_bkps ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.dynp.Dynp.fit]. Args: n_bkps (int): number of breakpoints. Raises: BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . seg ( 0 , self . n_samples , n_bkps ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"predict()"},{"location":"code-reference/detection/kernelcpd-reference/","text":"Efficient kernel change point detection # ruptures.detection.kernelcpd.KernelCPD # Find optimal change points (using dynamic programming or pelt) for the special case where the cost function derives from a kernel function. Given a segment model, it computes the best partition for which the sum of errors is minimum. See the user guide for more information. __init__ ( self , kernel = 'linear' , min_size = 2 , jump = 1 , params = None ) special # Creates a KernelCPD instance. Available kernels: linear : \\(k(x,y) = x^T y\\) . rbf : \\(k(x, y) = exp(\\gamma \\|x-y\\|^2)\\) where \\(\\gamma>0\\) ( gamma ) is a user-defined parameter. cosine : \\(k(x,y)= (x^T y)/(\\|x\\|\\|y\\|)\\) . Parameters: Name Type Description Default kernel str name of the kernel, [\"linear\", \"rbf\", \"cosine\"] 'linear' min_size int minimum segment length. 2 jump int not considered, set to 1. 1 params dict a dictionary of parameters for the kernel instance None Exceptions: Type Description AssertionError if the kernel is not implemented. Source code in ruptures/detection/kernelcpd.py def __init__ ( self , kernel = \"linear\" , min_size = 2 , jump = 1 , params = None ): r \"\"\"Creates a KernelCPD instance. Available kernels: - `linear`: $k(x,y) = x^T y$. - `rbf`: $k(x, y) = exp(\\gamma \\|x-y\\|^2)$ where $\\gamma>0$ (`gamma`) is a user-defined parameter. - `cosine`: $k(x,y)= (x^T y)/(\\|x\\|\\|y\\|)$. Args: kernel (str, optional): name of the kernel, [\"linear\", \"rbf\", \"cosine\"] min_size (int, optional): minimum segment length. jump (int, optional): not considered, set to 1. params (dict, optional): a dictionary of parameters for the kernel instance Raises: AssertionError: if the kernel is not implemented. \"\"\" self . kernel_name = kernel err_msg = \"Kernel not found: {} .\" . format ( self . kernel_name ) assert self . kernel_name in [ \"linear\" , \"rbf\" , \"cosine\" ], err_msg self . model_name = \"l2\" if self . kernel_name == \"linear\" else self . kernel_name self . params = params # load the associated cost function if self . params is None : self . cost = cost_factory ( model = self . model_name ) else : self . cost = cost_factory ( model = self . model_name , ** self . params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = 1 # set to 1 self . n_samples = None self . segmentations_dict = dict () # {n_bkps: bkps_list} fit ( self , signal ) # Update some parameters (no computation in this function). Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description KernelCPD self Source code in ruptures/detection/kernelcpd.py def fit ( self , signal ) -> \"KernelCPD\" : \"\"\"Update some parameters (no computation in this function). Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params self . segmentations_dict = dict () self . cost . fit ( signal . astype ( np . double )) self . n_samples = signal . shape [ 0 ] return self fit_predict ( self , signal , n_bkps = None , pen = None ) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int Number of change points. Defaults to None. None pen float penalty value (>0). Defaults to None. Not considered if n_bkps is not None. None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/kernelcpd.py def fit_predict ( self , signal , n_bkps = None , pen = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int, optional): Number of change points. Defaults to None. pen (float, optional): penalty value (>0). Defaults to None. Not considered if n_bkps is not None. Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen ) predict ( self , n_bkps = None , pen = None ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default n_bkps int Number of change points. Defaults to None. None pen float penalty value (>0). Defaults to None. Not considered if n_bkps is not None. None Exceptions: Type Description AssertionError if pen or n_bkps is not strictly positive. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list[int] sorted list of breakpoints Source code in ruptures/detection/kernelcpd.py def predict ( self , n_bkps = None , pen = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.kernelcpd.KernelCPD.fit]. Args: n_bkps (int, optional): Number of change points. Defaults to None. pen (float, optional): penalty value (>0). Defaults to None. Not considered if n_bkps is not None. Raises: AssertionError: if `pen` or `n_bkps` is not strictly positive. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list[int]: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters # dynamic programming if the user passed a number change points if n_bkps is not None : n_bkps = int ( n_bkps ) err_msg = \"The number of changes must be positive: {} \" . format ( n_bkps ) assert n_bkps > 0 , err_msg # if we have already computed it, return it without computations. if n_bkps in self . segmentations_dict : return self . segmentations_dict [ n_bkps ] # otherwise, call the C function if self . kernel_name == \"linear\" : path_matrix_flat = ekcpd_L2 ( self . cost . signal , n_bkps , self . min_size ) elif self . kernel_name == \"rbf\" : path_matrix_flat = ekcpd_Gaussian ( self . cost . signal , n_bkps , self . min_size , self . cost . gamma ) elif self . kernel_name == \"cosine\" : path_matrix_flat = ekcpd_cosine ( self . cost . signal , n_bkps , self . min_size ) # from the path matrix, get all segmentation for k=1,...,n_bkps changes for k in range ( 1 , n_bkps + 1 ): self . segmentations_dict [ k ] = from_path_matrix_to_bkps_list ( path_matrix_flat , k , self . n_samples , n_bkps , self . jump ) return self . segmentations_dict [ n_bkps ] # Call pelt if the user passed a penalty if pen is not None : assert pen > 0 , \"The penalty must be positive: {} \" . format ( pen ) if self . kernel_name == \"linear\" : path_matrix = ekcpd_pelt_L2 ( self . cost . signal , pen , self . min_size ) elif self . kernel_name == \"rbf\" : path_matrix = ekcpd_pelt_Gaussian ( self . cost . signal , pen , self . min_size , self . cost . gamma ) elif self . kernel_name == \"cosine\" : path_matrix = ekcpd_pelt_cosine ( self . cost . signal , pen , self . min_size ) my_bkps = list () ind = self . n_samples while ind > 0 : my_bkps . append ( ind ) ind = path_matrix [ ind ] return my_bkps [:: - 1 ]","title":"KernelCPD"},{"location":"code-reference/detection/kernelcpd-reference/#efficient-kernel-change-point-detection","text":"","title":"Efficient kernel change point detection"},{"location":"code-reference/detection/kernelcpd-reference/#ruptures.detection.kernelcpd.KernelCPD","text":"Find optimal change points (using dynamic programming or pelt) for the special case where the cost function derives from a kernel function. Given a segment model, it computes the best partition for which the sum of errors is minimum. See the user guide for more information.","title":"KernelCPD"},{"location":"code-reference/detection/kernelcpd-reference/#ruptures.detection.kernelcpd.KernelCPD.__init__","text":"Creates a KernelCPD instance. Available kernels: linear : \\(k(x,y) = x^T y\\) . rbf : \\(k(x, y) = exp(\\gamma \\|x-y\\|^2)\\) where \\(\\gamma>0\\) ( gamma ) is a user-defined parameter. cosine : \\(k(x,y)= (x^T y)/(\\|x\\|\\|y\\|)\\) . Parameters: Name Type Description Default kernel str name of the kernel, [\"linear\", \"rbf\", \"cosine\"] 'linear' min_size int minimum segment length. 2 jump int not considered, set to 1. 1 params dict a dictionary of parameters for the kernel instance None Exceptions: Type Description AssertionError if the kernel is not implemented. Source code in ruptures/detection/kernelcpd.py def __init__ ( self , kernel = \"linear\" , min_size = 2 , jump = 1 , params = None ): r \"\"\"Creates a KernelCPD instance. Available kernels: - `linear`: $k(x,y) = x^T y$. - `rbf`: $k(x, y) = exp(\\gamma \\|x-y\\|^2)$ where $\\gamma>0$ (`gamma`) is a user-defined parameter. - `cosine`: $k(x,y)= (x^T y)/(\\|x\\|\\|y\\|)$. Args: kernel (str, optional): name of the kernel, [\"linear\", \"rbf\", \"cosine\"] min_size (int, optional): minimum segment length. jump (int, optional): not considered, set to 1. params (dict, optional): a dictionary of parameters for the kernel instance Raises: AssertionError: if the kernel is not implemented. \"\"\" self . kernel_name = kernel err_msg = \"Kernel not found: {} .\" . format ( self . kernel_name ) assert self . kernel_name in [ \"linear\" , \"rbf\" , \"cosine\" ], err_msg self . model_name = \"l2\" if self . kernel_name == \"linear\" else self . kernel_name self . params = params # load the associated cost function if self . params is None : self . cost = cost_factory ( model = self . model_name ) else : self . cost = cost_factory ( model = self . model_name , ** self . params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = 1 # set to 1 self . n_samples = None self . segmentations_dict = dict () # {n_bkps: bkps_list}","title":"__init__()"},{"location":"code-reference/detection/kernelcpd-reference/#ruptures.detection.kernelcpd.KernelCPD.fit","text":"Update some parameters (no computation in this function). Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description KernelCPD self Source code in ruptures/detection/kernelcpd.py def fit ( self , signal ) -> \"KernelCPD\" : \"\"\"Update some parameters (no computation in this function). Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params self . segmentations_dict = dict () self . cost . fit ( signal . astype ( np . double )) self . n_samples = signal . shape [ 0 ] return self","title":"fit()"},{"location":"code-reference/detection/kernelcpd-reference/#ruptures.detection.kernelcpd.KernelCPD.fit_predict","text":"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required n_bkps int Number of change points. Defaults to None. None pen float penalty value (>0). Defaults to None. Not considered if n_bkps is not None. None Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/kernelcpd.py def fit_predict ( self , signal , n_bkps = None , pen = None ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). n_bkps (int, optional): Number of change points. Defaults to None. pen (float, optional): penalty value (>0). Defaults to None. Not considered if n_bkps is not None. Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen )","title":"fit_predict()"},{"location":"code-reference/detection/kernelcpd-reference/#ruptures.detection.kernelcpd.KernelCPD.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default n_bkps int Number of change points. Defaults to None. None pen float penalty value (>0). Defaults to None. Not considered if n_bkps is not None. None Exceptions: Type Description AssertionError if pen or n_bkps is not strictly positive. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list[int] sorted list of breakpoints Source code in ruptures/detection/kernelcpd.py def predict ( self , n_bkps = None , pen = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.kernelcpd.KernelCPD.fit]. Args: n_bkps (int, optional): Number of change points. Defaults to None. pen (float, optional): penalty value (>0). Defaults to None. Not considered if n_bkps is not None. Raises: AssertionError: if `pen` or `n_bkps` is not strictly positive. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list[int]: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters # dynamic programming if the user passed a number change points if n_bkps is not None : n_bkps = int ( n_bkps ) err_msg = \"The number of changes must be positive: {} \" . format ( n_bkps ) assert n_bkps > 0 , err_msg # if we have already computed it, return it without computations. if n_bkps in self . segmentations_dict : return self . segmentations_dict [ n_bkps ] # otherwise, call the C function if self . kernel_name == \"linear\" : path_matrix_flat = ekcpd_L2 ( self . cost . signal , n_bkps , self . min_size ) elif self . kernel_name == \"rbf\" : path_matrix_flat = ekcpd_Gaussian ( self . cost . signal , n_bkps , self . min_size , self . cost . gamma ) elif self . kernel_name == \"cosine\" : path_matrix_flat = ekcpd_cosine ( self . cost . signal , n_bkps , self . min_size ) # from the path matrix, get all segmentation for k=1,...,n_bkps changes for k in range ( 1 , n_bkps + 1 ): self . segmentations_dict [ k ] = from_path_matrix_to_bkps_list ( path_matrix_flat , k , self . n_samples , n_bkps , self . jump ) return self . segmentations_dict [ n_bkps ] # Call pelt if the user passed a penalty if pen is not None : assert pen > 0 , \"The penalty must be positive: {} \" . format ( pen ) if self . kernel_name == \"linear\" : path_matrix = ekcpd_pelt_L2 ( self . cost . signal , pen , self . min_size ) elif self . kernel_name == \"rbf\" : path_matrix = ekcpd_pelt_Gaussian ( self . cost . signal , pen , self . min_size , self . cost . gamma ) elif self . kernel_name == \"cosine\" : path_matrix = ekcpd_pelt_cosine ( self . cost . signal , pen , self . min_size ) my_bkps = list () ind = self . n_samples while ind > 0 : my_bkps . append ( ind ) ind = path_matrix [ ind ] return my_bkps [:: - 1 ]","title":"predict()"},{"location":"code-reference/detection/pelt-reference/","text":"Pelt # ruptures.detection.pelt.Pelt # Penalized change point detection. For a given model and penalty level, computes the segmentation which minimizes the constrained sum of approximation errors. __init__ ( self , model = 'l2' , custom_cost = None , min_size = 2 , jump = 5 , params = None ) special # Initialize a Pelt instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/pelt.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a Pelt instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None fit ( self , signal ) # Set params. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Pelt self Source code in ruptures/detection/pelt.py def fit ( self , signal ) -> \"Pelt\" : \"\"\"Set params. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update params self . cost . fit ( signal ) if signal . ndim == 1 : ( n_samples ,) = signal . shape else : n_samples , _ = signal . shape self . n_samples = n_samples return self fit_predict ( self , signal , pen ) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required pen float penalty value (>0) required Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/pelt.py def fit_predict ( self , signal , pen ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). pen (float): penalty value (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( pen ) predict ( self , pen ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default pen float penalty value (>0) required Exceptions: Type Description BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/pelt.py def predict ( self , pen ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.pelt.Pelt.fit]. Args: pen (float): penalty value (>0) Raises: BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( pen ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"Pelt"},{"location":"code-reference/detection/pelt-reference/#pelt","text":"","title":"Pelt"},{"location":"code-reference/detection/pelt-reference/#ruptures.detection.pelt.Pelt","text":"Penalized change point detection. For a given model and penalty level, computes the segmentation which minimizes the constrained sum of approximation errors.","title":"Pelt"},{"location":"code-reference/detection/pelt-reference/#ruptures.detection.pelt.Pelt.__init__","text":"Initialize a Pelt instance. Parameters: Name Type Description Default model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if 'custom_cost' is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance. None Source code in ruptures/detection/pelt.py def __init__ ( self , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Initialize a Pelt instance. Args: model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if ``'custom_cost'`` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance. \"\"\" if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . min_size = max ( min_size , self . cost . min_size ) self . jump = jump self . n_samples = None","title":"__init__()"},{"location":"code-reference/detection/pelt-reference/#ruptures.detection.pelt.Pelt.fit","text":"Set params. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Pelt self Source code in ruptures/detection/pelt.py def fit ( self , signal ) -> \"Pelt\" : \"\"\"Set params. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update params self . cost . fit ( signal ) if signal . ndim == 1 : ( n_samples ,) = signal . shape else : n_samples , _ = signal . shape self . n_samples = n_samples return self","title":"fit()"},{"location":"code-reference/detection/pelt-reference/#ruptures.detection.pelt.Pelt.fit_predict","text":"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Parameters: Name Type Description Default signal array signal. Shape (n_samples, n_features) or (n_samples,). required pen float penalty value (>0) required Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/pelt.py def fit_predict ( self , signal , pen ): \"\"\"Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once Args: signal (array): signal. Shape (n_samples, n_features) or (n_samples,). pen (float): penalty value (>0) Returns: list: sorted list of breakpoints \"\"\" self . fit ( signal ) return self . predict ( pen )","title":"fit_predict()"},{"location":"code-reference/detection/pelt-reference/#ruptures.detection.pelt.Pelt.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . Parameters: Name Type Description Default pen float penalty value (>0) required Exceptions: Type Description BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/pelt.py def predict ( self , pen ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.pelt.Pelt.fit]. Args: pen (float): penalty value (>0) Raises: BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters partition = self . _seg ( pen ) bkps = sorted ( e for s , e in partition . keys ()) return bkps","title":"predict()"},{"location":"code-reference/detection/window-reference/","text":"Window-based change point detection # ruptures.detection.window.Window # Window sliding method. __init__ ( self , width = 100 , model = 'l2' , custom_cost = None , min_size = 2 , jump = 5 , params = None ) special # Instanciate with window length. Parameters: Name Type Description Default width int window length. Defaults to 100 samples. 100 model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if custom_cost is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance.` None Source code in ruptures/detection/window.py def __init__ ( self , width = 100 , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Instanciate with window length. Args: width (int, optional): window length. Defaults to 100 samples. model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if `custom_cost` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance.` \"\"\" self . min_size = min_size self . jump = jump self . width = 2 * ( width // 2 ) self . n_samples = None self . signal = None self . inds = None if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . score = list () fit ( self , signal ) # Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Window self Source code in ruptures/detection/window.py def fit ( self , signal ) -> \"Window\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal self . n_samples , _ = self . signal . shape # indexes self . inds = np . arange ( self . n_samples , step = self . jump ) # delete borders keep = ( self . inds >= self . width // 2 ) & ( self . inds < self . n_samples - self . width // 2 ) self . inds = self . inds [ keep ] self . cost . fit ( signal ) # compute score score = list () for k in self . inds : start , end = k - self . width // 2 , k + self . width // 2 gain = self . cost . error ( start , end ) if np . isinf ( gain ) and gain < 0 : # segment is constant and no improvment possible on start .. end score . append ( 0 ) continue gain -= self . cost . error ( start , k ) + self . cost . error ( k , end ) score . append ( gain ) self . score = np . array ( score ) return self fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ) # Helper method to call fit and predict once. Source code in ruptures/detection/window.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Helper method to call fit and predict once.\"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) predict ( self , n_bkps = None , pen = None , epsilon = None ) # Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/window.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.window.Window.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg bkps = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) return bkps","title":"Window"},{"location":"code-reference/detection/window-reference/#window-based-change-point-detection","text":"","title":"Window-based change point detection"},{"location":"code-reference/detection/window-reference/#ruptures.detection.window.Window","text":"Window sliding method.","title":"Window"},{"location":"code-reference/detection/window-reference/#ruptures.detection.window.Window.__init__","text":"Instanciate with window length. Parameters: Name Type Description Default width int window length. Defaults to 100 samples. 100 model str segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if custom_cost is not None. 'l2' custom_cost BaseCost custom cost function. Defaults to None. None min_size int minimum segment length. 2 jump int subsample (one every jump points). 5 params dict a dictionary of parameters for the cost instance.` None Source code in ruptures/detection/window.py def __init__ ( self , width = 100 , model = \"l2\" , custom_cost = None , min_size = 2 , jump = 5 , params = None ): \"\"\"Instanciate with window length. Args: width (int, optional): window length. Defaults to 100 samples. model (str, optional): segment model, [\"l1\", \"l2\", \"rbf\"]. Not used if `custom_cost` is not None. custom_cost (BaseCost, optional): custom cost function. Defaults to None. min_size (int, optional): minimum segment length. jump (int, optional): subsample (one every *jump* points). params (dict, optional): a dictionary of parameters for the cost instance.` \"\"\" self . min_size = min_size self . jump = jump self . width = 2 * ( width // 2 ) self . n_samples = None self . signal = None self . inds = None if custom_cost is not None and isinstance ( custom_cost , BaseCost ): self . cost = custom_cost else : if params is None : self . cost = cost_factory ( model = model ) else : self . cost = cost_factory ( model = model , ** params ) self . score = list ()","title":"__init__()"},{"location":"code-reference/detection/window-reference/#ruptures.detection.window.Window.fit","text":"Compute params to segment signal. Parameters: Name Type Description Default signal array signal to segment. Shape (n_samples, n_features) or (n_samples,). required Returns: Type Description Window self Source code in ruptures/detection/window.py def fit ( self , signal ) -> \"Window\" : \"\"\"Compute params to segment signal. Args: signal (array): signal to segment. Shape (n_samples, n_features) or (n_samples,). Returns: self \"\"\" # update some params if signal . ndim == 1 : self . signal = signal . reshape ( - 1 , 1 ) else : self . signal = signal self . n_samples , _ = self . signal . shape # indexes self . inds = np . arange ( self . n_samples , step = self . jump ) # delete borders keep = ( self . inds >= self . width // 2 ) & ( self . inds < self . n_samples - self . width // 2 ) self . inds = self . inds [ keep ] self . cost . fit ( signal ) # compute score score = list () for k in self . inds : start , end = k - self . width // 2 , k + self . width // 2 gain = self . cost . error ( start , end ) if np . isinf ( gain ) and gain < 0 : # segment is constant and no improvment possible on start .. end score . append ( 0 ) continue gain -= self . cost . error ( start , k ) + self . cost . error ( k , end ) score . append ( gain ) self . score = np . array ( score ) return self","title":"fit()"},{"location":"code-reference/detection/window-reference/#ruptures.detection.window.Window.fit_predict","text":"Helper method to call fit and predict once. Source code in ruptures/detection/window.py def fit_predict ( self , signal , n_bkps = None , pen = None , epsilon = None ): \"\"\"Helper method to call fit and predict once.\"\"\" self . fit ( signal ) return self . predict ( n_bkps = n_bkps , pen = pen , epsilon = epsilon )","title":"fit_predict()"},{"location":"code-reference/detection/window-reference/#ruptures.detection.window.Window.predict","text":"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to fit() . The stopping rule depends on the parameter passed to the function. Parameters: Name Type Description Default n_bkps int number of breakpoints to find before stopping. None pen float penalty value (>0) None epsilon float reconstruction budget (>0) None Exceptions: Type Description AssertionError if none of n_bkps , pen , epsilon is set. BadSegmentationParameters in case of impossible segmentation configuration Returns: Type Description list sorted list of breakpoints Source code in ruptures/detection/window.py def predict ( self , n_bkps = None , pen = None , epsilon = None ): \"\"\"Return the optimal breakpoints. Must be called after the fit method. The breakpoints are associated with the signal passed to [`fit()`][ruptures.detection.window.Window.fit]. The stopping rule depends on the parameter passed to the function. Args: n_bkps (int): number of breakpoints to find before stopping. pen (float): penalty value (>0) epsilon (float): reconstruction budget (>0) Raises: AssertionError: if none of `n_bkps`, `pen`, `epsilon` is set. BadSegmentationParameters: in case of impossible segmentation configuration Returns: list: sorted list of breakpoints \"\"\" # raise an exception in case of impossible segmentation configuration if not sanity_check ( n_samples = self . cost . signal . shape [ 0 ], n_bkps = 1 if n_bkps is None else n_bkps , jump = self . jump , min_size = self . min_size , ): raise BadSegmentationParameters msg = \"Give a parameter.\" assert any ( param is not None for param in ( n_bkps , pen , epsilon )), msg bkps = self . _seg ( n_bkps = n_bkps , pen = pen , epsilon = epsilon ) return bkps","title":"predict()"},{"location":"code-reference/metrics/hausdorff/","text":"Hausdorff metric ( hausdorff ) # ruptures . metrics . hausdorff . hausdorff ( bkps1 , bkps2 ) # Compute the Hausdorff distance between changepoints. Parameters: Name Type Description Default bkps1 list list of the last index of each regime. required bkps2 list list of the last index of each regime. required Returns: Type Description float Hausdorff distance. Source code in ruptures/metrics/hausdorff.py def hausdorff ( bkps1 , bkps2 ): \"\"\"Compute the Hausdorff distance between changepoints. Args: bkps1 (list): list of the last index of each regime. bkps2 (list): list of the last index of each regime. Returns: float: Hausdorff distance. \"\"\" sanity_check ( bkps1 , bkps2 ) bkps1_arr = np . array ( bkps1 [: - 1 ]) . reshape ( - 1 , 1 ) bkps2_arr = np . array ( bkps2 [: - 1 ]) . reshape ( - 1 , 1 ) pw_dist = cdist ( bkps1_arr , bkps2_arr ) res = max ( pw_dist . min ( axis = 0 ) . max (), pw_dist . min ( axis = 1 ) . max ()) return res","title":"Hausdorff metric"},{"location":"code-reference/metrics/hausdorff/#hausdorff-metric-hausdorff","text":"","title":"Hausdorff metric (hausdorff)"},{"location":"code-reference/metrics/hausdorff/#ruptures.metrics.hausdorff.hausdorff","text":"Compute the Hausdorff distance between changepoints. Parameters: Name Type Description Default bkps1 list list of the last index of each regime. required bkps2 list list of the last index of each regime. required Returns: Type Description float Hausdorff distance. Source code in ruptures/metrics/hausdorff.py def hausdorff ( bkps1 , bkps2 ): \"\"\"Compute the Hausdorff distance between changepoints. Args: bkps1 (list): list of the last index of each regime. bkps2 (list): list of the last index of each regime. Returns: float: Hausdorff distance. \"\"\" sanity_check ( bkps1 , bkps2 ) bkps1_arr = np . array ( bkps1 [: - 1 ]) . reshape ( - 1 , 1 ) bkps2_arr = np . array ( bkps2 [: - 1 ]) . reshape ( - 1 , 1 ) pw_dist = cdist ( bkps1_arr , bkps2_arr ) res = max ( pw_dist . min ( axis = 0 ) . max (), pw_dist . min ( axis = 1 ) . max ()) return res","title":"hausdorff()"},{"location":"code-reference/metrics/precisionrecall/","text":"Precision and recall ( precision_recall ) # ruptures . metrics . precisionrecall . precision_recall ( true_bkps , my_bkps , margin = 10 ) # Calculate the precision/recall of an estimated segmentation compared with the true segmentation. Parameters: Name Type Description Default true_bkps list list of the last index of each regime (true partition). required my_bkps list list of the last index of each regime (computed partition). required margin int allowed error (in points). 10 Returns: Type Description tuple (precision, recall) Source code in ruptures/metrics/precisionrecall.py def precision_recall ( true_bkps , my_bkps , margin = 10 ): \"\"\"Calculate the precision/recall of an estimated segmentation compared with the true segmentation. Args: true_bkps (list): list of the last index of each regime (true partition). my_bkps (list): list of the last index of each regime (computed partition). margin (int, optional): allowed error (in points). Returns: tuple: (precision, recall) \"\"\" sanity_check ( true_bkps , my_bkps ) assert margin > 0 , \"Margin of error must be positive (margin = {} )\" . format ( margin ) if len ( my_bkps ) == 1 : return 0 , 0 used = set () true_pos = set ( true_b for true_b , my_b in product ( true_bkps [: - 1 ], my_bkps [: - 1 ]) if my_b - margin < true_b < my_b + margin and not ( my_b in used or used . add ( my_b )) ) tp_ = len ( true_pos ) precision = tp_ / ( len ( my_bkps ) - 1 ) recall = tp_ / ( len ( true_bkps ) - 1 ) return precision , recall","title":"Precision and recall"},{"location":"code-reference/metrics/precisionrecall/#precision-and-recall-precision_recall","text":"","title":"Precision and recall (precision_recall)"},{"location":"code-reference/metrics/precisionrecall/#ruptures.metrics.precisionrecall.precision_recall","text":"Calculate the precision/recall of an estimated segmentation compared with the true segmentation. Parameters: Name Type Description Default true_bkps list list of the last index of each regime (true partition). required my_bkps list list of the last index of each regime (computed partition). required margin int allowed error (in points). 10 Returns: Type Description tuple (precision, recall) Source code in ruptures/metrics/precisionrecall.py def precision_recall ( true_bkps , my_bkps , margin = 10 ): \"\"\"Calculate the precision/recall of an estimated segmentation compared with the true segmentation. Args: true_bkps (list): list of the last index of each regime (true partition). my_bkps (list): list of the last index of each regime (computed partition). margin (int, optional): allowed error (in points). Returns: tuple: (precision, recall) \"\"\" sanity_check ( true_bkps , my_bkps ) assert margin > 0 , \"Margin of error must be positive (margin = {} )\" . format ( margin ) if len ( my_bkps ) == 1 : return 0 , 0 used = set () true_pos = set ( true_b for true_b , my_b in product ( true_bkps [: - 1 ], my_bkps [: - 1 ]) if my_b - margin < true_b < my_b + margin and not ( my_b in used or used . add ( my_b )) ) tp_ = len ( true_pos ) precision = tp_ / ( len ( my_bkps ) - 1 ) recall = tp_ / ( len ( true_bkps ) - 1 ) return precision , recall","title":"precision_recall()"},{"location":"code-reference/metrics/randindex/","text":"Rand index ( randindex ) # ruptures . metrics . randindex . randindex ( bkps1 , bkps2 ) # Rand index for two partitions. The result is scaled to be within 0 and 1. Parameters: Name Type Description Default bkps1 list list of the last index of each regime. required bkps2 list list of the last index of each regime. required Returns: Type Description float Rand index Source code in ruptures/metrics/randindex.py def randindex ( bkps1 , bkps2 ): \"\"\"Rand index for two partitions. The result is scaled to be within 0 and 1. Args: bkps1 (list): list of the last index of each regime. bkps2 (list): list of the last index of each regime. Returns: float: Rand index \"\"\" return 1 - hamming ( bkps1 , bkps2 )","title":"Rand index"},{"location":"code-reference/metrics/randindex/#rand-index-randindex","text":"","title":"Rand index (randindex)"},{"location":"code-reference/metrics/randindex/#ruptures.metrics.randindex.randindex","text":"Rand index for two partitions. The result is scaled to be within 0 and 1. Parameters: Name Type Description Default bkps1 list list of the last index of each regime. required bkps2 list list of the last index of each regime. required Returns: Type Description float Rand index Source code in ruptures/metrics/randindex.py def randindex ( bkps1 , bkps2 ): \"\"\"Rand index for two partitions. The result is scaled to be within 0 and 1. Args: bkps1 (list): list of the last index of each regime. bkps2 (list): list of the last index of each regime. Returns: float: Rand index \"\"\" return 1 - hamming ( bkps1 , bkps2 )","title":"randindex()"},{"location":"code-reference/show/display/","text":"Display ( display ) # ruptures . show . display . display ( signal , true_chg_pts , computed_chg_pts = None , ** kwargs ) # Display a signal and the change points provided in alternating colors. If another set of change point is provided, they are displayed with dashed vertical dashed lines. The following matplotlib subplots options is set by default, but can be changed when calling display ): figure size figsize , defaults to (10, 2 * n_features) . Parameters: Name Type Description Default signal array signal array, shape (n_samples,) or (n_samples, n_features). required true_chg_pts list list of change point indexes. required computed_chg_pts list list of change point indexes. None **kwargs all additional keyword arguments are passed to the plt.subplots call. {} Returns: Type Description tuple (figure, axarr) with a :class: matplotlib.figure.Figure object and an array of Axes objects. Source code in ruptures/show/display.py def display ( signal , true_chg_pts , computed_chg_pts = None , ** kwargs ): \"\"\"Display a signal and the change points provided in alternating colors. If another set of change point is provided, they are displayed with dashed vertical dashed lines. The following matplotlib subplots options is set by default, but can be changed when calling `display`): - figure size `figsize`, defaults to `(10, 2 * n_features)`. Args: signal (array): signal array, shape (n_samples,) or (n_samples, n_features). true_chg_pts (list): list of change point indexes. computed_chg_pts (list, optional): list of change point indexes. **kwargs : all additional keyword arguments are passed to the plt.subplots call. Returns: tuple: (figure, axarr) with a :class:`matplotlib.figure.Figure` object and an array of Axes objects. \"\"\" try : import matplotlib.pyplot as plt except ImportError : raise MatplotlibMissingError ( \"This feature requires the optional dependency matpotlib, you can install it using `pip install matplotlib`.\" ) if type ( signal ) != np . ndarray : # Try to get array from Pandas dataframe signal = signal . values if signal . ndim == 1 : signal = signal . reshape ( - 1 , 1 ) n_samples , n_features = signal . shape # let's set a sensible defaut size for the subplots matplotlib_options = { \"figsize\" : ( 10 , 2 * n_features ), # figure size } # add/update the options given by the user matplotlib_options . update ( kwargs ) # create plots fig , axarr = plt . subplots ( n_features , sharex = True , ** matplotlib_options ) if n_features == 1 : axarr = [ axarr ] for axe , sig in zip ( axarr , signal . T ): color_cycle = cycle ( COLOR_CYCLE ) # plot s axe . plot ( range ( n_samples ), sig ) # color each (true) regime bkps = [ 0 ] + sorted ( true_chg_pts ) alpha = 0.2 # transparency of the colored background for ( start , end ), col in zip ( pairwise ( bkps ), color_cycle ): axe . axvspan ( max ( 0 , start - 0.5 ), end - 0.5 , facecolor = col , alpha = alpha ) color = \"k\" # color of the lines indicating the computed_chg_pts linewidth = 3 # linewidth of the lines indicating the computed_chg_pts linestyle = \"--\" # linestyle of the lines indicating the computed_chg_pts # vertical lines to mark the computed_chg_pts if computed_chg_pts is not None : for bkp in computed_chg_pts : if bkp != 0 and bkp < n_samples : axe . axvline ( x = bkp - 0.5 , color = color , linewidth = linewidth , linestyle = linestyle , ) fig . tight_layout () return fig , axarr","title":"Display function"},{"location":"code-reference/show/display/#display-display","text":"","title":"Display (display)"},{"location":"code-reference/show/display/#ruptures.show.display.display","text":"Display a signal and the change points provided in alternating colors. If another set of change point is provided, they are displayed with dashed vertical dashed lines. The following matplotlib subplots options is set by default, but can be changed when calling display ): figure size figsize , defaults to (10, 2 * n_features) . Parameters: Name Type Description Default signal array signal array, shape (n_samples,) or (n_samples, n_features). required true_chg_pts list list of change point indexes. required computed_chg_pts list list of change point indexes. None **kwargs all additional keyword arguments are passed to the plt.subplots call. {} Returns: Type Description tuple (figure, axarr) with a :class: matplotlib.figure.Figure object and an array of Axes objects. Source code in ruptures/show/display.py def display ( signal , true_chg_pts , computed_chg_pts = None , ** kwargs ): \"\"\"Display a signal and the change points provided in alternating colors. If another set of change point is provided, they are displayed with dashed vertical dashed lines. The following matplotlib subplots options is set by default, but can be changed when calling `display`): - figure size `figsize`, defaults to `(10, 2 * n_features)`. Args: signal (array): signal array, shape (n_samples,) or (n_samples, n_features). true_chg_pts (list): list of change point indexes. computed_chg_pts (list, optional): list of change point indexes. **kwargs : all additional keyword arguments are passed to the plt.subplots call. Returns: tuple: (figure, axarr) with a :class:`matplotlib.figure.Figure` object and an array of Axes objects. \"\"\" try : import matplotlib.pyplot as plt except ImportError : raise MatplotlibMissingError ( \"This feature requires the optional dependency matpotlib, you can install it using `pip install matplotlib`.\" ) if type ( signal ) != np . ndarray : # Try to get array from Pandas dataframe signal = signal . values if signal . ndim == 1 : signal = signal . reshape ( - 1 , 1 ) n_samples , n_features = signal . shape # let's set a sensible defaut size for the subplots matplotlib_options = { \"figsize\" : ( 10 , 2 * n_features ), # figure size } # add/update the options given by the user matplotlib_options . update ( kwargs ) # create plots fig , axarr = plt . subplots ( n_features , sharex = True , ** matplotlib_options ) if n_features == 1 : axarr = [ axarr ] for axe , sig in zip ( axarr , signal . T ): color_cycle = cycle ( COLOR_CYCLE ) # plot s axe . plot ( range ( n_samples ), sig ) # color each (true) regime bkps = [ 0 ] + sorted ( true_chg_pts ) alpha = 0.2 # transparency of the colored background for ( start , end ), col in zip ( pairwise ( bkps ), color_cycle ): axe . axvspan ( max ( 0 , start - 0.5 ), end - 0.5 , facecolor = col , alpha = alpha ) color = \"k\" # color of the lines indicating the computed_chg_pts linewidth = 3 # linewidth of the lines indicating the computed_chg_pts linestyle = \"--\" # linestyle of the lines indicating the computed_chg_pts # vertical lines to mark the computed_chg_pts if computed_chg_pts is not None : for bkp in computed_chg_pts : if bkp != 0 and bkp < n_samples : axe . axvline ( x = bkp - 0.5 , color = color , linewidth = linewidth , linestyle = linestyle , ) fig . tight_layout () return fig , axarr","title":"display()"},{"location":"examples/advanced-usages-introduction/","text":"Advanced usages #","title":"Introduction"},{"location":"examples/advanced-usages-introduction/#advanced-usages","text":"","title":"Advanced usages"},{"location":"examples/introduction/","text":"Gallery of examples #","title":"Introduction"},{"location":"examples/introduction/#gallery-of-examples","text":"","title":"Gallery of examples"},{"location":"examples/kernel-cpd-performance-comparison/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Kernel change point detection: a performance comparison # Info Try this notebook in an executable environment with Binder . Download this notebook here . Introduction # In ruptures , there are two ways to perform kernel change point detection: by using the pure Python classes Dynp (known number of change points) and Pelt (unknown number of change points), by using the faster class (implemented in C) KernelCPD which contains both the dynamic programming approach and the penalized approach (PELT). This example illustrates the performance of the fast C implementation compared to the pure Python one. The kernel change point detection setting is briefly described in the user guide . The interested reader can refer to [ Celisse2018 , Arlot2019 ] for a more complete introduction. The list of available kernels is available here , but in this example we only consider two: the linear kernel, \\(k_{\\text{linear}}(x, y) = x^T y\\) (Euclidean scalar product) and the induced norm is the Euclidean norm; the Gaussian kernel (also known as radial basis function, rbf), \\(k_{\\text{Gaussian}}(x,y)=\\exp(-\\gamma \\|x-y\\|^2)\\) where \\(\\|\\cdot\\|\\) is the Euclidean norm and \\(\\gamma>0\\) is a user-defined parameter. Setup # First, we make the necessary imports and generate a toy signal import time # for execution time comparison import matplotlib.pyplot as plt # for display purposes import ruptures as rpt # our package from ruptures.metrics import hausdorff # generate signal n_samples , dim , sigma = 500 , 3 , 3 n_bkps = 6 # number of breakpoints signal , bkps = rpt . pw_constant ( n_samples , dim , n_bkps , noise_std = sigma ) fig , ax_array = rpt . display ( signal , bkps ) Linear kernel # The linear kernel (see above) \\(k_{\\text{linear}}\\) can detect changes in the mean of a signal. It also corresponds to the cost function CostL2 . Dynamic programming # When the number of changes to detect is known beforehand, we use dynamic programming. algo_python = rpt . Dynp ( model = \"l2\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"linear\" , min_size = 2 ) . fit ( signal ) # written in C for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( n_bkps = n_bkps ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 8.601 s C implementation: 0.008 s The speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the number \\(K\\) of change points to detect. The C implementation has a time complexity of the order \\(\\mathcal{O}(KdT^2)\\) and space complexity of the order \\(\\mathcal{O}(T)\\) . As to the Python implementation, the complexities in time and space are of the order \\(\\mathcal{O}(KdT^3)\\) and \\(\\mathcal{O}(T^2)\\) respectively. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( n_bkps = n_bkps ) bkps_c = algo_c . predict ( n_bkps = n_bkps ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples) PELT # When the number of changes to detect is unknown, we resort to PELT [Killick2012] to solve the penalized detection problem. algo_python = rpt . Pelt ( model = \"l2\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"linear\" , min_size = 2 ) . fit ( signal ) # written in C, same class as before penalty_value = 100 # beta for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( pen = penalty_value ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 0.601 s C implementation: 0.001 s Again, the speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the penalty value \\(\\beta\\) . We remark that, for both Python and C implementations, PELT is more efficient then dynamic programming. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( pen = penalty_value ) bkps_c = algo_c . predict ( pen = penalty_value ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 189, 204, 285, 353, 401, 411, 422, 500] C implementation: [67, 133, 189, 204, 285, 353, 401, 411, 422, 500] (Hausdorff distance: 0 samples) Note By default, Dynp and Pelt has jump=5 . In KernelCPD , jump=1 and cannot be changed. This is because, in the C implementation, changing the jump does not improve the running time significatively, while it does in the Python implementation. Gaussian kernel # The Gaussian kernel (see above) \\(k_{\\text{Gaussian}}\\) can detect changes in the distribution of an i.i.d. process. This is a feature of several kernel functions (in particular characteristics kernels; see [Gretton2012] for more information). It also corresponds to the cost function CostRbf . Dynamic programming # When the number of changes to detect is known beforehand, we use dynamic programming. params = { \"gamma\" : 1e-2 } algo_python = rpt . Dynp ( model = \"rbf\" , params = params , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"rbf\" , params = params , min_size = 2 ) . fit ( signal ) # written in C for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( n_bkps = n_bkps ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 8.311 s C implementation: 0.014 s Again, the speed-up is quite significant. The C implementation has a time complexity of the order \\(\\mathcal{O}(CKT^2)\\) and space complexity of the order \\(\\mathcal{O}(T)\\) , where \\(C\\) is the complexity of computing \\(k(y_s, y_t)\\) once. As to the Python implementation, the complexities in time and space are of the order \\(\\mathcal{O}(CKT^4)\\) and \\(\\mathcal{O}(T^2)\\) respectively. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( n_bkps = n_bkps ) bkps_c = algo_c . predict ( n_bkps = n_bkps ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples) Note If not provided by the user, the gamma parameter is chosen using the median heuristics, meaning that it is set to inverse of the median of all pairwise products \\(k(y_s, y_t)\\) . PELT # When the number of changes to detect is unknown, we resort to PELT to solve the penalized detection problem. algo_python = rpt . Pelt ( model = \"rbf\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"rbf\" , min_size = 2 ) . fit ( signal ) # written in C, same class as before penalty_value = 1 # beta for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( pen = penalty_value ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 0.329 s C implementation: 0.002 s Again, the speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the penalty value \\(\\beta\\) . We remark that, for both Python and C implementations, PELT is more efficient then dynamic programming. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( pen = penalty_value ) bkps_c = algo_c . predict ( pen = penalty_value ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples) References # [Gretton2012] Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch\u00f6lkopf, B., & Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13, 723\u2013773. [Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598. [Celisse2018] Celisse, A., Marot, G., Pierre-Jean, M., & Rigaill, G. (2018). New efficient algorithms for multiple change-point detection with reproducing kernels. Computational Statistics and Data Analysis, 128, 200\u2013220. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"Kernel change point detection: a performance comparison"},{"location":"examples/kernel-cpd-performance-comparison/#kernel-change-point-detection-a-performance-comparison","text":"Info Try this notebook in an executable environment with Binder . Download this notebook here .","title":"Kernel change point detection: a performance comparison"},{"location":"examples/kernel-cpd-performance-comparison/#introduction","text":"In ruptures , there are two ways to perform kernel change point detection: by using the pure Python classes Dynp (known number of change points) and Pelt (unknown number of change points), by using the faster class (implemented in C) KernelCPD which contains both the dynamic programming approach and the penalized approach (PELT). This example illustrates the performance of the fast C implementation compared to the pure Python one. The kernel change point detection setting is briefly described in the user guide . The interested reader can refer to [ Celisse2018 , Arlot2019 ] for a more complete introduction. The list of available kernels is available here , but in this example we only consider two: the linear kernel, \\(k_{\\text{linear}}(x, y) = x^T y\\) (Euclidean scalar product) and the induced norm is the Euclidean norm; the Gaussian kernel (also known as radial basis function, rbf), \\(k_{\\text{Gaussian}}(x,y)=\\exp(-\\gamma \\|x-y\\|^2)\\) where \\(\\|\\cdot\\|\\) is the Euclidean norm and \\(\\gamma>0\\) is a user-defined parameter.","title":"Introduction"},{"location":"examples/kernel-cpd-performance-comparison/#setup","text":"First, we make the necessary imports and generate a toy signal import time # for execution time comparison import matplotlib.pyplot as plt # for display purposes import ruptures as rpt # our package from ruptures.metrics import hausdorff # generate signal n_samples , dim , sigma = 500 , 3 , 3 n_bkps = 6 # number of breakpoints signal , bkps = rpt . pw_constant ( n_samples , dim , n_bkps , noise_std = sigma ) fig , ax_array = rpt . display ( signal , bkps )","title":"Setup"},{"location":"examples/kernel-cpd-performance-comparison/#linear-kernel","text":"The linear kernel (see above) \\(k_{\\text{linear}}\\) can detect changes in the mean of a signal. It also corresponds to the cost function CostL2 .","title":"Linear kernel"},{"location":"examples/kernel-cpd-performance-comparison/#dynamic-programming","text":"When the number of changes to detect is known beforehand, we use dynamic programming. algo_python = rpt . Dynp ( model = \"l2\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"linear\" , min_size = 2 ) . fit ( signal ) # written in C for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( n_bkps = n_bkps ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 8.601 s C implementation: 0.008 s The speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the number \\(K\\) of change points to detect. The C implementation has a time complexity of the order \\(\\mathcal{O}(KdT^2)\\) and space complexity of the order \\(\\mathcal{O}(T)\\) . As to the Python implementation, the complexities in time and space are of the order \\(\\mathcal{O}(KdT^3)\\) and \\(\\mathcal{O}(T^2)\\) respectively. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( n_bkps = n_bkps ) bkps_c = algo_c . predict ( n_bkps = n_bkps ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples)","title":"Dynamic programming"},{"location":"examples/kernel-cpd-performance-comparison/#pelt","text":"When the number of changes to detect is unknown, we resort to PELT [Killick2012] to solve the penalized detection problem. algo_python = rpt . Pelt ( model = \"l2\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"linear\" , min_size = 2 ) . fit ( signal ) # written in C, same class as before penalty_value = 100 # beta for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( pen = penalty_value ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 0.601 s C implementation: 0.001 s Again, the speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the penalty value \\(\\beta\\) . We remark that, for both Python and C implementations, PELT is more efficient then dynamic programming. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( pen = penalty_value ) bkps_c = algo_c . predict ( pen = penalty_value ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 189, 204, 285, 353, 401, 411, 422, 500] C implementation: [67, 133, 189, 204, 285, 353, 401, 411, 422, 500] (Hausdorff distance: 0 samples) Note By default, Dynp and Pelt has jump=5 . In KernelCPD , jump=1 and cannot be changed. This is because, in the C implementation, changing the jump does not improve the running time significatively, while it does in the Python implementation.","title":"PELT"},{"location":"examples/kernel-cpd-performance-comparison/#gaussian-kernel","text":"The Gaussian kernel (see above) \\(k_{\\text{Gaussian}}\\) can detect changes in the distribution of an i.i.d. process. This is a feature of several kernel functions (in particular characteristics kernels; see [Gretton2012] for more information). It also corresponds to the cost function CostRbf .","title":"Gaussian kernel"},{"location":"examples/kernel-cpd-performance-comparison/#dynamic-programming_1","text":"When the number of changes to detect is known beforehand, we use dynamic programming. params = { \"gamma\" : 1e-2 } algo_python = rpt . Dynp ( model = \"rbf\" , params = params , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"rbf\" , params = params , min_size = 2 ) . fit ( signal ) # written in C for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( n_bkps = n_bkps ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 8.311 s C implementation: 0.014 s Again, the speed-up is quite significant. The C implementation has a time complexity of the order \\(\\mathcal{O}(CKT^2)\\) and space complexity of the order \\(\\mathcal{O}(T)\\) , where \\(C\\) is the complexity of computing \\(k(y_s, y_t)\\) once. As to the Python implementation, the complexities in time and space are of the order \\(\\mathcal{O}(CKT^4)\\) and \\(\\mathcal{O}(T^2)\\) respectively. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( n_bkps = n_bkps ) bkps_c = algo_c . predict ( n_bkps = n_bkps ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples) Note If not provided by the user, the gamma parameter is chosen using the median heuristics, meaning that it is set to inverse of the median of all pairwise products \\(k(y_s, y_t)\\) .","title":"Dynamic programming"},{"location":"examples/kernel-cpd-performance-comparison/#pelt_1","text":"When the number of changes to detect is unknown, we resort to PELT to solve the penalized detection problem. algo_python = rpt . Pelt ( model = \"rbf\" , jump = 1 , min_size = 2 ) . fit ( signal ) # written in pure python algo_c = rpt . KernelCPD ( kernel = \"rbf\" , min_size = 2 ) . fit ( signal ) # written in C, same class as before penalty_value = 1 # beta for ( label , algo ) in zip ( ( \"Python implementation\" , \"C implementation\" ), ( algo_python , algo_c ) ): start_time = time . time () result = algo . predict ( pen = penalty_value ) print ( f \" { label } : \\t { time . time () - start_time : .3f } s\" ) Python implementation: 0.329 s C implementation: 0.002 s Again, the speed-up is quite significant and depends on the signal size (number \\(T\\) of samples and dimension \\(d\\) ) and the penalty value \\(\\beta\\) . We remark that, for both Python and C implementations, PELT is more efficient then dynamic programming. We can also check that both methods return the same set of change points. bkps_python = algo_python . predict ( pen = penalty_value ) bkps_c = algo_c . predict ( pen = penalty_value ) print ( f \"Python implementation: \\t { bkps_python } \" ) print ( f \"C implementation: \\t { bkps_c } \" ) print ( f \"(Hausdorff distance: { hausdorff ( bkps_python , bkps_c ) : .0f } samples)\" ) Python implementation: [67, 133, 204, 285, 353, 422, 500] C implementation: [67, 133, 204, 285, 353, 422, 500] (Hausdorff distance: 0 samples)","title":"PELT"},{"location":"examples/kernel-cpd-performance-comparison/#references","text":"[Gretton2012] Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch\u00f6lkopf, B., & Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13, 723\u2013773. [Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598. [Celisse2018] Celisse, A., Marot, G., Pierre-Jean, M., & Rigaill, G. (2018). New efficient algorithms for multiple change-point detection with reproducing kernels. Computational Statistics and Data Analysis, 128, 200\u2013220. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"References"},{"location":"examples/music-segmentation/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Music segmentation # Info Try this notebook in an executable environment with Binder . Download this notebook here . Introduction # Music segmentation can be seen as a change point detection task and therefore can be carried out with ruptures . Roughly, it consists in finding the temporal boundaries of meaningful sections, e.g. the intro, verse, chorus and outro in a song. This is an important task in the field of music information retrieval. The adopted approach is summarized as follows: the original sound is transformed into an informative (multivariate) representation; mean shifts are detected in this new representation using a dynamic programming approach. In this example, we use the well-known tempogram representation, which is based on the onset strength envelope of the input signal, and captures tempo information [Grosche2010] . To load and manipulate sound data, we use the librosa package [McFee2015] . Setup # First, we make the necessary imports. import librosa import librosa.display import matplotlib.pyplot as plt import numpy as np import ruptures as rpt # our package from IPython.display import Audio , display We can also define a utility function. def fig_ax ( figsize = ( 15 , 5 ), dpi = 150 ): \"\"\"Return a (matplotlib) figure and ax objects with given size.\"\"\" return plt . subplots ( figsize = figsize , dpi = dpi ) Load the data # A number of music files are available in Librosa . See here for a complete list. In this example, we choose the Dance of the Sugar Plum Fairy from The Nutcracker by Tchaikovsky. We can listen to the music as well as display the sound envelope. duration = 30 # in seconds signal , sampling_rate = librosa . load ( librosa . ex ( \"nutcracker\" ), duration = duration ) # listen to the music display ( Audio ( data = signal , rate = sampling_rate )) # look at the envelope fig , ax = fig_ax () ax . plot ( np . arange ( signal . size ) / sampling_rate , signal ) ax . set_xlim ( 0 , signal . size / sampling_rate ) ax . set_xlabel ( \"Time (s)\" ) _ = ax . set ( title = \"Sound envelope\" ) Downloading file 'Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' from 'https://librosa.org/data/audio/Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' to '/home/runner/.cache/librosa'. Your browser does not support the audio element. Signal segmentation # Transform the signal into a tempogram # The tempogram measures the tempo (measured in Beats Per Minute, BPM) profile along the time axis. # Compute the onset strength hop_length_tempo = 256 oenv = librosa . onset . onset_strength ( y = signal , sr = sampling_rate , hop_length = hop_length_tempo ) # Compute the tempogram tempogram = librosa . feature . tempogram ( onset_envelope = oenv , sr = sampling_rate , hop_length = hop_length_tempo , ) # Display the tempogram fig , ax = fig_ax () _ = librosa . display . specshow ( tempogram , ax = ax , hop_length = hop_length_tempo , sr = sampling_rate , x_axis = \"s\" , y_axis = \"tempo\" , ) /opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/librosa/display.py:974: MatplotlibDeprecationWarning: The 'basey' parameter of __init__() has been renamed 'base' since Matplotlib 3.3; support for the old name will be dropped two minor releases later. scaler(mode, **kwargs) Detection algorithm # We choose to detect changes in the mean of the tempogram, which is a multivariate signal. This amounts to selecting the \\(L_2\\) cost function (see CostL2 ). To that end, two methods are available in ruptures : rpt.Dynp(model=\"l2\") rpt.KernelCPD(kernel=\"linear\") Both will return the same results but the latter is implemented in C and therefore significatively faster. Number of changes # In order to choose the number of change points, we use the elbow method. In the change point detection setting, this heuritic consists in: plotting the sum of costs for 1, 2,..., \\(K_{\\text{max}}\\) change points, picking the number of changes at the \"elbow\" of the curve. Intuitively, adding change points beyond the \"elbow\" only provides a marginal decrease of the sum of costs. Here, we set \\(K_{\\text{max}}\\) :=20. Note In rpt.Dynp and rpt.KernelCPD , whenever a segmentation with \\(K\\) changes is computed, all segmentations with 1,2,..., \\(K-1\\) are also computed and stored. Indeed, thanks to the dynamic programming approach, segmentations with less changes are avalaible for free as intermediate calculations. Therefore, users who need to compute segmentations with several numbers of changes should start with the one with the most changes. In addition, note that, in ruptures , the sum of costs of a segmentation defined by a set of change points bkps can easily be computed using: algo = rpt . KernelCPD ( kernel = \"linear\" ) . fit ( signal ) algo . cost . sum_of_costs ( bkps ) (Replace rpt.KernelCPD by the algorithm you are actually using, if different.) # Choose detection method algo = rpt . KernelCPD ( kernel = \"linear\" ) . fit ( tempogram . T ) # Choose the number of changes (elbow heuristic) n_bkps_max = 20 # K_max # Start by computing the segmentation with most changes. # After start, all segmentations with 1, 2,..., K_max-1 changes are also available for free. _ = algo . predict ( n_bkps_max ) array_of_n_bkps = np . arange ( 1 , n_bkps_max + 1 ) def get_sum_of_cost ( algo , n_bkps ) -> float : \"\"\"Return the sum of costs for the change points `bkps`\"\"\" bkps = algo . predict ( n_bkps = n_bkps ) return algo . cost . sum_of_costs ( bkps ) fig , ax = fig_ax (( 7 , 4 )) ax . plot ( array_of_n_bkps , [ get_sum_of_cost ( algo = algo , n_bkps = n_bkps ) for n_bkps in array_of_n_bkps ], \"-*\" , alpha = 0.5 , ) ax . set_xticks ( array_of_n_bkps ) ax . set_xlabel ( \"Number of change points\" ) ax . set_title ( \"Sum of costs\" ) ax . grid ( axis = \"x\" ) ax . set_xlim ( 0 , n_bkps_max + 1 ) # Visually we choose n_bkps=5 (highlighted in red on the elbow plot) n_bkps = 5 _ = ax . scatter ([ 5 ], [ get_sum_of_cost ( algo = algo , n_bkps = 5 )], color = \"r\" , s = 100 ) Visually, we choose 5 change points (highlighted in red on the elbow plot). Results # The tempogram can now be segmented into homogeous (from a tempo standpoint) portions. The results are show in the following figure. # Segmentation bkps = algo . predict ( n_bkps = n_bkps ) # Convert the estimated change points (frame counts) to actual timestamps bkps_times = librosa . frames_to_time ( bkps , sr = sampling_rate , hop_length = hop_length_tempo ) # Displaying results fig , ax = fig_ax () _ = librosa . display . specshow ( tempogram , ax = ax , x_axis = \"s\" , y_axis = \"tempo\" , hop_length = hop_length_tempo , sr = sampling_rate , ) for b in bkps_times [: - 1 ]: ax . axvline ( b , ls = \"--\" , color = \"white\" , lw = 4 ) /opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/librosa/display.py:974: MatplotlibDeprecationWarning: The 'basey' parameter of __init__() has been renamed 'base' since Matplotlib 3.3; support for the old name will be dropped two minor releases later. scaler(mode, **kwargs) Visually, the estimated change points indeed separate portions of signal with a relatively constant tempo profile. Going back to the original music signal, this intuition can be verified by listening to the indivudal segments defined by the changes points. # Compute change points corresponding indexes in original signal bkps_time_indexes = ( sampling_rate * bkps_times ) . astype ( int ) . tolist () for ( segment_number , ( start , end )) in enumerate ( rpt . utils . pairwise ([ 0 ] + bkps_time_indexes ), start = 1 ): segment = signal [ start : end ] print ( f \"Segment n\u00b0 { segment_number } (duration: { segment . size / sampling_rate : .2f } s)\" ) display ( Audio ( data = segment , rate = sampling_rate )) Segment n\u00b01 (duration: 1.76 s) Your browser does not support the audio element. Segment n\u00b02 (duration: 8.03 s) Your browser does not support the audio element. Segment n\u00b03 (duration: 8.46 s) Your browser does not support the audio element. Segment n\u00b04 (duration: 2.73 s) Your browser does not support the audio element. Segment n\u00b05 (duration: 5.97 s) Your browser does not support the audio element. Segment n\u00b06 (duration: 3.04 s) Your browser does not support the audio element. The first segment corresponds to the soundless part of the signal (visible on the plot of the signal enveloppe). The following segments correspond to different rythmic portions and the associated change points occur when various instruments enter or exit the play. Conclusion # This example shows how to apply ruptures on a music segmentation task. More precisely, we detected mean shifts on a well-suited representation (the tempogram) of a music signal. The number of changes was heuristically determined (with the \"elbow\" method) and the results agreed with visually and auditory intuition. Such results can then be used to characterize the structure of music and songs, for music classification, recommandation, instrument recognition, etc. This procedure could also be enriched with other musically relevant representations (e.g. the chromagram) to detect other types of changes. Authors # This example notebook has been authored by Olivier Boulant and edited by Charles Truong. References # [Grosche2010] Grosche, P., M\u00fcller, M., & Kurth, F. (2010). Cyclic tempogram - a mid-level tempo representation for music signals. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5522\u20135525. [McFee2015] McFee, B., Raffel, C., Liang, D., Ellis, D. P. W., McVicar, M., Battenberg, E., & Nieto, O. (2015). Librosa: audio and music signal analysis in Python. Proceedings of the Python in Science Conference, 8, 18\u201325.","title":"Music segmentation"},{"location":"examples/music-segmentation/#music-segmentation","text":"Info Try this notebook in an executable environment with Binder . Download this notebook here .","title":"Music segmentation"},{"location":"examples/music-segmentation/#introduction","text":"Music segmentation can be seen as a change point detection task and therefore can be carried out with ruptures . Roughly, it consists in finding the temporal boundaries of meaningful sections, e.g. the intro, verse, chorus and outro in a song. This is an important task in the field of music information retrieval. The adopted approach is summarized as follows: the original sound is transformed into an informative (multivariate) representation; mean shifts are detected in this new representation using a dynamic programming approach. In this example, we use the well-known tempogram representation, which is based on the onset strength envelope of the input signal, and captures tempo information [Grosche2010] . To load and manipulate sound data, we use the librosa package [McFee2015] .","title":"Introduction"},{"location":"examples/music-segmentation/#setup","text":"First, we make the necessary imports. import librosa import librosa.display import matplotlib.pyplot as plt import numpy as np import ruptures as rpt # our package from IPython.display import Audio , display We can also define a utility function. def fig_ax ( figsize = ( 15 , 5 ), dpi = 150 ): \"\"\"Return a (matplotlib) figure and ax objects with given size.\"\"\" return plt . subplots ( figsize = figsize , dpi = dpi )","title":"Setup"},{"location":"examples/music-segmentation/#load-the-data","text":"A number of music files are available in Librosa . See here for a complete list. In this example, we choose the Dance of the Sugar Plum Fairy from The Nutcracker by Tchaikovsky. We can listen to the music as well as display the sound envelope. duration = 30 # in seconds signal , sampling_rate = librosa . load ( librosa . ex ( \"nutcracker\" ), duration = duration ) # listen to the music display ( Audio ( data = signal , rate = sampling_rate )) # look at the envelope fig , ax = fig_ax () ax . plot ( np . arange ( signal . size ) / sampling_rate , signal ) ax . set_xlim ( 0 , signal . size / sampling_rate ) ax . set_xlabel ( \"Time (s)\" ) _ = ax . set ( title = \"Sound envelope\" ) Downloading file 'Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' from 'https://librosa.org/data/audio/Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' to '/home/runner/.cache/librosa'. Your browser does not support the audio element.","title":"Load the data"},{"location":"examples/music-segmentation/#signal-segmentation","text":"","title":"Signal segmentation"},{"location":"examples/music-segmentation/#transform-the-signal-into-a-tempogram","text":"The tempogram measures the tempo (measured in Beats Per Minute, BPM) profile along the time axis. # Compute the onset strength hop_length_tempo = 256 oenv = librosa . onset . onset_strength ( y = signal , sr = sampling_rate , hop_length = hop_length_tempo ) # Compute the tempogram tempogram = librosa . feature . tempogram ( onset_envelope = oenv , sr = sampling_rate , hop_length = hop_length_tempo , ) # Display the tempogram fig , ax = fig_ax () _ = librosa . display . specshow ( tempogram , ax = ax , hop_length = hop_length_tempo , sr = sampling_rate , x_axis = \"s\" , y_axis = \"tempo\" , ) /opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/librosa/display.py:974: MatplotlibDeprecationWarning: The 'basey' parameter of __init__() has been renamed 'base' since Matplotlib 3.3; support for the old name will be dropped two minor releases later. scaler(mode, **kwargs)","title":"Transform the signal into a tempogram"},{"location":"examples/music-segmentation/#detection-algorithm","text":"We choose to detect changes in the mean of the tempogram, which is a multivariate signal. This amounts to selecting the \\(L_2\\) cost function (see CostL2 ). To that end, two methods are available in ruptures : rpt.Dynp(model=\"l2\") rpt.KernelCPD(kernel=\"linear\") Both will return the same results but the latter is implemented in C and therefore significatively faster.","title":"Detection algorithm"},{"location":"examples/music-segmentation/#number-of-changes","text":"In order to choose the number of change points, we use the elbow method. In the change point detection setting, this heuritic consists in: plotting the sum of costs for 1, 2,..., \\(K_{\\text{max}}\\) change points, picking the number of changes at the \"elbow\" of the curve. Intuitively, adding change points beyond the \"elbow\" only provides a marginal decrease of the sum of costs. Here, we set \\(K_{\\text{max}}\\) :=20. Note In rpt.Dynp and rpt.KernelCPD , whenever a segmentation with \\(K\\) changes is computed, all segmentations with 1,2,..., \\(K-1\\) are also computed and stored. Indeed, thanks to the dynamic programming approach, segmentations with less changes are avalaible for free as intermediate calculations. Therefore, users who need to compute segmentations with several numbers of changes should start with the one with the most changes. In addition, note that, in ruptures , the sum of costs of a segmentation defined by a set of change points bkps can easily be computed using: algo = rpt . KernelCPD ( kernel = \"linear\" ) . fit ( signal ) algo . cost . sum_of_costs ( bkps ) (Replace rpt.KernelCPD by the algorithm you are actually using, if different.) # Choose detection method algo = rpt . KernelCPD ( kernel = \"linear\" ) . fit ( tempogram . T ) # Choose the number of changes (elbow heuristic) n_bkps_max = 20 # K_max # Start by computing the segmentation with most changes. # After start, all segmentations with 1, 2,..., K_max-1 changes are also available for free. _ = algo . predict ( n_bkps_max ) array_of_n_bkps = np . arange ( 1 , n_bkps_max + 1 ) def get_sum_of_cost ( algo , n_bkps ) -> float : \"\"\"Return the sum of costs for the change points `bkps`\"\"\" bkps = algo . predict ( n_bkps = n_bkps ) return algo . cost . sum_of_costs ( bkps ) fig , ax = fig_ax (( 7 , 4 )) ax . plot ( array_of_n_bkps , [ get_sum_of_cost ( algo = algo , n_bkps = n_bkps ) for n_bkps in array_of_n_bkps ], \"-*\" , alpha = 0.5 , ) ax . set_xticks ( array_of_n_bkps ) ax . set_xlabel ( \"Number of change points\" ) ax . set_title ( \"Sum of costs\" ) ax . grid ( axis = \"x\" ) ax . set_xlim ( 0 , n_bkps_max + 1 ) # Visually we choose n_bkps=5 (highlighted in red on the elbow plot) n_bkps = 5 _ = ax . scatter ([ 5 ], [ get_sum_of_cost ( algo = algo , n_bkps = 5 )], color = \"r\" , s = 100 ) Visually, we choose 5 change points (highlighted in red on the elbow plot).","title":"Number of changes"},{"location":"examples/music-segmentation/#results","text":"The tempogram can now be segmented into homogeous (from a tempo standpoint) portions. The results are show in the following figure. # Segmentation bkps = algo . predict ( n_bkps = n_bkps ) # Convert the estimated change points (frame counts) to actual timestamps bkps_times = librosa . frames_to_time ( bkps , sr = sampling_rate , hop_length = hop_length_tempo ) # Displaying results fig , ax = fig_ax () _ = librosa . display . specshow ( tempogram , ax = ax , x_axis = \"s\" , y_axis = \"tempo\" , hop_length = hop_length_tempo , sr = sampling_rate , ) for b in bkps_times [: - 1 ]: ax . axvline ( b , ls = \"--\" , color = \"white\" , lw = 4 ) /opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/librosa/display.py:974: MatplotlibDeprecationWarning: The 'basey' parameter of __init__() has been renamed 'base' since Matplotlib 3.3; support for the old name will be dropped two minor releases later. scaler(mode, **kwargs) Visually, the estimated change points indeed separate portions of signal with a relatively constant tempo profile. Going back to the original music signal, this intuition can be verified by listening to the indivudal segments defined by the changes points. # Compute change points corresponding indexes in original signal bkps_time_indexes = ( sampling_rate * bkps_times ) . astype ( int ) . tolist () for ( segment_number , ( start , end )) in enumerate ( rpt . utils . pairwise ([ 0 ] + bkps_time_indexes ), start = 1 ): segment = signal [ start : end ] print ( f \"Segment n\u00b0 { segment_number } (duration: { segment . size / sampling_rate : .2f } s)\" ) display ( Audio ( data = segment , rate = sampling_rate )) Segment n\u00b01 (duration: 1.76 s) Your browser does not support the audio element. Segment n\u00b02 (duration: 8.03 s) Your browser does not support the audio element. Segment n\u00b03 (duration: 8.46 s) Your browser does not support the audio element. Segment n\u00b04 (duration: 2.73 s) Your browser does not support the audio element. Segment n\u00b05 (duration: 5.97 s) Your browser does not support the audio element. Segment n\u00b06 (duration: 3.04 s) Your browser does not support the audio element. The first segment corresponds to the soundless part of the signal (visible on the plot of the signal enveloppe). The following segments correspond to different rythmic portions and the associated change points occur when various instruments enter or exit the play.","title":"Results"},{"location":"examples/music-segmentation/#conclusion","text":"This example shows how to apply ruptures on a music segmentation task. More precisely, we detected mean shifts on a well-suited representation (the tempogram) of a music signal. The number of changes was heuristically determined (with the \"elbow\" method) and the results agreed with visually and auditory intuition. Such results can then be used to characterize the structure of music and songs, for music classification, recommandation, instrument recognition, etc. This procedure could also be enriched with other musically relevant representations (e.g. the chromagram) to detect other types of changes.","title":"Conclusion"},{"location":"examples/music-segmentation/#authors","text":"This example notebook has been authored by Olivier Boulant and edited by Charles Truong.","title":"Authors"},{"location":"examples/music-segmentation/#references","text":"[Grosche2010] Grosche, P., M\u00fcller, M., & Kurth, F. (2010). Cyclic tempogram - a mid-level tempo representation for music signals. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5522\u20135525. [McFee2015] McFee, B., Raffel, C., Liang, D., Ellis, D. P. W., McVicar, M., Battenberg, E., & Nieto, O. (2015). Librosa: audio and music signal analysis in Python. Proceedings of the Python in Science Conference, 8, 18\u201325.","title":"References"},{"location":"examples/simple-usages-introduction/","text":"Simple usages #","title":"Introduction"},{"location":"examples/simple-usages-introduction/#simple-usages","text":"","title":"Simple usages"},{"location":"getting-started/basic-usage/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Basic usage # Info Try this notebook in an executable environment with Binder . Download this notebook here . Let us start with a simple example to illustrate the use of ruptures : generate a 3-dimensional piecewise constant signal with noise and estimate the change points. Setup # First, we make the necessary imports. import matplotlib.pyplot as plt # for display purposes import ruptures as rpt # our package Matplotlib is building the font cache; this may take a moment. Generate and display the signal # Let us generate a 3-dimensional piecewise constant signal with Gaussian noise. n_samples , n_dims , sigma = 1000 , 3 , 2 n_bkps = 4 # number of breakpoints signal , bkps = rpt . pw_constant ( n_samples , n_dims , n_bkps , noise_std = sigma ) The true change points of this synthetic signal are available in the bkps variable. print ( bkps ) [196, 396, 603, 806, 1000] Note that the first four element are change point indexes while the last is simply the number of samples. (This is a technical convention so that functions in ruptures always know the length of the signal at hand.) It is also possible to plot our \\(\\mathbb{R}^3\\) -valued signal along with the true change points with the rpt.display function. In the following image, the color changes whenever the mean of the signal shifts. fig , ax_array = rpt . display ( signal , bkps ) Change point detection # We can now perform change point detection, meaning that we find the indexes where the signal mean changes. To that end, we minimize the sum of squared errors when approximating the signal by a piecewise constant signal. Formally, for a signal \\(y_0,y_1,\\dots,y_{T-1}\\) ( \\(T\\) samples), we solve the following optimization problem, over all possible change positions \\(t_1<t_2<\\dots<t_K\\) (where the number \\(K\\) of changes is defined by the user): \\[ \\hat{t}_1, \\hat{t}_2,\\dots,\\hat{t}_K = \\arg\\min_{t_1,\\dots,t_K} V(t_1,t_2,\\dots,t_K) \\] with \\[ V(t_1,t_2,\\dots,t_K) := \\sum_{k=0}^K\\sum_{t=t_k}^{t_{k+1}-1} \\|y_t-\\bar{y}_{t_k..t_{k+1}}\\|^2 \\] where \\(\\bar{y}_{t_k..t_{k+1}}\\) is the empirical mean of the sub-signal \\(y_{t_k}, y_{t_k+1},\\dots,y_{t_{k+1}-1}\\) . (By convention \\(t_0=0\\) and \\(t_{K+1}=T\\) .) This optimization is solved with dynamic programming, using the Dynp class. (More information in the section What is change point detection? and the User guide .) # detection algo = rpt . Dynp ( model = \"l2\" ) . fit ( signal ) result = algo . predict ( n_bkps = 4 ) print ( result ) [195, 395, 600, 805, 1000] Again the first elements are change point indexes and the last is the number of samples. Display the results # To visualy compare the true segmentation ( bkps ) and the estimated one ( result ), we can resort to rpt.display a second time. In the following image, the alternating colors indicate the true breakpoints and the dashed vertical lines, the estimated breakpoints. # display rpt . display ( signal , bkps , result ) plt . show () In this simple example, both are quite similar and almost undistinguishable.","title":"Basic usage"},{"location":"getting-started/basic-usage/#basic-usage","text":"Info Try this notebook in an executable environment with Binder . Download this notebook here . Let us start with a simple example to illustrate the use of ruptures : generate a 3-dimensional piecewise constant signal with noise and estimate the change points.","title":"Basic usage"},{"location":"getting-started/basic-usage/#setup","text":"First, we make the necessary imports. import matplotlib.pyplot as plt # for display purposes import ruptures as rpt # our package Matplotlib is building the font cache; this may take a moment.","title":"Setup"},{"location":"getting-started/basic-usage/#generate-and-display-the-signal","text":"Let us generate a 3-dimensional piecewise constant signal with Gaussian noise. n_samples , n_dims , sigma = 1000 , 3 , 2 n_bkps = 4 # number of breakpoints signal , bkps = rpt . pw_constant ( n_samples , n_dims , n_bkps , noise_std = sigma ) The true change points of this synthetic signal are available in the bkps variable. print ( bkps ) [196, 396, 603, 806, 1000] Note that the first four element are change point indexes while the last is simply the number of samples. (This is a technical convention so that functions in ruptures always know the length of the signal at hand.) It is also possible to plot our \\(\\mathbb{R}^3\\) -valued signal along with the true change points with the rpt.display function. In the following image, the color changes whenever the mean of the signal shifts. fig , ax_array = rpt . display ( signal , bkps )","title":"Generate and display the signal"},{"location":"getting-started/basic-usage/#change-point-detection","text":"We can now perform change point detection, meaning that we find the indexes where the signal mean changes. To that end, we minimize the sum of squared errors when approximating the signal by a piecewise constant signal. Formally, for a signal \\(y_0,y_1,\\dots,y_{T-1}\\) ( \\(T\\) samples), we solve the following optimization problem, over all possible change positions \\(t_1<t_2<\\dots<t_K\\) (where the number \\(K\\) of changes is defined by the user): \\[ \\hat{t}_1, \\hat{t}_2,\\dots,\\hat{t}_K = \\arg\\min_{t_1,\\dots,t_K} V(t_1,t_2,\\dots,t_K) \\] with \\[ V(t_1,t_2,\\dots,t_K) := \\sum_{k=0}^K\\sum_{t=t_k}^{t_{k+1}-1} \\|y_t-\\bar{y}_{t_k..t_{k+1}}\\|^2 \\] where \\(\\bar{y}_{t_k..t_{k+1}}\\) is the empirical mean of the sub-signal \\(y_{t_k}, y_{t_k+1},\\dots,y_{t_{k+1}-1}\\) . (By convention \\(t_0=0\\) and \\(t_{K+1}=T\\) .) This optimization is solved with dynamic programming, using the Dynp class. (More information in the section What is change point detection? and the User guide .) # detection algo = rpt . Dynp ( model = \"l2\" ) . fit ( signal ) result = algo . predict ( n_bkps = 4 ) print ( result ) [195, 395, 600, 805, 1000] Again the first elements are change point indexes and the last is the number of samples.","title":"Change point detection"},{"location":"getting-started/basic-usage/#display-the-results","text":"To visualy compare the true segmentation ( bkps ) and the estimated one ( result ), we can resort to rpt.display a second time. In the following image, the alternating colors indicate the true breakpoints and the dashed vertical lines, the estimated breakpoints. # display rpt . display ( signal , bkps , result ) plt . show () In this simple example, both are quite similar and almost undistinguishable.","title":"Display the results"},{"location":"user-guide/","text":"User guide # This section describes the algorithms and utility functions of ruptures . Each entry of the user guide is linked to a companion entry in the Code reference section, where the API is detailed.","title":"Introduction"},{"location":"user-guide/#user-guide","text":"This section describes the algorithms and utility functions of ruptures . Each entry of the user guide is linked to a companion entry in the Code reference section, where the API is detailed.","title":"User guide"},{"location":"user-guide/evaluation/","text":"Evaluation and visualization #","title":"Evaluation and visualization"},{"location":"user-guide/evaluation/#evaluation-and-visualization","text":"","title":"Evaluation and visualization"},{"location":"user-guide/costs/costautoregressive/","text":"Autoregressive model change ( CostAR ) # Description # Let \\(0<t_1<t_2<\\dots<n\\) be unknown change points indexes. Consider the following piecewise autoregressive model \\[ y_t = z_t' \\delta_j + \\varepsilon_t, \\quad \\forall t=t_j,\\dots,t_{j+1}-1 \\] where \\(j>1\\) is the segment number, \\(z_t=[y_{t-1}, y_{t-2},\\dots,y_{t-p}]\\) is the lag vector,and \\(p>0\\) is the order of the process. The least-squares estimates of the break dates is obtained by minimizing the sum of squared residuals [Bai2000] . Formally, the associated cost function on an interval \\(I\\) is \\[ c(y_{I}) = \\min_{\\delta\\in\\mathbb{R}^p} \\sum_{t\\in I} \\|y_t - \\delta' z_t \\|_2^2. \\] Currently, this function is limited to 1D signals. Usage # Start with the usual imports and create a signal with piecewise linear trends. from itertools import cycle import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 2000 n_bkps , sigma = 4 , 0.5 # number of change points, noise standart deviation bkps = [ 400 , 1000 , 1300 , 1800 , n ] f1 = np . array ([ 0.075 , 0.1 ]) f2 = np . array ([ 0.1 , 0.125 ]) freqs = np . zeros (( n , 2 )) for sub , val in zip ( np . split ( freqs , bkps [: - 1 ]), cycle ([ f1 , f2 ])): sub += val tt = np . arange ( n ) signal = np . sum (( np . sin ( 2 * np . pi * tt * f ) for f in freqs . T )) signal += np . random . normal ( scale = sigma , size = signal . shape ) # display signal rpt . show . display ( signal , bkps , figsize = ( 10 , 6 )) plt . show () Then create a CostAR instance and print the cost of the sub-signal signal[50:150] . The autoregressive order can be specified through the keyword 'order' . c = rpt . costs . CostAR ( order = 10 ) . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostAR instance (through the argument 'custom_cost' ) or set model=\"ar\" . Additional parameters can be passed to the cost instance through the keyword 'params' . c = rpt . costs . CostAR ( order = 10 ) algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"ar\" , params = { \"order\" : 10 }) Reference # [Bai2000] Bai, J. (2000). Vector autoregressive models with structural changes in regression coefficients and in variance\u2013covariance matrices. Annals of Economics and Finance, 1(2), 301\u2013336.","title":"CostAR"},{"location":"user-guide/costs/costautoregressive/#autoregressive-model-change-costar","text":"","title":"Autoregressive model change (CostAR)"},{"location":"user-guide/costs/costautoregressive/#description","text":"Let \\(0<t_1<t_2<\\dots<n\\) be unknown change points indexes. Consider the following piecewise autoregressive model \\[ y_t = z_t' \\delta_j + \\varepsilon_t, \\quad \\forall t=t_j,\\dots,t_{j+1}-1 \\] where \\(j>1\\) is the segment number, \\(z_t=[y_{t-1}, y_{t-2},\\dots,y_{t-p}]\\) is the lag vector,and \\(p>0\\) is the order of the process. The least-squares estimates of the break dates is obtained by minimizing the sum of squared residuals [Bai2000] . Formally, the associated cost function on an interval \\(I\\) is \\[ c(y_{I}) = \\min_{\\delta\\in\\mathbb{R}^p} \\sum_{t\\in I} \\|y_t - \\delta' z_t \\|_2^2. \\] Currently, this function is limited to 1D signals.","title":"Description"},{"location":"user-guide/costs/costautoregressive/#usage","text":"Start with the usual imports and create a signal with piecewise linear trends. from itertools import cycle import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 2000 n_bkps , sigma = 4 , 0.5 # number of change points, noise standart deviation bkps = [ 400 , 1000 , 1300 , 1800 , n ] f1 = np . array ([ 0.075 , 0.1 ]) f2 = np . array ([ 0.1 , 0.125 ]) freqs = np . zeros (( n , 2 )) for sub , val in zip ( np . split ( freqs , bkps [: - 1 ]), cycle ([ f1 , f2 ])): sub += val tt = np . arange ( n ) signal = np . sum (( np . sin ( 2 * np . pi * tt * f ) for f in freqs . T )) signal += np . random . normal ( scale = sigma , size = signal . shape ) # display signal rpt . show . display ( signal , bkps , figsize = ( 10 , 6 )) plt . show () Then create a CostAR instance and print the cost of the sub-signal signal[50:150] . The autoregressive order can be specified through the keyword 'order' . c = rpt . costs . CostAR ( order = 10 ) . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostAR instance (through the argument 'custom_cost' ) or set model=\"ar\" . Additional parameters can be passed to the cost instance through the keyword 'params' . c = rpt . costs . CostAR ( order = 10 ) algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"ar\" , params = { \"order\" : 10 })","title":"Usage"},{"location":"user-guide/costs/costautoregressive/#reference","text":"[Bai2000] Bai, J. (2000). Vector autoregressive models with structural changes in regression coefficients and in variance\u2013covariance matrices. Annals of Economics and Finance, 1(2), 301\u2013336.","title":"Reference"},{"location":"user-guide/costs/costclinear/","text":"Continuous linear change ( CostCLinear ) # Description # For a given set of indexes (also called knots) \\(t_k\\) ( \\(k=1,\\dots,K\\) ), a linear spline \\(f\\) is such that: \\(f\\) is affine on each interval \\(t_k..t_{k+1}\\) , i.e. \\(f(t)=\\alpha_k (t-t_k) + \\beta_k\\) ( \\(\\alpha_k, \\beta_k \\in \\mathbb{R}^d\\) ) for all \\(t=t_k,t_k+1,\\dots,t_{k+1}-1\\) ; \\(f\\) is continuous. The cost function CostCLinear measures the error when approximating the signal with a linear spline. Formally, it is defined for \\(0<a<b\\leq T\\) by \\[ c(y_{a..b}) := \\sum_{t=a}^{b-1} \\left\\lVert y_t - y_{a-1} - \\frac{t-a+1}{b-a}(y_{b-1}-y_{a-1}) \\right\\rVert^2 \\] and \\(c(y_{0..b}):=c(y_{1..b})\\) (by convention). Usage # Start with the usual imports and create a signal with piecewise linear trends. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n_samples , n_dims = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n_samples , n_dims , n_bkps , noise_std = sigma ) signal = np . cumsum ( signal , axis = 1 ) Then create a CostCLinear instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostCLinear () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostCLinear instance (through the argument custom_cost ) or set model=\"clinear\" . c = rpt . costs . CostCLinear () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"clinear\" )","title":"CostCLinear"},{"location":"user-guide/costs/costclinear/#continuous-linear-change-costclinear","text":"","title":"Continuous linear change (CostCLinear)"},{"location":"user-guide/costs/costclinear/#description","text":"For a given set of indexes (also called knots) \\(t_k\\) ( \\(k=1,\\dots,K\\) ), a linear spline \\(f\\) is such that: \\(f\\) is affine on each interval \\(t_k..t_{k+1}\\) , i.e. \\(f(t)=\\alpha_k (t-t_k) + \\beta_k\\) ( \\(\\alpha_k, \\beta_k \\in \\mathbb{R}^d\\) ) for all \\(t=t_k,t_k+1,\\dots,t_{k+1}-1\\) ; \\(f\\) is continuous. The cost function CostCLinear measures the error when approximating the signal with a linear spline. Formally, it is defined for \\(0<a<b\\leq T\\) by \\[ c(y_{a..b}) := \\sum_{t=a}^{b-1} \\left\\lVert y_t - y_{a-1} - \\frac{t-a+1}{b-a}(y_{b-1}-y_{a-1}) \\right\\rVert^2 \\] and \\(c(y_{0..b}):=c(y_{1..b})\\) (by convention).","title":"Description"},{"location":"user-guide/costs/costclinear/#usage","text":"Start with the usual imports and create a signal with piecewise linear trends. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n_samples , n_dims = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n_samples , n_dims , n_bkps , noise_std = sigma ) signal = np . cumsum ( signal , axis = 1 ) Then create a CostCLinear instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostCLinear () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostCLinear instance (through the argument custom_cost ) or set model=\"clinear\" . c = rpt . costs . CostCLinear () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"clinear\" )","title":"Usage"},{"location":"user-guide/costs/costcosine/","text":"Kernelized mean change ( CostCosine ) # Description # Given a positive semi-definite kernel \\(k(\\cdot, \\cdot) : \\mathbb{R}^d\\times \\mathbb{R}^d \\mapsto \\mathbb{R}\\) and its associated feature map \\(\\Phi:\\mathbb{R}^d \\mapsto \\mathcal{H}\\) (where \\(\\mathcal{H}\\) is an appropriate Hilbert space), this cost function detects changes in the mean of the embedded signal \\(\\{\\Phi(y_t)\\}_t\\) [ Arlot2019 ]. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{a..b}) = \\sum_{t=a}^{b-1} \\| \\Phi(y_t) - \\bar{\\mu} \\|_{\\mathcal{H}}^2 \\] where \\(\\bar{\\mu}_{a..b}\\) is the empirical mean of the embedded sub-signal \\(\\{\\Phi(y_t)\\}_{a\\leq t < b-1}\\) . Here the kernel is the cosine similarity: \\[ k(x, y) = \\frac{\\langle x\\mid y\\rangle}{\\|x\\|\\|y\\|} \\] where \\(\\langle \\cdot\\mid\\cdot \\rangle\\) and \\(\\| \\cdot \\|\\) are the Euclidean scalar product and norm respectively. In other words, it is equal to the L2-normalized dot product of vectors. This cost function has been used for music segmentation tasks [ Cooper2002 ] and topic segmentation of text [ Hearst1994 ]. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostCosine instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostCosine () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostCosine instance (through the argument custom_cost ) or set model=\"cosine\" . c = rpt . costs . CostCosine () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"cosine\" ) References # [Hearst1994] Hearst, M. A. (1994). Multi-paragraph segmentation of expository text. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (pp. 9\u201316). Las Cruces, New Mexico, USA. [Cooper2002] Cooper, M., & Foote, J. (2002). Automatic music summarization via similarity analysis. In Proceedings of the International Conference on Music Information Retrieval (ISMIR) (pp. 81\u201385). Paris, France. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"CostCosine"},{"location":"user-guide/costs/costcosine/#kernelized-mean-change-costcosine","text":"","title":"Kernelized mean change (CostCosine)"},{"location":"user-guide/costs/costcosine/#description","text":"Given a positive semi-definite kernel \\(k(\\cdot, \\cdot) : \\mathbb{R}^d\\times \\mathbb{R}^d \\mapsto \\mathbb{R}\\) and its associated feature map \\(\\Phi:\\mathbb{R}^d \\mapsto \\mathcal{H}\\) (where \\(\\mathcal{H}\\) is an appropriate Hilbert space), this cost function detects changes in the mean of the embedded signal \\(\\{\\Phi(y_t)\\}_t\\) [ Arlot2019 ]. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{a..b}) = \\sum_{t=a}^{b-1} \\| \\Phi(y_t) - \\bar{\\mu} \\|_{\\mathcal{H}}^2 \\] where \\(\\bar{\\mu}_{a..b}\\) is the empirical mean of the embedded sub-signal \\(\\{\\Phi(y_t)\\}_{a\\leq t < b-1}\\) . Here the kernel is the cosine similarity: \\[ k(x, y) = \\frac{\\langle x\\mid y\\rangle}{\\|x\\|\\|y\\|} \\] where \\(\\langle \\cdot\\mid\\cdot \\rangle\\) and \\(\\| \\cdot \\|\\) are the Euclidean scalar product and norm respectively. In other words, it is equal to the L2-normalized dot product of vectors. This cost function has been used for music segmentation tasks [ Cooper2002 ] and topic segmentation of text [ Hearst1994 ].","title":"Description"},{"location":"user-guide/costs/costcosine/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostCosine instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostCosine () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostCosine instance (through the argument custom_cost ) or set model=\"cosine\" . c = rpt . costs . CostCosine () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"cosine\" )","title":"Usage"},{"location":"user-guide/costs/costcosine/#references","text":"[Hearst1994] Hearst, M. A. (1994). Multi-paragraph segmentation of expository text. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (pp. 9\u201316). Las Cruces, New Mexico, USA. [Cooper2002] Cooper, M., & Foote, J. (2002). Automatic music summarization via similarity analysis. In Proceedings of the International Conference on Music Information Retrieval (ISMIR) (pp. 81\u201385). Paris, France. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"References"},{"location":"user-guide/costs/costcustom/","text":"Custom cost class # Users who are interested in detecting a specific type of change can easily do so by creating a custom cost function. Provided, they subclass the base cost function BaseCost , they will be able to seamlessly run the algorithms implemented in ruptures . Important The custom cost class must at least implement the two following methods: .fit(signal) and .error(start, end) (see user guide ). Example # Let \\(\\{y_t\\}_t\\) denote a 1D piecewise stationary random process. Assume that the \\(y_t\\) are independent and exponentially distributed with a scale parameter that shifts at some unknown instants \\(t_1,t_2,\\dots\\) The change points estimates are the minimizers of the negative log-likelihood, and the associated cost function is given by \\[ c(y_I) = |I| \\log \\bar{\\mu}_I \\] where \\(I,\\, y_I\\) and \\(\\bar{\\mu}_I\\) are respectively an interval, the sub-signal on this interval and the empirical mean of this sub-signal. The following code implements this cost function: from math import log from ruptures.base import BaseCost class MyCost ( BaseCost ): \"\"\"Custom cost for exponential signals.\"\"\" # The 2 following attributes must be specified for compatibility. model = \"\" min_size = 2 def fit ( self , signal ): \"\"\"Set the internal parameter.\"\"\" self . signal = signal return self def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost \"\"\" sub = self . signal [ start : end ] return ( end - start ) * log ( sub . mean ()) Warning For compatibility reasons, the static attributes model and min_size must be explicitly specified: model is simply a string containing the name of the cost function (can be empty); min_size is a positive integer that indicates the minimum segment size (in number of samples) on which the cost function can be applied. This cost function can now be used with all algorithms from ruptures . For instance, import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data a = np . random . exponential ( scale = 1 , size = 100 ) b = np . random . exponential ( scale = 2 , size = 200 ) signal , bkps = np . r_ [ a , b , a ], [ 100 , 300 , 400 ] # cost algo = rpt . Pelt ( custom_cost = MyCost ()) . fit ( signal ) my_bkps = algo . predict ( pen = 10 ) # display rpt . display ( signal , bkps , my_bkps ) plt . show ()","title":"Custom cost"},{"location":"user-guide/costs/costcustom/#custom-cost-class","text":"Users who are interested in detecting a specific type of change can easily do so by creating a custom cost function. Provided, they subclass the base cost function BaseCost , they will be able to seamlessly run the algorithms implemented in ruptures . Important The custom cost class must at least implement the two following methods: .fit(signal) and .error(start, end) (see user guide ).","title":"Custom cost class"},{"location":"user-guide/costs/costcustom/#example","text":"Let \\(\\{y_t\\}_t\\) denote a 1D piecewise stationary random process. Assume that the \\(y_t\\) are independent and exponentially distributed with a scale parameter that shifts at some unknown instants \\(t_1,t_2,\\dots\\) The change points estimates are the minimizers of the negative log-likelihood, and the associated cost function is given by \\[ c(y_I) = |I| \\log \\bar{\\mu}_I \\] where \\(I,\\, y_I\\) and \\(\\bar{\\mu}_I\\) are respectively an interval, the sub-signal on this interval and the empirical mean of this sub-signal. The following code implements this cost function: from math import log from ruptures.base import BaseCost class MyCost ( BaseCost ): \"\"\"Custom cost for exponential signals.\"\"\" # The 2 following attributes must be specified for compatibility. model = \"\" min_size = 2 def fit ( self , signal ): \"\"\"Set the internal parameter.\"\"\" self . signal = signal return self def error ( self , start , end ): \"\"\"Return the approximation cost on the segment [start:end]. Args: start (int): start of the segment end (int): end of the segment Returns: float: segment cost \"\"\" sub = self . signal [ start : end ] return ( end - start ) * log ( sub . mean ()) Warning For compatibility reasons, the static attributes model and min_size must be explicitly specified: model is simply a string containing the name of the cost function (can be empty); min_size is a positive integer that indicates the minimum segment size (in number of samples) on which the cost function can be applied. This cost function can now be used with all algorithms from ruptures . For instance, import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data a = np . random . exponential ( scale = 1 , size = 100 ) b = np . random . exponential ( scale = 2 , size = 200 ) signal , bkps = np . r_ [ a , b , a ], [ 100 , 300 , 400 ] # cost algo = rpt . Pelt ( custom_cost = MyCost ()) . fit ( signal ) my_bkps = algo . predict ( pen = 10 ) # display rpt . display ( signal , bkps , my_bkps ) plt . show ()","title":"Example"},{"location":"user-guide/costs/costl1/","text":"Least absolute deviation ( CostL1 ) # Description # This cost function detects changes in the median of a signal. Overall, it is a robust estimator of a shift in the central point (mean, median, mode) of a distribution [Bai1995] . Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\|y_t - \\bar{y}\\|_1 \\] where \\(\\bar{y}\\) is the componentwise median of \\(\\{y_t\\}_{t\\in I}\\) . Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostL1 instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostL1 () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator , either pass a CostL1 instance (through the argument custom_cost ) or set model=\"l1\" . c = rpt . costs . CostL1 () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"l1\" ) References # [Bai1995] Bai, J. (1995). Least absolute deviation of a shift. Econometric Theory, 11(3), 403\u2013436.","title":"CostL1"},{"location":"user-guide/costs/costl1/#least-absolute-deviation-costl1","text":"","title":"Least absolute deviation (CostL1)"},{"location":"user-guide/costs/costl1/#description","text":"This cost function detects changes in the median of a signal. Overall, it is a robust estimator of a shift in the central point (mean, median, mode) of a distribution [Bai1995] . Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\|y_t - \\bar{y}\\|_1 \\] where \\(\\bar{y}\\) is the componentwise median of \\(\\{y_t\\}_{t\\in I}\\) .","title":"Description"},{"location":"user-guide/costs/costl1/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostL1 instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostL1 () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator , either pass a CostL1 instance (through the argument custom_cost ) or set model=\"l1\" . c = rpt . costs . CostL1 () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"l1\" )","title":"Usage"},{"location":"user-guide/costs/costl1/#references","text":"[Bai1995] Bai, J. (1995). Least absolute deviation of a shift. Econometric Theory, 11(3), 403\u2013436.","title":"References"},{"location":"user-guide/costs/costl2/","text":"Least squared deviation ( CostL2 ) # Description # This cost function detects mean-shifts in a signal. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\|y_t - \\bar{y}\\|_2^2 \\] where \\(\\bar{y}\\) is the mean of \\(\\{y_t\\}_{t\\in I}\\) . Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostL2 instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostL2 () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostL2 instance (through the argument custom_cost ) or set model=\"l2\" . c = rpt . costs . CostL2 () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"l2\" )","title":"CostL2"},{"location":"user-guide/costs/costl2/#least-squared-deviation-costl2","text":"","title":"Least squared deviation (CostL2)"},{"location":"user-guide/costs/costl2/#description","text":"This cost function detects mean-shifts in a signal. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\|y_t - \\bar{y}\\|_2^2 \\] where \\(\\bar{y}\\) is the mean of \\(\\{y_t\\}_{t\\in I}\\) .","title":"Description"},{"location":"user-guide/costs/costl2/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostL2 instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostL2 () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostL2 instance (through the argument custom_cost ) or set model=\"l2\" . c = rpt . costs . CostL2 () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"l2\" )","title":"Usage"},{"location":"user-guide/costs/costlinear/","text":"Linear model change ( CostLinear ) # Description # Let \\(0 < t_1 < t_2 < \\dots < n\\) be unknown change points indexes. Consider the following multiple linear regression model \\[ y_t = x_t' \\delta_j + \\varepsilon_t, \\quad \\forall t=t_j,\\dots,t_{j+1}-1 \\] for \\(j>1\\) . Here, the observed dependant variable is \\(y_t\\in\\mathbb{R}\\) , the covariate vector is \\(x_t \\in\\mathbb{R}^p\\) , the disturbance is \\(\\varepsilon_t\\in\\mathbb{R}\\) . The vectors \\(\\delta_j\\in\\mathbb{R}^p\\) are the parameter vectors (or regression coefficients). The least-squares estimates of the break dates is obtained by minimizing the sum of squared residuals [Bai2003] . Formally, the associated cost function on an interval \\(I\\) is \\[ c(y_{I}) = \\min_{\\delta\\in\\mathbb{R}^p} \\sum_{t\\in I} \\|y_t - \\delta' x_t \\|_2^2. \\] Usage # Start with the usual imports and create a signal with piecewise linear trends. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , n_reg = 2000 , 3 # number of samples, number of regressors (including intercept) n_bkps = 3 # number of change points # regressors tt = np . linspace ( 0 , 10 * np . pi , n ) X = np . vstack (( np . sin ( tt ), np . sin ( 5 * tt ), np . ones ( n ))) . T # parameter vectors deltas , bkps = rpt . pw_constant ( n , n_reg , n_bkps , noise_std = None , delta = ( 1 , 3 )) # observed signal y = np . sum ( X * deltas , axis = 1 ) y += np . random . normal ( size = y . shape ) # display signal rpt . show . display ( y , bkps , figsize = ( 10 , 6 )) plt . show () Then create a CostLinear instance and print the cost of the sub-signal signal[50:150] . # stack observed signal and regressors. # first dimension is the observed signal. signal = np . column_stack (( y . reshape ( - 1 , 1 ), X )) c = rpt . costs . CostLinear () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostLinear instance (through the argument custom_cost ) or set model=\"linear\" . c = rpt . costs . CostLinear () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"linear\" ) References # [Bai2003] J. Bai and P. Perron. Critical values for multiple structural change tests. Econometrics Journal, 6(1):72\u201378, 2003.","title":"CostLinear"},{"location":"user-guide/costs/costlinear/#linear-model-change-costlinear","text":"","title":"Linear model change (CostLinear)"},{"location":"user-guide/costs/costlinear/#description","text":"Let \\(0 < t_1 < t_2 < \\dots < n\\) be unknown change points indexes. Consider the following multiple linear regression model \\[ y_t = x_t' \\delta_j + \\varepsilon_t, \\quad \\forall t=t_j,\\dots,t_{j+1}-1 \\] for \\(j>1\\) . Here, the observed dependant variable is \\(y_t\\in\\mathbb{R}\\) , the covariate vector is \\(x_t \\in\\mathbb{R}^p\\) , the disturbance is \\(\\varepsilon_t\\in\\mathbb{R}\\) . The vectors \\(\\delta_j\\in\\mathbb{R}^p\\) are the parameter vectors (or regression coefficients). The least-squares estimates of the break dates is obtained by minimizing the sum of squared residuals [Bai2003] . Formally, the associated cost function on an interval \\(I\\) is \\[ c(y_{I}) = \\min_{\\delta\\in\\mathbb{R}^p} \\sum_{t\\in I} \\|y_t - \\delta' x_t \\|_2^2. \\]","title":"Description"},{"location":"user-guide/costs/costlinear/#usage","text":"Start with the usual imports and create a signal with piecewise linear trends. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , n_reg = 2000 , 3 # number of samples, number of regressors (including intercept) n_bkps = 3 # number of change points # regressors tt = np . linspace ( 0 , 10 * np . pi , n ) X = np . vstack (( np . sin ( tt ), np . sin ( 5 * tt ), np . ones ( n ))) . T # parameter vectors deltas , bkps = rpt . pw_constant ( n , n_reg , n_bkps , noise_std = None , delta = ( 1 , 3 )) # observed signal y = np . sum ( X * deltas , axis = 1 ) y += np . random . normal ( size = y . shape ) # display signal rpt . show . display ( y , bkps , figsize = ( 10 , 6 )) plt . show () Then create a CostLinear instance and print the cost of the sub-signal signal[50:150] . # stack observed signal and regressors. # first dimension is the observed signal. signal = np . column_stack (( y . reshape ( - 1 , 1 ), X )) c = rpt . costs . CostLinear () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostLinear instance (through the argument custom_cost ) or set model=\"linear\" . c = rpt . costs . CostLinear () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"linear\" )","title":"Usage"},{"location":"user-guide/costs/costlinear/#references","text":"[Bai2003] J. Bai and P. Perron. Critical values for multiple structural change tests. Econometrics Journal, 6(1):72\u201378, 2003.","title":"References"},{"location":"user-guide/costs/costml/","text":"Change detection with a Mahalanobis-type metric ( CostMl ) # Description # Given a positive semi-definite matrix \\(M\\in\\mathbb{R}^{d\\times d}\\) , this cost function detects changes in the mean of the embedded signal defined by the pseudo-metric \\[ \\| x - y \\|_M^2 = (x-y)^t M (x-y). \\] Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , the cost function is equal to \\[ c(y_{I}) = \\sum_{t\\in I} \\| y_t - \\bar{\\mu} \\|_{M}^2 \\] where \\(\\bar{\\mu}\\) is the empirical mean of the sub-signal \\(\\{y_t\\}_{t\\in I}\\) . The matrix \\(M\\) can for instance be the result of a similarity learning algorithm [ Xing2003 , Truong2019 ] or the inverse of the empirical covariance matrix (yielding the Mahalanobis distance). Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostMl instance and print the cost of the sub-signal signal[50:150] . M = np . eye ( dim ) c = rpt . costs . CostMl ( metric = M ) . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostMl instance (through the argument custom_cost ) or set model=\"mahalanobis\" . c = rpt . costs . CostMl ( metric = M ) algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"mahalanobis\" , params = { \"metric\" : M }) References # [Xing2003] Xing, E. P., Jordan, M. I., & Russell, S. J. (2003). Distance metric learning, with application to clustering with side-Information. Advances in Neural Information Processing Systems (NIPS), 521\u2013528. [Truong2019] Truong, C., Oudre, L., & Vayatis, N. (2019). Supervised kernel change point detection with partial annotations. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1\u20135.","title":"CostMl"},{"location":"user-guide/costs/costml/#change-detection-with-a-mahalanobis-type-metric-costml","text":"","title":"Change detection with a Mahalanobis-type metric (CostMl)"},{"location":"user-guide/costs/costml/#description","text":"Given a positive semi-definite matrix \\(M\\in\\mathbb{R}^{d\\times d}\\) , this cost function detects changes in the mean of the embedded signal defined by the pseudo-metric \\[ \\| x - y \\|_M^2 = (x-y)^t M (x-y). \\] Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , the cost function is equal to \\[ c(y_{I}) = \\sum_{t\\in I} \\| y_t - \\bar{\\mu} \\|_{M}^2 \\] where \\(\\bar{\\mu}\\) is the empirical mean of the sub-signal \\(\\{y_t\\}_{t\\in I}\\) . The matrix \\(M\\) can for instance be the result of a similarity learning algorithm [ Xing2003 , Truong2019 ] or the inverse of the empirical covariance matrix (yielding the Mahalanobis distance).","title":"Description"},{"location":"user-guide/costs/costml/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostMl instance and print the cost of the sub-signal signal[50:150] . M = np . eye ( dim ) c = rpt . costs . CostMl ( metric = M ) . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostMl instance (through the argument custom_cost ) or set model=\"mahalanobis\" . c = rpt . costs . CostMl ( metric = M ) algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"mahalanobis\" , params = { \"metric\" : M })","title":"Usage"},{"location":"user-guide/costs/costml/#references","text":"[Xing2003] Xing, E. P., Jordan, M. I., & Russell, S. J. (2003). Distance metric learning, with application to clustering with side-Information. Advances in Neural Information Processing Systems (NIPS), 521\u2013528. [Truong2019] Truong, C., Oudre, L., & Vayatis, N. (2019). Supervised kernel change point detection with partial annotations. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1\u20135.","title":"References"},{"location":"user-guide/costs/costnormal/","text":"Gaussian process change ( CostNormal ) # Description # This cost function detects changes in the mean and covariance matrix of a sequence of multivariate Gaussian random variables. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , $$ c(y_{I}) = |I| \\log\\det\\widehat{\\Sigma}_I $$ where \\(\\widehat{\\Sigma}_I\\) is the empirical covariance matrix of the sub-signal \\(\\{y_t\\}_{t\\in I}\\) . It is robust to strongly dependant processes; for more information, see [Lavielle1999] (univariate case) and [Lavielle2006] (multivariate case). Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostNormal instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostNormal () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostNormal instance (through the argument custom_cost ) or set model=\"normal\" . c = rpt . costs . CostNormal () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"normal\" ) References # [Lavielle1999] Lavielle, M. (1999). Detection of multiples changes in a sequence of dependant variables. Stochastic Processes and Their Applications, 83(1), 79\u2013102. [Lavielle2006] Lavielle, M., & Teyssi\u00e8re, G. (2006). Detection of multiple change-points in multivariate time series. Lithuanian Mathematical Journal, 46(3).","title":"CostNormal"},{"location":"user-guide/costs/costnormal/#gaussian-process-change-costnormal","text":"","title":"Gaussian process change (CostNormal)"},{"location":"user-guide/costs/costnormal/#description","text":"This cost function detects changes in the mean and covariance matrix of a sequence of multivariate Gaussian random variables. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , $$ c(y_{I}) = |I| \\log\\det\\widehat{\\Sigma}_I $$ where \\(\\widehat{\\Sigma}_I\\) is the empirical covariance matrix of the sub-signal \\(\\{y_t\\}_{t\\in I}\\) . It is robust to strongly dependant processes; for more information, see [Lavielle1999] (univariate case) and [Lavielle2006] (multivariate case).","title":"Description"},{"location":"user-guide/costs/costnormal/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostNormal instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostNormal () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostNormal instance (through the argument custom_cost ) or set model=\"normal\" . c = rpt . costs . CostNormal () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"normal\" )","title":"Usage"},{"location":"user-guide/costs/costnormal/#references","text":"[Lavielle1999] Lavielle, M. (1999). Detection of multiples changes in a sequence of dependant variables. Stochastic Processes and Their Applications, 83(1), 79\u2013102. [Lavielle2006] Lavielle, M., & Teyssi\u00e8re, G. (2006). Detection of multiple change-points in multivariate time series. Lithuanian Mathematical Journal, 46(3).","title":"References"},{"location":"user-guide/costs/costrank/","text":"Rank-based cost function ( CostRank ) # Description # This cost function detects general distribution changes in multivariate signals, using a rank transformation [Lung-Yut-Fong2015] . Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\([a, b)\\) , \\[ c_{rank}(a, b) = -(b - a) \\bar{r}_{a..b}' \\hat{\\Sigma}_r^{-1} \\bar{r}_{a..b} \\] where \\(\\bar{r}_{a..b}\\) is the empirical mean of the sub-signal \\(\\{r_t\\}_{t=a+1}^b\\) , and \\(\\hat{\\Sigma}_r\\) is the covariance matrix of the complete rank signal \\(r\\) . Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostRank instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostRank () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostRank instance (through the argument custom_cost ) or set model=\"rank\" . c = rpt . costs . CostRank () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"rank\" ) References # [Lung-Yut-Fong2015] Lung-Yut-Fong, A., L\u00e9vy-Leduc, C., & Capp\u00e9, O. (2015). Homogeneity and change-point detection tests for multivariate data using rank statistics. Journal de La Soci\u00e9t\u00e9 Fran\u00e7aise de Statistique, 156(4), 133\u2013162.","title":"CostRank"},{"location":"user-guide/costs/costrank/#rank-based-cost-function-costrank","text":"","title":"Rank-based cost function (CostRank)"},{"location":"user-guide/costs/costrank/#description","text":"This cost function detects general distribution changes in multivariate signals, using a rank transformation [Lung-Yut-Fong2015] . Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\([a, b)\\) , \\[ c_{rank}(a, b) = -(b - a) \\bar{r}_{a..b}' \\hat{\\Sigma}_r^{-1} \\bar{r}_{a..b} \\] where \\(\\bar{r}_{a..b}\\) is the empirical mean of the sub-signal \\(\\{r_t\\}_{t=a+1}^b\\) , and \\(\\hat{\\Sigma}_r\\) is the covariance matrix of the complete rank signal \\(r\\) .","title":"Description"},{"location":"user-guide/costs/costrank/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostRank instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostRank () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostRank instance (through the argument custom_cost ) or set model=\"rank\" . c = rpt . costs . CostRank () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"rank\" )","title":"Usage"},{"location":"user-guide/costs/costrank/#references","text":"[Lung-Yut-Fong2015] Lung-Yut-Fong, A., L\u00e9vy-Leduc, C., & Capp\u00e9, O. (2015). Homogeneity and change-point detection tests for multivariate data using rank statistics. Journal de La Soci\u00e9t\u00e9 Fran\u00e7aise de Statistique, 156(4), 133\u2013162.","title":"References"},{"location":"user-guide/costs/costrbf/","text":"Kernelized mean change ( CostRbf ) # Description # Given a positive semi-definite kernel \\(k(\\cdot, \\cdot) : \\mathbb{R}^d\\times \\mathbb{R}^d \\mapsto \\mathbb{R}\\) and its associated feature map \\(\\Phi:\\mathbb{R}^d \\mapsto \\mathcal{H}\\) (where \\(\\mathcal{H}\\) is an appropriate Hilbert space), this cost function detects changes in the mean of the embedded signal \\(\\{\\Phi(y_t)\\}_t\\) [ Garreau2018 , Arlot2019 ]. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\| \\Phi(y_t) - \\bar{\\mu} \\|_{\\mathcal{H}}^2 \\] where \\(\\bar{\\mu}\\) is the empirical mean of the embedded sub-signal \\(\\{\\Phi(y_t)\\}_{t\\in I}\\) . Here the kernel is the radial basis function (rbf): \\[ k(x, y) = \\exp(-\\gamma \\| x - y \\|^2 ) \\] where \\(\\| \\cdot \\|\\) is the Euclidean norm and \\(\\gamma>0\\) is the so-called bandwidth parameter and is determined according to median heuristics (i.e. equal to the inverse of median of all pairwise distances). In a nutshell, this cost function is able to detect changes in the distribution of an iid sequence of random variables. Because it is non-parametric, it is performs reasonably well on a wide range of tasks. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostRbf instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostRbf () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostRbf instance (through the argument custom_cost ) or set model=\"rbf\" . c = rpt . costs . CostRbf () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"rbf\" ) References # [Garreau2018] Garreau, D., & Arlot, S. (2018). Consistent change-point detection with kernels. Electronic Journal of Statistics, 12(2), 4440\u20134486. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"CostRbf"},{"location":"user-guide/costs/costrbf/#kernelized-mean-change-costrbf","text":"","title":"Kernelized mean change (CostRbf)"},{"location":"user-guide/costs/costrbf/#description","text":"Given a positive semi-definite kernel \\(k(\\cdot, \\cdot) : \\mathbb{R}^d\\times \\mathbb{R}^d \\mapsto \\mathbb{R}\\) and its associated feature map \\(\\Phi:\\mathbb{R}^d \\mapsto \\mathcal{H}\\) (where \\(\\mathcal{H}\\) is an appropriate Hilbert space), this cost function detects changes in the mean of the embedded signal \\(\\{\\Phi(y_t)\\}_t\\) [ Garreau2018 , Arlot2019 ]. Formally, for a signal \\(\\{y_t\\}_t\\) on an interval \\(I\\) , \\[ c(y_{I}) = \\sum_{t\\in I} \\| \\Phi(y_t) - \\bar{\\mu} \\|_{\\mathcal{H}}^2 \\] where \\(\\bar{\\mu}\\) is the empirical mean of the embedded sub-signal \\(\\{\\Phi(y_t)\\}_{t\\in I}\\) . Here the kernel is the radial basis function (rbf): \\[ k(x, y) = \\exp(-\\gamma \\| x - y \\|^2 ) \\] where \\(\\| \\cdot \\|\\) is the Euclidean norm and \\(\\gamma>0\\) is the so-called bandwidth parameter and is determined according to median heuristics (i.e. equal to the inverse of median of all pairwise distances). In a nutshell, this cost function is able to detect changes in the distribution of an iid sequence of random variables. Because it is non-parametric, it is performs reasonably well on a wide range of tasks.","title":"Description"},{"location":"user-guide/costs/costrbf/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) Then create a CostRbf instance and print the cost of the sub-signal signal[50:150] . c = rpt . costs . CostRbf () . fit ( signal ) print ( c . error ( 50 , 150 )) You can also compute the sum of costs for a given list of change points. print ( c . sum_of_costs ( bkps )) print ( c . sum_of_costs ([ 10 , 100 , 200 , 250 , n ])) In order to use this cost class in a change point detection algorithm (inheriting from BaseEstimator ), either pass a CostRbf instance (through the argument custom_cost ) or set model=\"rbf\" . c = rpt . costs . CostRbf () algo = rpt . Dynp ( custom_cost = c ) # is equivalent to algo = rpt . Dynp ( model = \"rbf\" )","title":"Usage"},{"location":"user-guide/costs/costrbf/#references","text":"[Garreau2018] Garreau, D., & Arlot, S. (2018). Consistent change-point detection with kernels. Electronic Journal of Statistics, 12(2), 4440\u20134486. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"References"},{"location":"user-guide/datasets/pw_constant/","text":"Piecewise constant ( pw_constant ) # Description # For a given number of samples \\(T\\) , number \\(K\\) of change points and noise variance \\(\\sigma^2\\) , the function pw_constant generates change point dexes \\(0 < t_1 < \\dots < t_K < T\\) and a piecewise constant signal \\(\\{y_t\\}_t\\) with additive Gaussian noise. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps ) The mean shift amplitude is uniformly drawn from an interval that can be changed through the keyword delta . signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma , delta = ( 1 , 10 ))","title":"Piecewise constant"},{"location":"user-guide/datasets/pw_constant/#piecewise-constant-pw_constant","text":"","title":"Piecewise constant (pw_constant)"},{"location":"user-guide/datasets/pw_constant/#description","text":"For a given number of samples \\(T\\) , number \\(K\\) of change points and noise variance \\(\\sigma^2\\) , the function pw_constant generates change point dexes \\(0 < t_1 < \\dots < t_K < T\\) and a piecewise constant signal \\(\\{y_t\\}_t\\) with additive Gaussian noise.","title":"Description"},{"location":"user-guide/datasets/pw_constant/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps ) The mean shift amplitude is uniformly drawn from an interval that can be changed through the keyword delta . signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma , delta = ( 1 , 10 ))","title":"Usage"},{"location":"user-guide/datasets/pw_linear/","text":"Piecewise linear ( pw_linear ) # Description # This function pw_linear simulates a piecewise linear model (see Cost linear ). The covariates are standard Gaussian random variables. The response variable is a (piecewise) linear combination of the covariates. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension of the covariates n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_linear ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps )","title":"Piecewise linear"},{"location":"user-guide/datasets/pw_linear/#piecewise-linear-pw_linear","text":"","title":"Piecewise linear (pw_linear)"},{"location":"user-guide/datasets/pw_linear/#description","text":"This function pw_linear simulates a piecewise linear model (see Cost linear ). The covariates are standard Gaussian random variables. The response variable is a (piecewise) linear combination of the covariates.","title":"Description"},{"location":"user-guide/datasets/pw_linear/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension of the covariates n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_linear ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps )","title":"Usage"},{"location":"user-guide/datasets/pw_normal/","text":"Piecewise 2D Gaussian process ( pw_normal ) # Description # The function pw_normal simulates a 2D signal of Gaussian i.i.d. random variables with zero mean and covariance matrix alternating between \\([[1, 0.9], [0.9, 1]]\\) and \\([[1, -0.9], [-0.9, 1]]\\) at every change point. Top and middle: 2D signal example. Bottom: Scatter plot for each regime type Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 500 , 3 # number of samples n_bkps = 3 # number of change points, noise standart deviation signal , bkps = rpt . pw_normal ( n , n_bkps ) rpt . display ( signal , bkps )","title":"Piecewise Gaussian"},{"location":"user-guide/datasets/pw_normal/#piecewise-2d-gaussian-process-pw_normal","text":"","title":"Piecewise 2D Gaussian process (pw_normal)"},{"location":"user-guide/datasets/pw_normal/#description","text":"The function pw_normal simulates a 2D signal of Gaussian i.i.d. random variables with zero mean and covariance matrix alternating between \\([[1, 0.9], [0.9, 1]]\\) and \\([[1, -0.9], [-0.9, 1]]\\) at every change point. Top and middle: 2D signal example. Bottom: Scatter plot for each regime type","title":"Description"},{"location":"user-guide/datasets/pw_normal/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 500 , 3 # number of samples n_bkps = 3 # number of change points, noise standart deviation signal , bkps = rpt . pw_normal ( n , n_bkps ) rpt . display ( signal , bkps )","title":"Usage"},{"location":"user-guide/datasets/pw_wavy/","text":"Piecewise sinusoidal signal ( pw_wavy ) # Description # The function pw_wavy simulates a sum-of-sine signal \\(y_t=\\sin(2\\pi f_1 t)+\\sin(2\\pi f_2 t)\\) where \\(t=0,\\dots,T-1\\) . The frequency vector \\([f_1, f_2]\\) alternates between \\([0.075, 0.1]\\) and \\([0.1, 0.125]\\) at each change point index. Gaussian white noise can be added to the signal. Top: signal example. Bottom: associated spectrogram. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_wavy ( n , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps )","title":"Piecewise sinusoidal"},{"location":"user-guide/datasets/pw_wavy/#piecewise-sinusoidal-signal-pw_wavy","text":"","title":"Piecewise sinusoidal signal (pw_wavy)"},{"location":"user-guide/datasets/pw_wavy/#description","text":"The function pw_wavy simulates a sum-of-sine signal \\(y_t=\\sin(2\\pi f_1 t)+\\sin(2\\pi f_2 t)\\) where \\(t=0,\\dots,T-1\\) . The frequency vector \\([f_1, f_2]\\) alternates between \\([0.075, 0.1]\\) and \\([0.1, 0.125]\\) at each change point index. Gaussian white noise can be added to the signal. Top: signal example. Bottom: associated spectrogram.","title":"Description"},{"location":"user-guide/datasets/pw_wavy/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_wavy ( n , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps )","title":"Usage"},{"location":"user-guide/detection/binseg/","text":"Binary segmentation ( Binseg ) # Description # Binary change point detection is used to perform fast signal segmentation and is implemented in Binseg . It is a sequential approach: first, one change point is detected in the complete input signal, then series is split around this change point, then the operation is repeated on the two resulting sub-signals. For a theoretical and algorithmic analysis of Binseg , see for instance [Bai1997] and [Fryzlewicz2014] . The benefits of binary segmentation includes low complexity (of the order of \\(\\mathcal{O}(Cn\\log n)\\) , where \\(n\\) is the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the binary segmentation algorithm Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 500 # number of samples n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a binary segmentation of a signal, initialize a BinSeg instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\",... algo = rpt . Binseg ( model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . Binseg ( model = model , jump = 10 ) . fit ( signal ) References # [Bai1997] Bai, J. (1997). Estimating multiple breaks one at a time. Econometric Theory, 13(3), 315\u2013352. [Fryzlewicz2014] Fryzlewicz, P. (2014). Wild binary segmentation for multiple change-point detection. The Annals of Statistics, 42(6), 2243\u20132281.","title":"Binary segmentation"},{"location":"user-guide/detection/binseg/#binary-segmentation-binseg","text":"","title":"Binary segmentation (Binseg)"},{"location":"user-guide/detection/binseg/#description","text":"Binary change point detection is used to perform fast signal segmentation and is implemented in Binseg . It is a sequential approach: first, one change point is detected in the complete input signal, then series is split around this change point, then the operation is repeated on the two resulting sub-signals. For a theoretical and algorithmic analysis of Binseg , see for instance [Bai1997] and [Fryzlewicz2014] . The benefits of binary segmentation includes low complexity (of the order of \\(\\mathcal{O}(Cn\\log n)\\) , where \\(n\\) is the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the binary segmentation algorithm","title":"Description"},{"location":"user-guide/detection/binseg/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n = 500 # number of samples n_bkps , sigma = 3 , 5 # number of change points, noise standard deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a binary segmentation of a signal, initialize a BinSeg instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\",... algo = rpt . Binseg ( model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . Binseg ( model = model , jump = 10 ) . fit ( signal )","title":"Usage"},{"location":"user-guide/detection/binseg/#references","text":"[Bai1997] Bai, J. (1997). Estimating multiple breaks one at a time. Econometric Theory, 13(3), 315\u2013352. [Fryzlewicz2014] Fryzlewicz, P. (2014). Wild binary segmentation for multiple change-point detection. The Annals of Statistics, 42(6), 2243\u20132281.","title":"References"},{"location":"user-guide/detection/bottomup/","text":"Bottom-up segmentation ( BottomUp ) # Description # Bottom-up change point detection is used to perform fast signal segmentation and is implemented in BottomUp in a sequential manner. Contrary to binary segmentation, which is a greedy procedure, bottom-up segmentation is generous: it starts with many change points and successively deletes the less significant ones. First, the signal is divided in many sub-signals along a regular grid. Then contiguous segments are successively merged according to a measure of how similar they are. See for instance [Keogh2001] or [Fryzlewicz2007] for an algorithmic analysis of BottomUp . The benefits of bottom-up segmentation includes low complexity (of the order of \\(\\mathcal{O}(n\\log n)\\) , where \\(n\\) is the number of samples), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the bottom-up segmentation algorithm Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a bottom-up segmentation of a signal, initialize a BottomUp instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\" algo = rpt . BottomUp ( model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . BottomUp ( model = model , jump = 10 ) . fit ( signal ) References # [Keogh2001] Keogh, E., Chu, S., Hart, D., & Pazzani, M. (2001). An online algorithm for segmenting time series. Proceedings of the IEEE International Conference on Data Mining (ICDM), 289\u2013296. [Fryzlewicz2007] Fryzlewicz, P. (2007). Unbalanced Haar technique for nonparametric function estimation. Journal of the American Statistical Association, 102(480), 1318\u20131327.","title":"Bottom-up segmentation"},{"location":"user-guide/detection/bottomup/#bottom-up-segmentation-bottomup","text":"","title":"Bottom-up segmentation (BottomUp)"},{"location":"user-guide/detection/bottomup/#description","text":"Bottom-up change point detection is used to perform fast signal segmentation and is implemented in BottomUp in a sequential manner. Contrary to binary segmentation, which is a greedy procedure, bottom-up segmentation is generous: it starts with many change points and successively deletes the less significant ones. First, the signal is divided in many sub-signals along a regular grid. Then contiguous segments are successively merged according to a measure of how similar they are. See for instance [Keogh2001] or [Fryzlewicz2007] for an algorithmic analysis of BottomUp . The benefits of bottom-up segmentation includes low complexity (of the order of \\(\\mathcal{O}(n\\log n)\\) , where \\(n\\) is the number of samples), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the bottom-up segmentation algorithm","title":"Description"},{"location":"user-guide/detection/bottomup/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a bottom-up segmentation of a signal, initialize a BottomUp instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\" algo = rpt . BottomUp ( model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . BottomUp ( model = model , jump = 10 ) . fit ( signal )","title":"Usage"},{"location":"user-guide/detection/bottomup/#references","text":"[Keogh2001] Keogh, E., Chu, S., Hart, D., & Pazzani, M. (2001). An online algorithm for segmenting time series. Proceedings of the IEEE International Conference on Data Mining (ICDM), 289\u2013296. [Fryzlewicz2007] Fryzlewicz, P. (2007). Unbalanced Haar technique for nonparametric function estimation. Journal of the American Statistical Association, 102(480), 1318\u20131327.","title":"References"},{"location":"user-guide/detection/dynp/","text":"Dynamic programming ( Dynp ) # Description # The method is implemented in both Dynp , which is a full native python implementation for which the user can choose any cost functions defined in ruptures.costs It finds the (exact) minimum of the sum of costs by computing the cost of all subsequences of a given signal. It is called \"dynamic programming\" because the search over all possible segmentations is ordered using a dynamic programming approach. In order to work, the user must specify in advance the number of changes to detect . (Consider using penalized methods when this number is unknown.) The complexity of the dynamic programming approach is of the order \\(\\mathcal{O}(CKn^2)\\) , where \\(K\\) is the number of change points to detect, \\(n\\) the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal. Consequently, piecewise constant models ( model=l2 ) are significantly faster than linear or autoregressive models. To reduce the computational cost, you can consider only a subsample of possible change point indexes, by changing the min_size and jump arguments when instantiating Dynp : min_size controls the minimum distance between change points; for instance, if min_size=10 , all change points will be at least 10 samples apart. jump controls the grid of possible change points; for instance, if jump=k , only changes at k, 2*k, 3*k,... are considered. Usage # import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 n_bkps , sigma = 3 , 5 signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) # change point detection model = \"l1\" # \"l2\", \"rbf\" algo = rpt . Dynp ( model = model , min_size = 3 , jump = 5 ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show ()","title":"Dynamic programming"},{"location":"user-guide/detection/dynp/#dynamic-programming-dynp","text":"","title":"Dynamic programming (Dynp)"},{"location":"user-guide/detection/dynp/#description","text":"The method is implemented in both Dynp , which is a full native python implementation for which the user can choose any cost functions defined in ruptures.costs It finds the (exact) minimum of the sum of costs by computing the cost of all subsequences of a given signal. It is called \"dynamic programming\" because the search over all possible segmentations is ordered using a dynamic programming approach. In order to work, the user must specify in advance the number of changes to detect . (Consider using penalized methods when this number is unknown.) The complexity of the dynamic programming approach is of the order \\(\\mathcal{O}(CKn^2)\\) , where \\(K\\) is the number of change points to detect, \\(n\\) the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal. Consequently, piecewise constant models ( model=l2 ) are significantly faster than linear or autoregressive models. To reduce the computational cost, you can consider only a subsample of possible change point indexes, by changing the min_size and jump arguments when instantiating Dynp : min_size controls the minimum distance between change points; for instance, if min_size=10 , all change points will be at least 10 samples apart. jump controls the grid of possible change points; for instance, if jump=k , only changes at k, 2*k, 3*k,... are considered.","title":"Description"},{"location":"user-guide/detection/dynp/#usage","text":"import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 n_bkps , sigma = 3 , 5 signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) # change point detection model = \"l1\" # \"l2\", \"rbf\" algo = rpt . Dynp ( model = model , min_size = 3 , jump = 5 ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show ()","title":"Usage"},{"location":"user-guide/detection/kernelcpd/","text":"Kernel change point detection # Problem formulation # In this section, the kernel change point detection setting is briefly described. The interested reader can refer to [ Celisse2018 , Arlot2019 ] for a more complete introduction. Let \\(y = \\{y_0,y_1,\\dots,y_{T-1}\\}\\) denote a \\(\\mathbb{R}^d\\) -valued signal with \\(T\\) samples. This signal is mapped onto a reproducing Hilbert space (rkhs) \\(\\mathcal{H}\\) associated with a user-defined kernel function \\(k(\\cdot, \\cdot):\\mathbb{R}^d\\times\\mathbb{R}^d\\rightarrow\\mathbb{R}\\) . The mapping function \\(\\phi:\\mathbb{R}^d\\rightarrow\\mathcal{H}\\) onto this rkhs is implicitly defined by \\(\\phi(y_t) = k(y_t, \\cdot)\\in\\mathcal{H}\\) resulting in the following inner-product and norm: \\[ \\langle\\phi(y_s)\\mid\\phi(y_t)\\rangle_{\\mathcal{H}} = k(y_s,y_t) \\] and \\[ \\|\\phi(y_t)\\|_{\\mathcal{H}}^2 = k(y_t,y_t) \\] for any samples \\(y_s,y_t\\in\\mathbb{R}^d\\) . Kernel change point detection consists in finding mean-shifts in the mapped signal \\(\\phi(y)\\) by minimizing \\(V(\\cdot)\\) where \\[ V(t_1,\\dots,t_K) := \\sum_{k=0}^K\\sum_{t=t_k}^{t_{k+1}-1} \\|\\phi(y_t)-\\bar{\\mu}_{t_k..t_{k+1}}\\|^2_{\\mathcal{H}} \\] where \\(\\bar{\\mu}_{t_k..t_{k+1}}\\) is the empirical mean of the sub-signal \\(\\phi(y_{t_k}), \\phi(y_{t_k+1}),\\dots,\\phi(y_{t_{k+1}-1})\\) , and \\(t_1,t_2,\\dots,t_K\\) are change point indexes, in increasing order. (By convention \\(t_0=0\\) and \\(t_{K+1}=T\\) .) If the number of changes is known beforehand , we solve the following optimization problem, over all possible change positions \\(t_1<t_2<\\dots<t_K\\) (where the number \\(K\\) of changes is provided by the user): \\[ \\hat{t}_1,\\dots,\\hat{t}_K := \\arg\\min_{t_1,\\dots,t_K} V(t_1,\\dots,t_K). \\] The exact optimization procedure is described in [Celisse2018] . If the number of changes is not known , we solve the following penalized optimization problem \\[ \\hat{K}, \\{\\hat{t}_1,\\dots,\\hat{t}_{\\hat{K}}\\} := \\arg\\min_{K, \\{t_1,\\dots, t_K\\}} V(t_1,\\dots, t_K) + \\beta K \\] where \\(\\beta>0\\) is the smoothing parameter (provided by the user) and \\(\\hat{K}\\) is the estimated number of change points. Higher values of \\(\\beta\\) produce lower \\(\\hat{K}\\) . The exact optimization procedure is described in [Killick2012] . Available kernels # We list below a number of kernels that are already implemented in ruptures . In the following, \\(u\\) and \\(v\\) are two d-dimensional vectors and \\(\\|\\cdot\\|\\) is the Euclidean norm. Kernel Description Cost function Linear model=\"linear\" \\(k_{\\text{linear}}(u, v) = u^T v\\) . CostL2 Gaussian model=\"rbf\" \\(k_{\\text{Gaussian}}(u,v)=\\exp(-\\gamma \\|u-v\\|^2)\\) where \\(\\gamma>0\\) is a user-defined parameter. CostRbf Cosine model=\"cosine\" \\(k_{\\text{cosine}}(u, v) = (u^T v)/(\\|u\\|\\|v\\|)\\) CostCosine Implementation and usage # Kernel change point detection is implemented in the class KernelCPD , which is a C implementation of dynamic programming and PELT. To see it in action, please look at the gallery of examples, in particular: Kernel change point detection: a performance comparison The exact class API is available here . References # [Gretton2012] Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch\u00f6lkopf, B., & Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13, 723\u2013773. [Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598. [Celisse2018] Celisse, A., Marot, G., Pierre-Jean, M., & Rigaill, G. (2018). New efficient algorithms for multiple change-point detection with reproducing kernels. Computational Statistics and Data Analysis, 128, 200\u2013220. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"Kernel change detection"},{"location":"user-guide/detection/kernelcpd/#kernel-change-point-detection","text":"","title":"Kernel change point detection"},{"location":"user-guide/detection/kernelcpd/#problem-formulation","text":"In this section, the kernel change point detection setting is briefly described. The interested reader can refer to [ Celisse2018 , Arlot2019 ] for a more complete introduction. Let \\(y = \\{y_0,y_1,\\dots,y_{T-1}\\}\\) denote a \\(\\mathbb{R}^d\\) -valued signal with \\(T\\) samples. This signal is mapped onto a reproducing Hilbert space (rkhs) \\(\\mathcal{H}\\) associated with a user-defined kernel function \\(k(\\cdot, \\cdot):\\mathbb{R}^d\\times\\mathbb{R}^d\\rightarrow\\mathbb{R}\\) . The mapping function \\(\\phi:\\mathbb{R}^d\\rightarrow\\mathcal{H}\\) onto this rkhs is implicitly defined by \\(\\phi(y_t) = k(y_t, \\cdot)\\in\\mathcal{H}\\) resulting in the following inner-product and norm: \\[ \\langle\\phi(y_s)\\mid\\phi(y_t)\\rangle_{\\mathcal{H}} = k(y_s,y_t) \\] and \\[ \\|\\phi(y_t)\\|_{\\mathcal{H}}^2 = k(y_t,y_t) \\] for any samples \\(y_s,y_t\\in\\mathbb{R}^d\\) . Kernel change point detection consists in finding mean-shifts in the mapped signal \\(\\phi(y)\\) by minimizing \\(V(\\cdot)\\) where \\[ V(t_1,\\dots,t_K) := \\sum_{k=0}^K\\sum_{t=t_k}^{t_{k+1}-1} \\|\\phi(y_t)-\\bar{\\mu}_{t_k..t_{k+1}}\\|^2_{\\mathcal{H}} \\] where \\(\\bar{\\mu}_{t_k..t_{k+1}}\\) is the empirical mean of the sub-signal \\(\\phi(y_{t_k}), \\phi(y_{t_k+1}),\\dots,\\phi(y_{t_{k+1}-1})\\) , and \\(t_1,t_2,\\dots,t_K\\) are change point indexes, in increasing order. (By convention \\(t_0=0\\) and \\(t_{K+1}=T\\) .) If the number of changes is known beforehand , we solve the following optimization problem, over all possible change positions \\(t_1<t_2<\\dots<t_K\\) (where the number \\(K\\) of changes is provided by the user): \\[ \\hat{t}_1,\\dots,\\hat{t}_K := \\arg\\min_{t_1,\\dots,t_K} V(t_1,\\dots,t_K). \\] The exact optimization procedure is described in [Celisse2018] . If the number of changes is not known , we solve the following penalized optimization problem \\[ \\hat{K}, \\{\\hat{t}_1,\\dots,\\hat{t}_{\\hat{K}}\\} := \\arg\\min_{K, \\{t_1,\\dots, t_K\\}} V(t_1,\\dots, t_K) + \\beta K \\] where \\(\\beta>0\\) is the smoothing parameter (provided by the user) and \\(\\hat{K}\\) is the estimated number of change points. Higher values of \\(\\beta\\) produce lower \\(\\hat{K}\\) . The exact optimization procedure is described in [Killick2012] .","title":"Problem formulation"},{"location":"user-guide/detection/kernelcpd/#available-kernels","text":"We list below a number of kernels that are already implemented in ruptures . In the following, \\(u\\) and \\(v\\) are two d-dimensional vectors and \\(\\|\\cdot\\|\\) is the Euclidean norm. Kernel Description Cost function Linear model=\"linear\" \\(k_{\\text{linear}}(u, v) = u^T v\\) . CostL2 Gaussian model=\"rbf\" \\(k_{\\text{Gaussian}}(u,v)=\\exp(-\\gamma \\|u-v\\|^2)\\) where \\(\\gamma>0\\) is a user-defined parameter. CostRbf Cosine model=\"cosine\" \\(k_{\\text{cosine}}(u, v) = (u^T v)/(\\|u\\|\\|v\\|)\\) CostCosine","title":"Available kernels"},{"location":"user-guide/detection/kernelcpd/#implementation-and-usage","text":"Kernel change point detection is implemented in the class KernelCPD , which is a C implementation of dynamic programming and PELT. To see it in action, please look at the gallery of examples, in particular: Kernel change point detection: a performance comparison The exact class API is available here .","title":"Implementation and usage"},{"location":"user-guide/detection/kernelcpd/#references","text":"[Gretton2012] Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch\u00f6lkopf, B., & Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13, 723\u2013773. [Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598. [Celisse2018] Celisse, A., Marot, G., Pierre-Jean, M., & Rigaill, G. (2018). New efficient algorithms for multiple change-point detection with reproducing kernels. Computational Statistics and Data Analysis, 128, 200\u2013220. [Arlot2019] Arlot, S., Celisse, A., & Harchaoui, Z. (2019). A kernel multiple change-point algorithm via model selection. Journal of Machine Learning Research, 20(162), 1\u201356.","title":"References"},{"location":"user-guide/detection/pelt/","text":"Linearly penalized segmentation ( Pelt ) # Description # The method is implemented in Pelt . Because the enumeration of all possible partitions impossible, the algorithm relies on a pruning rule. Many indexes are discarded, greatly reducing the computational cost while retaining the ability to find the optimal segmentation. The implementation follows [Killick2012] . In addition, under certain conditions on the change point repartition, the avarage computational complexity is of the order of \\(\\mathcal{O}(CKn)\\) , where \\(K\\) is the number of change points to detect, \\(n\\) the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal. Consequently, piecewise constant models ( model=l2 ) are significantly faster than linear or autoregressive models. To reduce the computational cost, you can consider only a subsample of possible change point indexes, by changing the min_size and jump arguments when instantiating Pelt : min_size controls the minimum distance between change points; for instance, if min_size=10 , all change points will be at least 10 samples apart. jump controls the grid of possible change points; for instance, if jump=k , only changes at k, 2*k, 3*k,... are considered. Usage # import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 n_bkps , sigma = 3 , 1 signal , b = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) # change point detection model = \"l1\" # \"l2\", \"rbf\" algo = rpt . Pelt ( model = model , min_size = 3 , jump = 5 ) . fit ( signal ) my_bkps = algo . predict ( pen = 3 ) # show results fig , ( ax ,) = rpt . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () References # [Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598.","title":"Pelt"},{"location":"user-guide/detection/pelt/#linearly-penalized-segmentation-pelt","text":"","title":"Linearly penalized segmentation (Pelt)"},{"location":"user-guide/detection/pelt/#description","text":"The method is implemented in Pelt . Because the enumeration of all possible partitions impossible, the algorithm relies on a pruning rule. Many indexes are discarded, greatly reducing the computational cost while retaining the ability to find the optimal segmentation. The implementation follows [Killick2012] . In addition, under certain conditions on the change point repartition, the avarage computational complexity is of the order of \\(\\mathcal{O}(CKn)\\) , where \\(K\\) is the number of change points to detect, \\(n\\) the number of samples and \\(C\\) the complexity of calling the considered cost function on one sub-signal. Consequently, piecewise constant models ( model=l2 ) are significantly faster than linear or autoregressive models. To reduce the computational cost, you can consider only a subsample of possible change point indexes, by changing the min_size and jump arguments when instantiating Pelt : min_size controls the minimum distance between change points; for instance, if min_size=10 , all change points will be at least 10 samples apart. jump controls the grid of possible change points; for instance, if jump=k , only changes at k, 2*k, 3*k,... are considered.","title":"Description"},{"location":"user-guide/detection/pelt/#usage","text":"import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 n_bkps , sigma = 3 , 1 signal , b = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) # change point detection model = \"l1\" # \"l2\", \"rbf\" algo = rpt . Pelt ( model = model , min_size = 3 , jump = 5 ) . fit ( signal ) my_bkps = algo . predict ( pen = 3 ) # show results fig , ( ax ,) = rpt . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show ()","title":"Usage"},{"location":"user-guide/detection/pelt/#references","text":"[Killick2012] Killick, R., Fearnhead, P., & Eckley, I. (2012). Optimal detection of changepoints with a linear computational cost. Journal of the American Statistical Association, 107(500), 1590\u20131598.","title":"References"},{"location":"user-guide/detection/window/","text":"Window-based change point detection ( Window ) # Description # Window-based change point detection is used to perform fast signal segmentation and is implemented in Window . The algorithm uses two windows which slide along the data stream. The statistical properties of the signals within each window are compared with a discrepancy measure. For a given cost function \\(c(\\cdot)\\) , a discrepancy measure is derived \\(d(\\cdot,\\cdot)\\) as follows: \\[ d(y_{u..v}, y_{v..w}) = c(y_{u..w}) - c(y_{u..v}) - c(y_{v..w}) \\] where \\(\\{y_t\\}_t\\) is the input signal and \\(u < v < w\\) are indexes. The discrepancy is the cost gain of splitting the sub-signal \\(y_{u..w}\\) at the index \\(v\\) . If the sliding windows \\(u..v\\) and \\(v..w\\) both fall into a segment, their statistical properties are similar and the discrepancy between the first window and the second window is low. If the sliding windows fall into two dissimilar segments, the discrepancy is significantly higher, suggesting that the boundary between windows is a change point. The discrepancy curve is the curve, defined for all indexes \\(t\\) between \\(w/2\\) and \\(n-w/2\\) ( \\(n\\) is the number of samples), \\[ \\big(t, d(y_{t-w/2..t}, y_{t..t+w/2})\\big) \\] where \\(w\\) is the window length. A sequential peak search is performed on the discrepancy curve in order to detect change points. The benefits of window-based segmentation includes low complexity (of the order of \\(\\mathcal{O}(n w)\\) , where \\(n\\) is the number of samples), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the window sliding segmentation algorithm Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a binary segmentation of a signal, initialize a Window instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\" algo = rpt . Window ( width = 40 , model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () The window length (in number of samples) is modified through the argument width . Usual methods assume that the window length is smaller than the smallest regime length. In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . Window ( model = model , jump = 10 ) . fit ( signal )","title":"Window sliding segmentation"},{"location":"user-guide/detection/window/#window-based-change-point-detection-window","text":"","title":"Window-based change point detection (Window)"},{"location":"user-guide/detection/window/#description","text":"Window-based change point detection is used to perform fast signal segmentation and is implemented in Window . The algorithm uses two windows which slide along the data stream. The statistical properties of the signals within each window are compared with a discrepancy measure. For a given cost function \\(c(\\cdot)\\) , a discrepancy measure is derived \\(d(\\cdot,\\cdot)\\) as follows: \\[ d(y_{u..v}, y_{v..w}) = c(y_{u..w}) - c(y_{u..v}) - c(y_{v..w}) \\] where \\(\\{y_t\\}_t\\) is the input signal and \\(u < v < w\\) are indexes. The discrepancy is the cost gain of splitting the sub-signal \\(y_{u..w}\\) at the index \\(v\\) . If the sliding windows \\(u..v\\) and \\(v..w\\) both fall into a segment, their statistical properties are similar and the discrepancy between the first window and the second window is low. If the sliding windows fall into two dissimilar segments, the discrepancy is significantly higher, suggesting that the boundary between windows is a change point. The discrepancy curve is the curve, defined for all indexes \\(t\\) between \\(w/2\\) and \\(n-w/2\\) ( \\(n\\) is the number of samples), \\[ \\big(t, d(y_{t-w/2..t}, y_{t..t+w/2})\\big) \\] where \\(w\\) is the window length. A sequential peak search is performed on the discrepancy curve in order to detect change points. The benefits of window-based segmentation includes low complexity (of the order of \\(\\mathcal{O}(n w)\\) , where \\(n\\) is the number of samples), the fact that it can extend any single change point detection method to detect multiple changes points and that it can work whether the number of regimes is known beforehand or not. Schematic view of the window sliding segmentation algorithm","title":"Description"},{"location":"user-guide/detection/window/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 3 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) To perform a binary segmentation of a signal, initialize a Window instance. # change point detection model = \"l2\" # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\" algo = rpt . Window ( width = 40 , model = model ) . fit ( signal ) my_bkps = algo . predict ( n_bkps = 3 ) # show results rpt . show . display ( signal , bkps , my_bkps , figsize = ( 10 , 6 )) plt . show () The window length (in number of samples) is modified through the argument width . Usual methods assume that the window length is smaller than the smallest regime length. In the situation in which the number of change points is unknown, one can specify a penalty using the pen parameter or a threshold on the residual norm using epsilon . my_bkps = algo . predict ( pen = np . log ( n ) * dim * sigma ** 2 ) # or my_bkps = algo . predict ( epsilon = 3 * n * sigma ** 2 ) For faster predictions, one can modify the jump parameter during initialization. The higher it is, the faster the prediction is achieved (at the expense of precision). algo = rpt . Window ( model = model , jump = 10 ) . fit ( signal )","title":"Usage"},{"location":"user-guide/metrics/hausdorff/","text":"Hausdorff metric ( hausdorff ) # Description # The hausdorff function computes the Hausdorff metric which measures the worst prediction error. Assume a set of change point indexes \\(t_1,t_2,\\dots\\) and their estimates \\(\\hat{t}_1, \\hat{t}_2,\\dots\\) . The Hausdorff metric is then equal to \\[ \\text{Hausdorff}(\\{t_k\\}_k, \\{\\hat{t}_k\\}_k) := \\max \\{ \\max_k \\min_l |t_k - \\hat{t}_l| \\, , \\max_k \\min_l |\\hat{t}_k - t_l|\\}. \\] Schematic example: true segmentation in gray, estimated segmentation in dashed lines. Here, Hausdorff is equal to \\(\\max(\\Delta t_1, \\Delta t_2, \\Delta t_3)\\) . Usage # Start with the usual imports and create two segmentations to compare. from ruptures.metrics import hausdorff bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] print ( hausdorff ( bkps1 , bkps2 ))","title":"Hausdorff metric"},{"location":"user-guide/metrics/hausdorff/#hausdorff-metric-hausdorff","text":"","title":"Hausdorff metric (hausdorff)"},{"location":"user-guide/metrics/hausdorff/#description","text":"The hausdorff function computes the Hausdorff metric which measures the worst prediction error. Assume a set of change point indexes \\(t_1,t_2,\\dots\\) and their estimates \\(\\hat{t}_1, \\hat{t}_2,\\dots\\) . The Hausdorff metric is then equal to \\[ \\text{Hausdorff}(\\{t_k\\}_k, \\{\\hat{t}_k\\}_k) := \\max \\{ \\max_k \\min_l |t_k - \\hat{t}_l| \\, , \\max_k \\min_l |\\hat{t}_k - t_l|\\}. \\] Schematic example: true segmentation in gray, estimated segmentation in dashed lines. Here, Hausdorff is equal to \\(\\max(\\Delta t_1, \\Delta t_2, \\Delta t_3)\\) .","title":"Description"},{"location":"user-guide/metrics/hausdorff/#usage","text":"Start with the usual imports and create two segmentations to compare. from ruptures.metrics import hausdorff bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] print ( hausdorff ( bkps1 , bkps2 ))","title":"Usage"},{"location":"user-guide/metrics/precisionrecall/","text":"Precision and recall ( precision_recall ) # Description # The precision and recall of an estimated segmentation is computed by the function precision_recall as follows. A true change point is declared \"detected\" (or positive) if there is at least one computed change point at less than \"margin\" points from it. Formally, assume a set of change point indexes \\(t_1,t_2,\\dots\\) and their estimates \\(\\hat{t}_1, \\hat{t}_2,\\dots\\) In the context of change point detection, precision and recall are defined as follows: \\[ \\text{precision}:=|\\text{TP}|/|\\{\\hat{t}_l\\}_l| \\quad \\text{and}\\quad\\text{recall}:=|\\text{TP}|/|\\{t_k\\}_k| \\] where, for a given margin \\(M\\) , true positives \\(\\text{TP}\\) are true change points for which there is an estimated one at less than \\(M\\) samples, i.e. \\[ \\text{TP}:= \\{t_k\\,|\\, \\exists\\, \\hat{t}_l\\,\\, \\text{s.t.}\\, |\\hat{t}_l - t_k|<M \\}. \\] Schematic example: true segmentation in gray, estimated segmentation in dashed lines and margin in dashed areas. Here, precision is 2/3 and recall is 2/2. Usage # Start with the usual imports and create two change point sets to compare. from ruptures.metrics import precision_recall bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] p , r = precision_recall ( bkps1 , bkps2 ) print (( p , r )) The margin parameter \\(M\\) can be changed through the keyword margin (default is 10 samples). p , r = precision_recall ( bkps1 , bkps2 , margin = 10 ) print (( p , r )) p , r = precision_recall ( bkps1 , bkps2 , margin = 20 ) print (( p , r ))","title":"Precision and recall"},{"location":"user-guide/metrics/precisionrecall/#precision-and-recall-precision_recall","text":"","title":"Precision and recall (precision_recall)"},{"location":"user-guide/metrics/precisionrecall/#description","text":"The precision and recall of an estimated segmentation is computed by the function precision_recall as follows. A true change point is declared \"detected\" (or positive) if there is at least one computed change point at less than \"margin\" points from it. Formally, assume a set of change point indexes \\(t_1,t_2,\\dots\\) and their estimates \\(\\hat{t}_1, \\hat{t}_2,\\dots\\) In the context of change point detection, precision and recall are defined as follows: \\[ \\text{precision}:=|\\text{TP}|/|\\{\\hat{t}_l\\}_l| \\quad \\text{and}\\quad\\text{recall}:=|\\text{TP}|/|\\{t_k\\}_k| \\] where, for a given margin \\(M\\) , true positives \\(\\text{TP}\\) are true change points for which there is an estimated one at less than \\(M\\) samples, i.e. \\[ \\text{TP}:= \\{t_k\\,|\\, \\exists\\, \\hat{t}_l\\,\\, \\text{s.t.}\\, |\\hat{t}_l - t_k|<M \\}. \\] Schematic example: true segmentation in gray, estimated segmentation in dashed lines and margin in dashed areas. Here, precision is 2/3 and recall is 2/2.","title":"Description"},{"location":"user-guide/metrics/precisionrecall/#usage","text":"Start with the usual imports and create two change point sets to compare. from ruptures.metrics import precision_recall bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] p , r = precision_recall ( bkps1 , bkps2 ) print (( p , r )) The margin parameter \\(M\\) can be changed through the keyword margin (default is 10 samples). p , r = precision_recall ( bkps1 , bkps2 , margin = 10 ) print (( p , r )) p , r = precision_recall ( bkps1 , bkps2 , margin = 20 ) print (( p , r ))","title":"Usage"},{"location":"user-guide/metrics/randindex/","text":"Rand index ( randindex ) # Description # The Rand index, computed by the randindex function, measures the similarity between two segmentations. Formally, for a signal \\(\\{y_t\\}_t\\) and a segmentation \\(\\mathcal{S}\\) , denote by \\(A\\) the associated membership matrix: \\[ \\begin{aligned} \\mathcal{A}_{ij} &= 1 \\text{ if both samples } y_i \\text{ and } y_j \\text{ are in the same segment according to } \\mathcal{S} \\\\ &= 0 \\quad\\text{otherwise} \\end{aligned} \\] Let \\(\\hat{\\mathcal{S}}\\) be the estimated segmentation and \\(\\hat{A}\\) , the associated membership matrix. Then the Rand index is equal to \\[ \\frac{\\sum_{i<j} \\mathbb{1}(A_{ij} = \\hat{A}_{ij})}{T(T-1)/2} \\] where \\(T\\) is the number of samples. It has a value between 0 and 1: 0 indicates that the two segmentations do not agree on any pair of points and 1 indicates that the two segmentations are exactly the same. Schematic example: true segmentation in gray, estimated segmentation in dashed lines and their associated membership matrices. Rand index is equal to 1 minus the gray area. Usage # Start with the usual imports and create two segmentations to compare. from ruptures.metrics import randindex bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] print ( randindex ( bkps1 , bkps2 ))","title":"Rand index"},{"location":"user-guide/metrics/randindex/#rand-index-randindex","text":"","title":"Rand index (randindex)"},{"location":"user-guide/metrics/randindex/#description","text":"The Rand index, computed by the randindex function, measures the similarity between two segmentations. Formally, for a signal \\(\\{y_t\\}_t\\) and a segmentation \\(\\mathcal{S}\\) , denote by \\(A\\) the associated membership matrix: \\[ \\begin{aligned} \\mathcal{A}_{ij} &= 1 \\text{ if both samples } y_i \\text{ and } y_j \\text{ are in the same segment according to } \\mathcal{S} \\\\ &= 0 \\quad\\text{otherwise} \\end{aligned} \\] Let \\(\\hat{\\mathcal{S}}\\) be the estimated segmentation and \\(\\hat{A}\\) , the associated membership matrix. Then the Rand index is equal to \\[ \\frac{\\sum_{i<j} \\mathbb{1}(A_{ij} = \\hat{A}_{ij})}{T(T-1)/2} \\] where \\(T\\) is the number of samples. It has a value between 0 and 1: 0 indicates that the two segmentations do not agree on any pair of points and 1 indicates that the two segmentations are exactly the same. Schematic example: true segmentation in gray, estimated segmentation in dashed lines and their associated membership matrices. Rand index is equal to 1 minus the gray area.","title":"Description"},{"location":"user-guide/metrics/randindex/#usage","text":"Start with the usual imports and create two segmentations to compare. from ruptures.metrics import randindex bkps1 , bkps2 = [ 100 , 200 , 500 ], [ 105 , 115 , 350 , 400 , 500 ] print ( randindex ( bkps1 , bkps2 ))","title":"Usage"},{"location":"user-guide/show/display/","text":"Display ( display ) # Description # The function display displays a signal and the change points provided in alternating colors. If another set of change point indexes is provided, they are displayed with dashed vertical dashed lines. Usage # Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 2 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps ) If we computed another set of change points, for instance [110, 150, 320, 500] , we can easily compare the two segmentations. rpt . display ( signal , bkps , [ 110 , 150 , 320 , 500 ]) Example output of the function display .","title":"Display"},{"location":"user-guide/show/display/#display-display","text":"","title":"Display (display)"},{"location":"user-guide/show/display/#description","text":"The function display displays a signal and the change points provided in alternating colors. If another set of change point indexes is provided, they are displayed with dashed vertical dashed lines.","title":"Description"},{"location":"user-guide/show/display/#usage","text":"Start with the usual imports and create a signal. import numpy as np import matplotlib.pylab as plt import ruptures as rpt # creation of data n , dim = 500 , 2 # number of samples, dimension n_bkps , sigma = 3 , 5 # number of change points, noise standart deviation signal , bkps = rpt . pw_constant ( n , dim , n_bkps , noise_std = sigma ) rpt . display ( signal , bkps ) If we computed another set of change points, for instance [110, 150, 320, 500] , we can easily compare the two segmentations. rpt . display ( signal , bkps , [ 110 , 150 , 320 , 500 ]) Example output of the function display .","title":"Usage"}]}